<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="Extreme Learning Machine With Subnetwork Hidden Nodes for Regression and Classification (Cybernet 2015)">
<title>Read: Optim - SLFN | ELM with SNN</title>

<link rel='canonical' href='http://blog.zichen.uk/post/writenotes/model/subnetwork/b-note-elm-subnet/'>

<link rel="stylesheet" href="/scss/style.min.0e95b70faf4f470dc6ba88da538ece0f8cf22d03bab371e1b345205b81899732.css"><meta property='og:title' content="Read: Optim - SLFN | ELM with SNN">
<meta property='og:description' content="Extreme Learning Machine With Subnetwork Hidden Nodes for Regression and Classification (Cybernet 2015)">
<meta property='og:url' content='http://blog.zichen.uk/post/writenotes/model/subnetwork/b-note-elm-subnet/'>
<meta property='og:site_name' content='Zichen Wang'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='SLFN' /><meta property='article:published_time' content='2023-01-20T11:46:00-05:00'/><meta property='article:modified_time' content='2023-01-20T11:46:00-05:00'/>
<meta name="twitter:title" content="Read: Optim - SLFN | ELM with SNN">
<meta name="twitter:description" content="Extreme Learning Machine With Subnetwork Hidden Nodes for Regression and Classification (Cybernet 2015)">
    <link rel="shortcut icon" href="/favicon-32x32.png" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu_b598b46054b3fa80.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Zichen Wang</a></h1>
            <h2 class="site-description"></h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://github.com/zichen34'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://twitter.com/luckily1640'
                        target="_blank"
                        title="Twitter"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/post/writenotes/' >
                
                
                
                <span>WriteNotes</span>
            </a>
        </li>
        
        
        <li >
            <a href='/post/writenotes/model/acadmodel/aboutme/' >
                
                
                
                <span>About</span>
            </a>
        </li>
        
        
        <li >
            <a href='/page/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>Dark Mode</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#-introduction">â… . Introduction</a></li>
    <li><a href="#-definitions-and-basic-elm">â…¡. Definitions and Basic-ELM</a>
      <ol>
        <li><a href="#a-notations-and-definitions">A. Notations and Definitions</a></li>
        <li><a href="#b-basic-elm">B. Basic-ELM</a></li>
      </ol>
    </li>
    <li><a href="#-proposed-elm-method-with-subnetwork-hidden-nodes">â…¢. Proposed ELM Method With Subnetwork Hidden Nodes</a>
      <ol>
        <li><a href="#a-structure-of-the-proposed-method">A. Structure of the Proposed Method</a></li>
        <li><a href="#b-proposed-method">B. Proposed Method</a></li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/read/" style="background-color: #2a9d8f; color: #fff;">
                Read
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/post/writenotes/model/subnetwork/b-note-elm-subnet/">Read: Optim - SLFN | ELM with SNN</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            Extreme Learning Machine With Subnetwork Hidden Nodes for Regression and Classification (Cybernet 2015)
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Jan 20, 2023</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    8 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
<section class="toc toc--inline">
    <h2 class="">Table of contents</h2>
    <div class="" >
        <nav id="TableOfContents">
  <ol>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#-introduction">â… . Introduction</a></li>
    <li><a href="#-definitions-and-basic-elm">â…¡. Definitions and Basic-ELM</a>
      <ol>
        <li><a href="#a-notations-and-definitions">A. Notations and Definitions</a></li>
        <li><a href="#b-basic-elm">B. Basic-ELM</a></li>
      </ol>
    </li>
    <li><a href="#-proposed-elm-method-with-subnetwork-hidden-nodes">â…¢. Proposed ELM Method With Subnetwork Hidden Nodes</a>
      <ol>
        <li><a href="#a-structure-of-the-proposed-method">A. Structure of the Proposed Method</a></li>
        <li><a href="#b-proposed-method">B. Proposed Method</a></li>
      </ol>
    </li>
  </ol>
</nav>

    </div>
</section>



    
    
    <p><a class="link" href="https://ieeexplore.ieee.org/abstract/document/7314912"  target="_blank" rel="noopener"
    >IEEE Cybernetics(2015-11-02)</a>
| <a class="link" href="https://drive.google.com/file/d/13FD2IifYUndeTXeV6NrlS_ka7-2JFUTY/view"  target="_blank" rel="noopener"
    >Google Drive</a>
| <a class="link" href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=fFP4b9kAAAAJ&amp;citation_for_view=fFP4b9kAAAAJ:rHJHxKgnXwkC"  target="_blank" rel="noopener"
    >G.Scholar</a></p>
<ul>
<li>This is the first paper of ELM with subnetwork nodes by <a class="link" href="http://www.yiminyang.com/"  target="_blank" rel="noopener"
    >Yimin Yang</a>.
<ul>
<li>The second paper in the series is <a class="link" href="http://blog.zichen.uk/post/writenotes/model/subnetwork/b-note-elm-mltlyr/" >MltLyr ELM with subnetwork nodes</a></li>
</ul>
</li>
<li>The outline of Yang&rsquo;s research works: <a class="link" href="http://blog.zichen.uk/post/writenotes/model/subnetwork/d-vid-%E6%9D%A8%E6%98%93%E6%97%BB221020/" >Yang-WeChatLive-20221020</a>;</li>
</ul>
<h2 id="abstract">Abstract
</h2><ul>
<li>Learning effectiveness and speed of SLFN are bottleneck.</li>
<li>ELM is fast.</li>
<li>Grow subnetwork nodes by pulling back residual network error to the hidden layer.</li>
<li>Better generalization performance with fewr hidden nodes.</li>
</ul>
<h2 id="-introduction">â… . Introduction
</h2><ul>
<li>
<p>Bring out the subject: <br>
FNN (universial approximator) â” SLFN</p>
</li>
<li>
<p>What is an SLFN? <br>
Input layer + hidden  layer + output layer</p>
</li>
<li>
<p>Math description: <br>
For N arbitary distinct samples {(ğ±áµ¢,ğ­áµ¢)}áµ¢â‚Œâ‚á´º, where ğ±áµ¢âˆˆ ğ‘â¿ and ğ­áµ¢âˆˆ ğ‘áµ, the network output is:</p>
<p>$ğŸ\_L(ğ±)$ = âˆ‘áµ¢â‚Œâ‚á´¸ ğ›ƒáµ¢h(ğšáµ¢â‹…ğ±â±¼ + báµ¢) = âˆ‘áµ¢â‚Œâ‚á´¸ ğ‡áµ¢â‹…ğ›ƒáµ¢, j=1,&hellip;,N   â€ƒ    (1)</p>
<ul>
<li>SLFN output is the weighted sum of ğ¿ hidden nodes (perceptrons) with the factor ğ›ƒ.</li>
<li>The ith perceptron receives the weighted sum of ğ‘ inputs through its parameters (ğšáµ¢, báµ¢), ğšáµ¢âˆˆ ğ‘â¿, bâˆˆ ğ‘, and performs activation function h.
Its contribution ratio to the all output nodes is ğ›ƒáµ¢.</li>
</ul>
</li>
<li>
<p>ELM traits: <br>
NN (all params are adjustable) â” partial random networks â” ELM is a full-random learning method,
where the input weights and bias (ğš, b) are generated randomly and independent of training data.
(Will the Glorot normalization has no effect?)</p>
</li>
<li>
<p>ELM advantages: <br>
An unification of FNNs and SVM/LS-SVM</p>
</li>
<li>
<p>ELM application: <br>
CV, da,&hellip;, online learning</p>
</li>
<li>
<p>Problems:</p>
<ol>
<li>
<p>The choice of the regularization parameter C which affects the generalization performance of ELM mainly relies on trial-and-error method.</p>
</li>
<li>
<p>How many neurons should be used in ELM. Although Huang suggested to use more than 1000 hidden nodes, whether the number of hidden nodes can be further reduced without affecting learning effectiveness for large-size/high dimension data set. <br>
Several improved ELM methods, like <a class="link" href="https://ieeexplore.ieee.org/abstract/document/6222007"  target="_blank" rel="noopener"
    >B-ELM</a> pulls the network residual error back to the hidden layer but it only works for regression task,
and other methods bring a higher computation complexity when compared to standard ELM.</p>
</li>
</ol>
</li>
<li>
<p>Solution: Growing subnetwork hidden nodes to the exisiting network by pulling back the network residual error to hidden layers. A hidden node itself can be formed by several hidden nodes.</p>
</li>
<li>
<p>Contributions:</p>
<ol>
<li>Faster than BP, SVM and other ELMs and compatible to regreesion and classification problems.</li>
<li>The regularized parameter C do not affect the generalization performance of this method.</li>
<li>This method with m hidden nodes (the desired output dimensionality) can achieve better training accuracy than the original ELM with a large number of hidden nodes.</li>
</ol>
</li>
</ul>
<h2 id="-definitions-and-basic-elm">â…¡. Definitions and Basic-ELM
</h2><h3 id="a-notations-and-definitions">A. Notations and Definitions
</h3><ul>
<li>
<p>ğ‘ : set of real numbers</p>
</li>
<li>
<p>{(ğ±áµ¢,ğ­áµ¢)}áµ¢â‚Œâ‚á´º : N arbitrary distinct samples,</p>
</li>
<li>
<p>ğ±áµ¢ = [xáµ¢â‚,xáµ¢â‚‚,&hellip;,xáµ¢â‚™]áµ€ : n-dim input data, ğ±áµ¢âˆˆ ğ‘â¿ is a column vector;</p>
</li>
<li>
<p>ğ­áµ¢ : m-dim desired output data, ğ­áµ¢âˆˆ ğ‘áµ</p>
</li>
<li>
<p>ğ± : input data matrix, ğ±=[ğ±â‚,&hellip;ğ±_N], ğ±áµ¢âˆˆ ğ‘â¿á•á´º</p>
</li>
<li>
<p>ğ­ : desired output data matrix, ğ­=[ğ­â‚,&hellip;ğ­_N], ğ­âˆˆ ğ‘áµá•á´º</p>
</li>
<li>
<p>(^ğšâ‚™,^bâ‚™) : parameters of the ğ‘›th subnetwork hidden node, ^ğšâ‚™âˆˆ ğ‘â¿á•áµ, ^bâ‚™âˆˆ ğ‘ (suppose the number of hidden nodes equals to the output dimension m, thus the mapping is from n to m.)</p>
</li>
<li>
<p>^ğšâ‚™ = [ğšâ‚™â‚,&hellip;,ğšâ‚™â‚˜], nÃ—m weights matrix (for a n-dimension sample ğ±áµ¢), ğšâ‚™â‚˜âˆˆ ğ‘â¿</p>
</li>
<li>
<p>ğâ‚™ : residual error of current network output ğ‘“â‚™ with  ğ‘› hidden nodes (for N samples),
i.e., ğâ‚™=ğ­-ğ‘“â‚™, ğâ‚™âˆˆ ğ‘áµá•á´º.</p>
</li>
<li>
<p>ğ‡ : output matrix of the hidden layer (of SLFN) for tarining set {(ğ±áµ¢,ğ­áµ¢)}áµ¢â‚Œâ‚á´º,
ğ‡ = [h(ğ±â‚),&hellip;,h(ğ±_N)]áµ€, ğ‡âˆˆ ğ‘á´ºá•áµ, ğ‡ = g(ğ±áµ€ğš+ğ›)???</p>
</li>
<li>
<p>h(ğ±) : activation function. <del>ELM feature mapping (or Huang&rsquo;s transform)</del></p>
</li>
<li>
<p>ğ‡áµ¢ : the ğ‘–th hidden node output w.r.t. inputs, i.e., the ğ‘–th column of ğ‡</p>
</li>
<li>
<p>ğˆ : unit matrix</p>
</li>
<li>
<p>sum(ğ) : the sum of all elements of the matrix ğ</p>
</li>
</ul>
<h3 id="b-basic-elm">B. Basic-ELM
</h3><p>ELM is proposed for single-hidden-layer feedforward networks (SLFNs).</p>
<ul>
<li>
<p>The output function of ELM with L hidden nodes for SLFNs is:</p>
<p>$ğ‘“\_L(ğ±)$ = âˆ‘áµ¢â‚Œâ‚á´¸ Î²áµ¢â‹…h(ğšáµ¢â‹…ğ±â±¼ + báµ¢) = âˆ‘áµ¢â‚Œâ‚á´¸ ğ‡áµ¢â‹…ğ›ƒáµ¢, j=1,&hellip;,N.</p>
<p>where h(â‹…) denotes an activation function, (ğšáµ¢, báµ¢), ğšáµ¢âˆˆ ğ‘â¿, báµ¢âˆˆ ğ‘, denotes the ith hidden node parameters, and ğ›ƒáµ¢ is the ith output weight between the ith hidden node and the output nodes.</p>
</li>
<li>
<p>Based on Bartlett&rsquo;s theory, ELM theory aims to reach not only the smallest training error, but also the smallest norm of output weights
(Least square-least norm solution, where the regularization <a class="link" href="http://blog.zichen.uk/post/writenotes/calc/pseudo_inverse/" >makes an invertible matrix</a>, such that a special solution can be determined.):</p>
<p>Minimize: â€–ğ›ƒâ€–Â² + Câ‹…â€–ğ‡ğ›ƒ - ğ­â€–Â²</p>
<p>&ldquo;then the generalization performance depends on the size of weights rather than the number of nodes.&rdquo;</p>
</li>
</ul>
<blockquote>
<p><strong>Lemma 1</strong> (proved by Huang):<br>
Given an SLFN with nonconstant piecewise continuous hidden nodes ğ‡(ğ±, ğš, b),
then for any continuous target function ğ‘“ and any function sequence ğ‡â‚™Ê³(ğ±) = ğ‡(ğ±, ğšâ‚™, bâ‚™) randomly generated based on any continuous sampling distribution,</p>
<p>lim$\_{nââˆ}$ â€–ğ‘“ - (ğ‘“â‚™â‚‹â‚ + ğ‡â‚™Ê³â‹…ğ›ƒâ‚™)â€– = 0</p>
<p>holds with probabitliy 1 if: <br>
ğ›ƒâ‚™ = âŸ¨ğâ‚™â‚‹â‚, ğ‡â‚™Ê³âŸ© / â€–ğ‡â‚™Ê³â€–Â² (the weight of the ğ‘›th node)</p></blockquote>
<p>where</p>
<ul>
<li>&ldquo;âŸ¨ , âŸ©&rdquo; stands for &ldquo;dot product&rdquo; (<a class="link" href="https://en.wikipedia.org/wiki/Frobenius_inner_product"  target="_blank" rel="noopener"
    >Frobenius inner product</a>) of two matrices and is a scalar.</li>
<li>n is the number of hidden nodes in the hidden layer.</li>
<li>ğâ‚™â‚‹â‚ is the residual error of the last iteration, i.e., when there were n-1 hidden nodes.</li>
<li>ğ‡â‚™Ê³ is the output matrix of the current hidden layer (activated but havn&rsquo;t scaled by ğ›ƒ).</li>
</ul>
<p>Intuitively, as the residual error reduces, the weight of the newer node gets smaller.</p>
<h2 id="-proposed-elm-method-with-subnetwork-hidden-nodes">â…¢. Proposed ELM Method With Subnetwork Hidden Nodes
</h2><h3 id="a-structure-of-the-proposed-method">A. Structure of the Proposed Method
</h3><p><strong>Motivations</strong>:</p>
<ol>
<li>Selecting an appropriate number of neurons can resort to optimization algorithms.</li>
<li>The generalization performance depends on the size of the weights rather than the number of weights.</li>
</ol>
<p><strong>Inspiration</strong>:</p>
<p>&ldquo;A hidden node itself can be a subnetwork formed by several nodes.
And these <strong>subnetwork hidden nodes</strong> and output weights itself should be the smallest norm, and also aim to reach the smallest training error.&rdquo;</p>
<p><strong>Objectives</strong>:</p>
<p>Given N training samples {(ğ±áµ¢,ğ­áµ¢)}áµ¢â‚Œâ‚á´º, ğ±áµ¢âˆˆ ğ‘â¿, ğ­áµ¢âˆˆ ğ‘áµ, generated from the same continuous system,
if activation function h is invertible, the objectives are:</p>
<ol>
<li>â€–ğâ‚™â‚‹â‚â€– â‰¥ â€–ğâ‚™â‚‹â‚ - h(^ğšâ‚™,ğ±)â€– â‰¥ â€–ğâ‚™â‚‹â‚ - ğ‡â‚™â€– â‰¥ â€–ğâ‚™â‚‹â‚ - ğ‡â‚™â‹…ğ›ƒâ‚™â€– (residual error is decreasing.)</li>
<li>â€–h(^ğšâ‚™,ğ±) - ğâ‚™â‚‹â‚â€– = min_{ğšâ‚™â‚,&hellip;,ğšâ‚™â‚˜} â€–h(ğšâ‚™â‚,&hellip;,ğšâ‚™â‚˜) - ğâ‚™â‚‹â‚â€–  (minimize weights inside nodes)</li>
<li>â€–ğ‡â‚™â‹…^ğ›ƒâ‚™ - ğâ‚™â‚‹â‚â€– = min_{ğ›ƒ} â€–ğ‡â‚™â‹…ğ›ƒ - ğâ‚™â‚‹â‚â€–   (minimize the weights outside nodes)</li>
</ol>
<p>where</p>
<ul>
<li>^ğšâ‚™ and ^ğ›ƒâ‚™ are the optimal (the ultimate status) parameters with the smallest norm among all the least squares solutions.</li>
<li>ğ‡â‚™ = h(^ğšâ‚™, ^bâ‚™, ğ±) is the output of the nth hidden node with the optimal parameters.</li>
</ul>
<p>If activation function h is invertible, subnetwork hidden nodes in SLFN can be calculated by pulling back network residual error to hidden layers.</p>
<ul>
<li>
<p>For example, with sine function as the activation function, training a subnetwork hidden node (^ğš) is equivalent to finding a least-square solution ^ğšâ‚™ (letting the derivative of MSE=0) with the least norm for the linear system:</p>
<p>[ğšâ‚™â‚,&hellip;,ğšâ‚™â‚˜]â‹…ğ± = arcsin(ğâ‚™â‚‹â‚), ğâ‚™â‚‹â‚âˆˆ (0,1],</p>
<p>such that the optimal ^ğšâ‚™ satifies:</p>
<p>â€–sin(^ğšâ‚™, ğ±) - ğâ‚™â‚‹â‚â€– = min_{ğšâ‚™â‚,&hellip;,ğšâ‚™â‚˜} â€–sin(ğšâ‚™â‚,&hellip;,ğšâ‚™â‚˜, ğ±) - ğâ‚™â‚‹â‚â€–,</p>
<p>That means the output of the nth &ldquo;subnetwork hidden node&rdquo; ^ğšâ‚™ is approaching the residual error ğâ‚™â‚‹â‚ of the last status.</p>
<p>The input weights ^ğšâ‚™ of a node for this model is a matrix (instead of a vector), beacuse each &ldquo;subnetwork (general) hidden node&rdquo; <strong>contains a standard SLFN</strong> (several hidden nodes) internally.</p>
</li>
</ul>
<p><strong>Differences with standard ELM</strong></p>
<div class="table-wrapper"><table>
  <thead>
      <tr>
          <th></th>
          <th>ELM with subnetwork</th>
          <th>standard ELM</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>hidden node</td>
          <td>m neurons: $ğš_fâˆˆ ğ‘â¿á•áµ, ğ›_fâˆˆ ğ‘áµ$</td>
          <td>single neuron:<br> ğšâˆˆ ğ‘â¿, bâˆˆ ğ‘</td>
      </tr>
      <tr>
          <td>construct</td>
          <td>calculated</td>
          <td>generated randomly</td>
      </tr>
      <tr>
          <td># hidden nodes</td>
          <td>L x m (m âŸ‚ L, m = #output dim)</td>
          <td>L</td>
      </tr>
  </tbody>
</table></div>
<h3 id="b-proposed-method">B. Proposed Method
</h3><blockquote>
<p><strong>Lemma 2</strong>: <br>
Given a bounded nonconstant piecewise continuous activation function h, there is: <br>
lim$\_{(ğš,b)â†’(ğšâ‚€,bâ‚€)}$ â€–h(ğšâ‹…ğ±+b) - h(ğšâ‚€â‹…ğ±+bâ‚€)â€– = 0 (è¿ç»­æ€§)</p></blockquote>
<blockquote>
<p><strong>Theorem 1</strong>: <br>
Given N arbitrary distinct samples {(ğ±áµ¢,ğ­áµ¢)}áµ¢â‚Œâ‚á´º, ğ±áµ¢âˆˆ ğ‘â¿, ğ­áµ¢âˆˆ ğ‘áµ, a sigmoid or sine activation function h, and then for any continuous desired outputs ğ­, the limit of error converges to 0:</p>
<p>lim$\_{nââˆ}$ â€– ğ­-{ uâ»Â¹(h(^ğšâ‹…ğ±+b))} â€– = 0</p></blockquote>
<p><strong>Proof</strong>:</p>
<ul>
<li>
<p>Prove the sequence â€–ğâ‚™â€– is decreasing with 0 as the lower bound and it converges.</p>
<ol>
<li>
<p>For the ğ‘›th subnetwork hidden node containing m hidden nodes, the linear mapping is:</p>
<p>ğ›Œâ‚™ = [ğšâ‚™â‚,&hellip;,ğšâ‚™â‚˜]â‹…ğ±, ğ›Œâ‚™âˆˆ ğ‘áµ</p>
</li>
<li>
<p>Then ğ›Œâ‚™ passes through the activation function. Because the target is error, which should become 0 at the end, the error at present is the output of activation function:</p>
<p>ğâ‚™â‚‹â‚ = h(ğ›Œâ‚™) âˆˆ ğ‘áµ</p>
</li>
<li>
<p>The inverse function of h is hâ»Â¹, and its input value should range from (0,1].
Therefore, if trying to solve ğ›Œâ‚™ from ğâ‚™â‚‹â‚, every element in ğâ‚™â‚‹â‚ should be scaled to the range of (0,1] by the normalized function u(â‹…). Then, ğ›Œâ‚™ can be calculated through:</p>
<p>ğ›Œâ‚™ = hâ»Â¹(u(ğâ‚™â‚‹â‚))</p>
</li>
<li>
<p>Further, the input weights of this subnetwork hidden node can be solved:</p>
$$\\^ğšâ‚™ = [ğšâ‚™â‚,...,ğšâ‚™â‚˜] = hâ»Â¹(u(ğâ‚™â‚‹â‚))â‹…ğ±â»Â¹$$</li>
<li>
<p>For different activation functions, there will be:</p>
$$\rm \\{^{\\^ğšâ‚™ = arcsin(u(ğâ‚™â‚‹â‚))â‹…ğ±â»Â¹,\quad sine}
        \_{\\^ğšâ‚™ = -log( (1/u(ğâ‚™â‚‹â‚)) - 1)â‹…ğ±â»Â¹,\quad sigmoid}$$</li>
</ol>
<p>(This work is a continuation on ELM, that is once the ğ›ƒ calculated based on target ğ­ and ğ‡â»Â¹, the residual error is also fixed, so it serves as the target for ğš,b.
Still, applying least-square, the optimial a can be calculated based on &ldquo;target&rdquo; e and ğ±â»Â¹.)</p>
<ol start="6">
<li>
<p>^b is the mean of hidden nodes.</p>
</li>
<li>
<p>The error can be reduced by adding the bias</p>
</li>
<li>
<p>Do feedforward using the calculated ^ğšâ‚™ and ^bâ‚™, so this time the output of the hidden layer is:</p>
$$\\^ğ‡â‚™áµ‰ = uâ»Â¹(h(\\^ğšâ‚™â‹…ğ±+\\^bâ‚™))$$<p>Because ğâ‚™â‚‹â‚ is the last output of the activation fuction, ğâ‚™â‚‹â‚ and $\\^ğ‡â‚™áµ‰$ are the same things.
So they can subtract from each other. Then the residual error for this time is:</p>
<p>Î” = â€–ğâ‚™â‚‹â‚â€–Â² - â€–ğâ‚™â‚‹â‚ - ^ğ‡â‚™áµ‰â€–Â² <br>
= â€–ğâ‚™â‚‹â‚â€–Â² - (â€–ğâ‚™â‚‹â‚â€–Â² - 2â€–ğâ‚™â‚‹â‚â€–â€–^ğ‡â‚™áµ‰â€– + â€–^ğ‡â‚™áµ‰â€–Â²) <br>
= 2â€–ğâ‚™â‚‹â‚â€–â€–^ğ‡â‚™áµ‰â€– - â€–^ğ‡â‚™áµ‰â€–Â² <br>
= 2âŸ¨ğâ‚™â‚‹â‚, ^ğ‡â‚™áµ‰âŸ© - â€–^ğ‡â‚™áµ‰â€–Â² <br>
= â€–^ğ‡â‚™áµ‰â€–Â² ( 2âŸ¨ğâ‚™â‚‹â‚, ^ğ‡â‚™áµ‰âŸ©/â€–^ğ‡â‚™áµ‰â€–Â² - 1 )</p>
</li>
<li>
<p>Î” is â‰¥ 0</p>
</li>
</ol>
</li>
<li>
<p>Prove the limit converges to 0 when n tends to infinity.</p>
</li>
</ul>
<p>The target value is approximated while the error is decreased.</p>
<p>The final estimation is the summation of the ouput of d subnetwork hidden nodes</p>
<p>The VC dimension is lower than standard ELM, i.e., the dimension of feature space mâ‰ª L, so the generalization ability of this method is better.</p>
<p><a class="link" href="#abstract" >(Back to top)</a></p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/slfn/">SLFN</a>
        
    </section>


    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
	const mainArticleElement = document.querySelector(".main-article");
        renderMathInElement(mainArticleElement, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>

    

    

    


    

    


    
    


    
    


    
    

    

    


</article>



    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/post/writenotes/model/subnetwork/b-note-elm-mltlyr/">
        
        

        <div class="article-details">
            <h2 class="article-title">Read: Optim - SLFN | Multilayer SNN</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2025 Zichen Wang
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.29.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
