<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Shapes on Zichen Wang</title>
        <link>http://blog.zichen.uk/post/writenotes/model/shapes/</link>
        <description>Recent content in Shapes on Zichen Wang</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Thu, 13 Jul 2023 18:00:00 +0000</lastBuildDate><atom:link href="http://blog.zichen.uk/post/writenotes/model/shapes/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>watch: Jun Gao | ML for 3D content generation</title>
        <link>http://blog.zichen.uk/post/writenotes/model/shapes/%E9%AB%98%E8%B4%A8%E9%87%8F3d%E5%86%85%E5%AE%B9%E5%88%9B%E9%80%A0-%E9%AB%98%E4%BF%8A/</link>
        <pubDate>Thu, 13 Jul 2023 18:00:00 +0000</pubDate>
        
        <guid>http://blog.zichen.uk/post/writenotes/model/shapes/%E9%AB%98%E8%B4%A8%E9%87%8F3d%E5%86%85%E5%AE%B9%E5%88%9B%E9%80%A0-%E9%AB%98%E4%BF%8A/</guid>
        <description>&lt;p&gt;Source video: &lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1mo4y1A7it&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;英伟达高俊: AI高质量三维内容生成（内容生成系列【一】）&lt;/a&gt;
北京智源大会2023 视觉与多模态大模型&lt;/p&gt;
&lt;h2 id=&#34;the-representation-of-3d-objects&#34;&gt;The representation of 3D objects
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Implicit field is in favor of neural network, where it can be optimized by gradient.&lt;/li&gt;
&lt;li&gt;mesh can achieve real-time rendering and is handy for downstream creation, and good topology.&lt;/li&gt;
&lt;li&gt;Marching cube is not fully differentiable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DMTet: A differentiable iso-surfacing is an implict field, and also a mesh.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An field where only the location at surface has value?&lt;/li&gt;
&lt;li&gt;a field only has one mesh?&lt;/li&gt;
&lt;li&gt;Diff-render&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2d-images-supervise-3d-generation&#34;&gt;2D images supervise 3D generation
&lt;/h2&gt;&lt;p&gt;2D GAN advantages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;various discriminator architecture&lt;/li&gt;
&lt;li&gt;powerful generator&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;GAN3D&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The latent codes of geometry and texture are sampled from 3D gaussian as prior&lt;/li&gt;
&lt;li&gt;3D generator: Tri-plane consistute the implicit field.&lt;/li&gt;
&lt;li&gt;Get a mesh by DMTet from the generated geometry and texture, then render it to 2D image&lt;/li&gt;
&lt;li&gt;Use GAN to discriminate if the render is real and backward the gradient of loss&lt;/li&gt;
&lt;li&gt;Limitation: class label conditioned. One model can only can generate 1 category of objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;text-prompts-generate-3d-objects&#34;&gt;Text prompts generate 3D objects
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;2D diffusion used &lt;strong&gt;socre function&lt;/strong&gt; to encourage high-fadality images&lt;/li&gt;
&lt;li&gt;score function needs a full image, but NeRF are trained batch-by-batch of rays, not a full image.&lt;/li&gt;
&lt;li&gt;Dream fusion can only render 64x64 images, so its geometry is low-quality.&lt;/li&gt;
&lt;li&gt;Coarse to fine: Use instant-ngp generate a rough geometry based on low-resolution diffusion model， then use DMTet convert the geometry to mesh;
So that a highe-resolution image can be rendered, which can offer a &lt;strong&gt;strong&lt;/strong&gt; gradient for fine geometry&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;future-work&#34;&gt;Future work
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;a universal model can generate any category of objects.&lt;/li&gt;
&lt;li&gt;composite objects to form a scene&lt;/li&gt;
&lt;li&gt;dynamic objects&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Watch: 215-智能三维内容生成</title>
        <link>http://blog.zichen.uk/post/writenotes/model/shapes/215-%E8%A7%86%E8%A7%89%E4%B8%93%E9%A2%98%E6%99%BA%E8%83%BD%E4%B8%89%E7%BB%B4%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90--%E9%87%8D%E5%BB%BA%E4%B8%8E%E5%88%9B%E9%80%A0-kangxue-yin/</link>
        <pubDate>Fri, 07 Jan 2022 22:22:00 +0000</pubDate>
        
        <guid>http://blog.zichen.uk/post/writenotes/model/shapes/215-%E8%A7%86%E8%A7%89%E4%B8%93%E9%A2%98%E6%99%BA%E8%83%BD%E4%B8%89%E7%BB%B4%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90--%E9%87%8D%E5%BB%BA%E4%B8%8E%E5%88%9B%E9%80%A0-kangxue-yin/</guid>
        <description>&lt;p&gt;title: &amp;ldquo;3D Content Creation and Stylization with AI&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Source link: &lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1mZ4y1U7ns/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GAMES Webinar 215-视觉专题：智能三维内容生成&amp;ndash;重建与创造-Kangxue Yin&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;3d内容创作&#34;&gt;3D内容创作：
&lt;/h2&gt;&lt;p&gt;游戏，电影特效，动画，VR/AR，专业化程度高（建模软件）&lt;/p&gt;
&lt;p&gt;动画电影创作流程:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://blog.zichen.uk/post/writenotes/model/shapes/215-%E8%A7%86%E8%A7%89%E4%B8%93%E9%A2%98%E6%99%BA%E8%83%BD%E4%B8%89%E7%BB%B4%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90--%E9%87%8D%E5%BB%BA%E4%B8%8E%E5%88%9B%E9%80%A0-kangxue-yin/215-3D%E5%8A%A8%E7%94%BB%E7%94%B5%E5%BD%B1%E5%88%9B%E4%BD%9C%E6%B5%81%E7%A8%8B_4_55.png&#34;
	width=&#34;1216&#34;
	height=&#34;810&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;剧本&lt;/li&gt;
&lt;li&gt;原画&lt;/li&gt;
&lt;li&gt;Layout: 物体相机摆放，位置关系&lt;/li&gt;
&lt;li&gt;特效技术研发&lt;/li&gt;
&lt;li&gt;2D 建模为3D&lt;/li&gt;
&lt;li&gt;纹理&lt;/li&gt;
&lt;li&gt;绑定骨骼，皮肤，相对运动关系&lt;/li&gt;
&lt;li&gt;人物运动（运动捕捉）&lt;/li&gt;
&lt;li&gt;VFX 特效模拟（爆炸）&lt;/li&gt;
&lt;li&gt;打光&lt;/li&gt;
&lt;li&gt;渲染(物理仿真)&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;梦工厂pipeline：https://www.youtube.com/watch?v=ru0tQRJ4qKs&lt;/p&gt;
&lt;p&gt;3D 内容成本高：2009 阿凡达（3D） $ 2.37亿 ，而 2010年的2D电影 让子弹飞 只有 $ 0.18亿&lt;/p&gt;
&lt;p&gt;元宇宙需要大量3D 内容&lt;/p&gt;
&lt;p&gt;降低3D内容制作成本：让普通玩家参与创作（房子，汽车&amp;hellip;）NFT，未经训练，细节不足，风格不够多样，用人工智能辅助。&lt;/p&gt;
&lt;h2 id=&#34;research-works&#34;&gt;Research works
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape&lt;/p&gt;
&lt;p&gt;输入 voxel 模型，网络合成细节。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;3D represention 选择&lt;/p&gt;
&lt;p&gt;Discrete Repre&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://blog.zichen.uk/post/writenotes/model/shapes/215-%E8%A7%86%E8%A7%89%E4%B8%93%E9%A2%98%E6%99%BA%E8%83%BD%E4%B8%89%E7%BB%B4%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90--%E9%87%8D%E5%BB%BA%E4%B8%8E%E5%88%9B%E9%80%A0-kangxue-yin/215-%E7%A6%BB%E6%95%A3%E8%A1%A8%E7%A4%BA%E6%9C%89%E7%BC%BA%E7%82%B9_11-31.png&#34;
	width=&#34;1216&#34;
	height=&#34;810&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Implicit Fields:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://blog.zichen.uk/post/writenotes/model/shapes/215-%E8%A7%86%E8%A7%89%E4%B8%93%E9%A2%98%E6%99%BA%E8%83%BD%E4%B8%89%E7%BB%B4%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90--%E9%87%8D%E5%BB%BA%E4%B8%8E%E5%88%9B%E9%80%A0-kangxue-yin/215-%E9%9A%90%E5%90%AB%E5%9C%BA%E7%9A%84%E7%BC%BA%E7%82%B9_13-18.png&#34;
	width=&#34;1216&#34;
	height=&#34;810&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;生成网络细节不足，转换为mesh有问题&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://blog.zichen.uk/post/writenotes/model/shapes/215-%E8%A7%86%E8%A7%89%E4%B8%93%E9%A2%98%E6%99%BA%E8%83%BD%E4%B8%89%E7%BB%B4%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90--%E9%87%8D%E5%BB%BA%E4%B8%8E%E5%88%9B%E9%80%A0-kangxue-yin/215-%E6%8A%8A%E9%9A%90%E5%BC%8F%E6%96%B9%E7%A8%8B%E8%BD%AC%E5%8C%96%E4%B8%BA%E6%98%BE%E5%BC%8F%E8%A1%A8%E9%9D%A2_14-06.png&#34;
	width=&#34;1216&#34;
	height=&#34;810&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;differentiable iso-surfacing 把隐式方程转化为一个mesh，然后用 mesh 和 ground truth 之间的差（loss）来优化网络，降低 iso-surfacing 离散化带来的误差，其中使用的不是 Marching cube 而是 Marching Tetrahedra&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://blog.zichen.uk/post/writenotes/model/shapes/215-%E8%A7%86%E8%A7%89%E4%B8%93%E9%A2%98%E6%99%BA%E8%83%BD%E4%B8%89%E7%BB%B4%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90--%E9%87%8D%E5%BB%BA%E4%B8%8E%E5%88%9B%E9%80%A0-kangxue-yin/215-Marching_Tetra_15-33.png&#34;
	width=&#34;1216&#34;
	height=&#34;810&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3DStyleNet: Creating&lt;/p&gt;
&lt;p&gt;3D 物体的风格迁移&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
