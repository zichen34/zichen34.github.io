<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Diffusion models on Zichen Wang</title>
        <link>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/</link>
        <description>Recent content in Diffusion models on Zichen Wang</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sat, 04 Nov 2023 16:30:00 +0000</lastBuildDate><atom:link href="http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Sympo: Diffusion | Misc</title>
        <link>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/c-symp-misc/</link>
        <pubDate>Sat, 04 Nov 2023 16:30:00 +0000</pubDate>
        
        <guid>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/c-symp-misc/</guid>
        <description>&lt;img src="https://miro.medium.com/v2/resize:fit:1358/0*hRF_dQv3uSGuS_IU.gif" alt="Featured image of post Sympo: Diffusion | Misc" /&gt;&lt;p&gt;Feature image from: &lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/understanding-diffusion-probabilistic-models-dpms-1940329d6048&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Understanding Diffusion Probabilistic Models (DPMs) | by Joseph Rocca - Medium&lt;/a&gt;
(&lt;small&gt;
Searched by &lt;code&gt;diffusion model&lt;/code&gt; in &lt;a class=&#34;link&#34; href=&#34;https://duckduckgo.com/?q=diffusion&amp;#43;model&amp;amp;iax=images&amp;amp;ia=images&amp;amp;iaf=size%3AMedium%2Clayout%3ASquare&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DDG image&lt;/a&gt;
&lt;/small&gt;)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;collections&#34;&gt;Collections
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a id=&#34;&#34;&gt;&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/moatifbutt/awesome-diffusion-iclr-2025&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;moatifbutt/awesome-diffusion-iclr-2025 - GitHub&lt;/a&gt;
&lt;small&gt;
&lt;ul&gt;
&lt;li&gt;Surfaced when searching the paper of IC-Light in
&lt;a id=&#34;s1-241201&#34;&gt;&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://duckduckgo.com/?q=Scaling&amp;#43;In-the-Wild&amp;#43;Training&amp;#43;for&amp;#43;Diffusion-based&amp;#43;Illumination&amp;#43;Harmonization&amp;#43;and&amp;#43;Editing&amp;#43;by&amp;#43;Imposing&amp;#43;Consistent&amp;#43;Light&amp;#43;Transport&amp;amp;ia=web&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DDG&lt;/a&gt;
&lt;/small&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Variational Diffusion Models&lt;/strong&gt;
~ NIPS 2021&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2107.00630&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Arxiv&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(2023-11-04)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SyncDreamer: Generating Multiview-consistent Images from a Single-view Image&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/liuyuan-pal/SyncDreamer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Code&lt;/a&gt;
| &lt;a class=&#34;link&#34; href=&#34;https://liuyuan-pal.github.io/SyncDreamer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ProjPage&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion Model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://diffusion-vision.github.io/dmd/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ProjPage&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(2023-12-26)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DM for single-image depth estimation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;nerf&#34;&gt;NeRF
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1Zh4y157K8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ã€Diffusionç”ŸæˆNeRFã€‘TUM, Appleæå‡ºHyperDiffusionï¼Œç”¨Diffusionè®¡ç®—ç¥ç»åœºæƒé‡ï¼Œç»Ÿä¸€æ¡†æ¶ä¸‹ç”Ÿæˆ3Dæƒé‡æˆ–4DåŠ¨ç”»&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(2023-07-16)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use DM to generate a NeRF.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Comment: &amp;ldquo;æ€è·¯ä¸å¦‚ shapE å®½ã€‚shapEçš„encoderä¸ä»…æŠŠ3d assetså‹ç¼©ä¸ºMLPï¼Œ
è€Œä¸”åŒæ—¶æ”¯æŒNerfå’ŒDMTetçš„è¡¨å¾ï¼Œåœ¨MLPä¸Šåšdiffusionè¿˜æ˜¯conditionalçš„ã€‚è¿™ç¯‡æ–‡ç« ç›¸æ¯”èµ·æ¥è¿˜ä¸å¤ªæ¸…æ¥šå–ç‚¹åœ¨å“ª&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;rcg&#34;&gt;RCG
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Self-conditioned Image Generation via Generating Representations&lt;/em&gt;
&lt;a class=&#34;link&#34; href=&#34;github.com/LTH14/rcg&#34; &gt;Code&lt;/a&gt;
| &lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1CG411Y72q/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;brief&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(2023-12-30)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The distribution of image is learned by a pre-trained encoder, used as the condition for image generation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Representative Diffusion model: Sampling from the representation distribution&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pixel generater: convert samples to pixel&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;FID (Frechet Inception Distance): 3.31, IS (Inception score): 253.4&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2d-to-3d&#34;&gt;2D to 3D
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MVDD: Multi-View Depth Diffusion Models&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2312.04875&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Arxiv&lt;/a&gt;
| &lt;a class=&#34;link&#34; href=&#34;https://www.emergentmind.com/papers/2312.04875&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Emergent&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(2023-12-31)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use DM to generate multi-view &lt;strong&gt;depth maps&lt;/strong&gt; for point cloud generation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;20K+ points. The number of valid points may no larger than the resolution of an image,
because depth and geometry consistencies needs to be checked like the point cloud fusion performed in MVSNet.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Depth map fusion&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Epipolar attention affects the denosing steps.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huanngzh.github.io/EpiDiff/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Code&lt;/a&gt;
| &lt;a class=&#34;link&#34; href=&#34;https://www.emergentmind.com/papers/2312.06725&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Emergent&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(2023-12-31) (å¯èƒ½æ˜¯ ç¾è²Œä¸æ™ºæ…§å¹¶é‡ ä»–ä»¬åšçš„ï¼Œä»–åœ¨VAST?)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;DM conditioned by a single image for generating multi-view images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Restrict the frozen diffusion model with an epipolar cross-view attention&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reminds me MVDiffusion&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generate 16 multi-view images in 12 seconds&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the resolution?&lt;/li&gt;
&lt;li&gt;What is the device?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adjusting &lt;strong&gt;feature maps&lt;/strong&gt; to control image generation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No 3D geometry.
I believe &lt;strong&gt;explicit&lt;/strong&gt; structure is necessary for multi-view consistency especially in views with large-baselines.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;text-to-3d&#34;&gt;Text to 3D
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail Richness in Text-to-3D&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.emergentmind.com/papers/2311.16918&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Emergent&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(2024-01-05)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;generalizable Normal-Depth diffusion model,&lt;/li&gt;
&lt;li&gt;PBR&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;multi-view&#34;&gt;Multi-view
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cameras as Rays: Pose Estimation via Ray Diffusion&lt;/strong&gt;
~  ICLR 2024 (Oral)&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://jasonyzhang.com/RayDiffusion/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ProjPage&lt;/a&gt;
| &lt;a class=&#34;link&#34; href=&#34;https://github.com/jasonyzhang/RayDiffusion&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Code&lt;/a&gt;
| CMU&lt;/p&gt;
&lt;p&gt;(2024-03-01)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generate ray moments and ray directions by diffusion model.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;control&#34;&gt;Control
&lt;/h2&gt;&lt;h3 id=&#34;illumination-editing&#34;&gt;Illumination Editing
&lt;/h3&gt;&lt;h4 id=&#34;light-transport&#34;&gt;Light Transport
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a id=&#34;Ctrl-Illu-LT-r1&#34;&gt;&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://openreview.net/forum?id=u1cQYxRI1H&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Scaling In-the-Wild Training for Diffusion-based Illumination Harmonization and Editing by Imposing Consistent Light Transport - OpenReview&lt;/a&gt;
&lt;small&gt;
&lt;ul&gt;
&lt;li&gt;Surfaced by WeChat subscription:
&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/ZoEXu18ZzAjUFnYsP7JGwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ICLR æƒŠç° 10,10,10,10 æ»¡åˆ†è®ºæ–‡ï¼ŒControlNet ä½œè€…æ–°ä½œï¼ŒGithub 5.8k é¢—æ˜Ÿ - æœºå™¨ä¹‹å¿ƒ&lt;/a&gt;
&lt;/small&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id=&#34;Ctrl-Illu-LT-r2&#34;&gt;&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://lllyasviel.github.io/Style2PaintsResearch/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Style2Paints Research Lvmin Zhang (Lyumin Zhang)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Training Model From Scratch&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;(2024-12-01)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;IC-Light&lt;/strong&gt; &lt;sup&gt;&lt;a class=&#34;link&#34; href=&#34;Ctrl-Illu-LT-r1&#34; &gt;r1-OpenReview&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Related&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://openreview.net/pdf?id=u1cQYxRI1H&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Pdf&lt;/a&gt;:
Lvmin Zhang&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/lllyasviel/IC-Light&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;lllyasviel/IC-Light&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasons&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;This paper draw my attention as it involves &lt;strong&gt;light transportation&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Q&amp;amp;A&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;How does this method combine with Light Transport?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Is the training process similar to NeRF, which integrated &lt;strong&gt;differentiable rendering&lt;/strong&gt; into the
&amp;ldquo;pipeline to fulfill the task&amp;rdquo;, i.e., volumetric rendering.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bonds&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;in-the-wild data&amp;rdquo;&lt;/strong&gt; reminds me &lt;em&gt;NeRF-in-the-wild&lt;/em&gt;,
which separates &lt;strong&gt;transient and consistant&lt;/strong&gt; contents using two gates.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;linear blending&amp;rdquo;&lt;/strong&gt; of lighting effects under each single illumination condition.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Weighted sum, which the NN is good at.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I remember the word prompts to diffusion model have arithmatic characteristic,
demonstrated in the short course of DLAI (Andrew Ng).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Diffusion-baed&lt;/strong&gt; illumination editing method&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lvmin commits himself to help artists
&lt;sup&gt;&lt;a class=&#34;link&#34; href=&#34;#Ctrl-Illu-LT-r2&#34; &gt;r2-Paints&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ideas&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Inproper training constraints result in a &amp;ldquo;Structure-guided random image generator&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Complex illumination &amp;gt; Mixture of illumination &amp;gt; Approximated with $k$ diffusion model.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Can the Mixture of diffusion models be replaced with Gaussian mixture model?&lt;/p&gt;
&lt;p&gt;What are the similarity between the Mixture of diffusion models and Gaussian mixture model?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>watch: Diffusion - Outlier | Explain 4 papers</title>
        <link>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/d-vid-outlier/</link>
        <pubDate>Fri, 14 Jul 2023 21:00:00 +0000</pubDate>
        
        <guid>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/d-vid-outlier/</guid>
        <description>




  
  
  
  
   
  
  
   
  
  &lt;img src= /post/writenotes/model/imagen/diffusion/imgs/Outlier_Explain.jpg width=ZgotmplZ&gt;
  
  


&lt;ul&gt;
&lt;li&gt;Source Video: &lt;a class=&#34;link&#34; href=&#34;https://youtu.be/HoKDTa5jHvg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Diffusion Models | Paper Explanation | Math Explained - Outlier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code: &lt;a class=&#34;link&#34; href=&#34;https://github.com/dome272/Diffusion-Models-pytorch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;dome272/Diffusion-Models-pytorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;(2023-08-02)&lt;/p&gt;
&lt;h2 id=&#34;idea--theory&#34;&gt;Idea &amp;amp; Theory
&lt;/h2&gt;&lt;p&gt;Diffusion model is a generative model, so it learns the distribution of data ğ—.
(Discrimitive model learns labels.
And MLE is a strategy to determine the distribution through parameters ğš¯)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The essential idea is to systematically and slowly &lt;br&gt;
destroy structure in a &lt;strong&gt;data distribution&lt;/strong&gt; through &lt;br&gt;
an iterative forward diffusion process. We then &lt;br&gt;
learn a reverse diffusion process that restores &lt;br&gt;
structure in data, yielding a highly flexible and &lt;br&gt;
&lt;strong&gt;tractable&lt;/strong&gt; generative model of the data. [&lt;a class=&#34;link&#34; href=&#34;#2015&#34; &gt;1&lt;/a&gt;]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Forward diffusion process&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Sample noise from a normal distribution&lt;a class=&#34;link&#34; href=&#34;#2015&#34; &gt;Â¹&lt;/a&gt; and add it to an image iteratively,
until the original distribution of the image has been completely destroyed,
becoming the same as the noise distribution.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The noise level (mean, variance) of each timestep is scaled by a schedule to avoid the variance explosion along with adding more noise.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The image distribution should be destroyed slowly,
and the noise redundency at the end stage should be reduced.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OpenAI &lt;a class=&#34;link&#34; href=&#34;#2102&#34; &gt;Â³&lt;/a&gt; proposed Cosine schedule in favor of the Linear schedule in DDPM&lt;a class=&#34;link&#34; href=&#34;#2020&#34; &gt;Â²&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Reverse diffusion process&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Predict the noise of each step.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Do not predict the full image in one-shot because that&amp;rsquo;s intractable and results in worse results&lt;a class=&#34;link&#34; href=&#34;#2015&#34; &gt;Â¹&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Predicting the mean of the noise distribution and predicting the noise in the image directly are equivalent,
just being parameterized differently &lt;a class=&#34;link&#34; href=&#34;#2020&#34; &gt;Â²&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Predict noise directly, so it can be subtracted from image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The variance ÏƒÂ² of the normal distribution followed by the noise can be fixed&lt;a class=&#34;link&#34; href=&#34;#2020&#34; &gt;Â²&lt;/a&gt;.
But optimizing it together with the mean, the log-likehood will get improved &lt;a class=&#34;link&#34; href=&#34;#2102&#34; &gt;Â³&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;DDPM used UNet like model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multi-level downsample + resnet block â” Low-res feature maps â” Upsample to origianl size&lt;/li&gt;
&lt;li&gt;Concatenate RHS feature maps with the LHS feature maps of the same resolution to supplement the location information for features at each pixel.&lt;/li&gt;
&lt;li&gt;Attend some of LHS and RHS feature maps by attention blocks to fuse features further.&lt;/li&gt;
&lt;li&gt;Time embedding is added to each level of feature maps for &amp;ldquo;identifying&amp;rdquo; the consistent amount of noise to be predicted during a forward pass at a timestep.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OpenAI 2nd paper&lt;a class=&#34;link&#34; href=&#34;#2105&#34; &gt;(4)&lt;/a&gt; made improvement by modifying the model in:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Increase levels, reduce width;&lt;/li&gt;
&lt;li&gt;More attention blocks, more heads;&lt;/li&gt;
&lt;li&gt;BigGAN residual block when downsampling and upsampling;&lt;/li&gt;
&lt;li&gt;Adaptive Group Normalization after each resnet block: GroupNorm + affine transform ( Time embedding * GN + Label embedding)&lt;/li&gt;
&lt;li&gt;Classifier guidance is a separate classifier that helps to generate images of a certain category.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math-derivation&#34;&gt;Math Derivation
&lt;/h2&gt;&lt;p&gt;(2024-04-17)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VAE and diffuseion model both follows MLE strategy to find the parameter corresponding to the desired data distribution.&lt;/li&gt;
&lt;li&gt;VAE solves the dataset distribution P(ğ—) by approximating ELBO;&lt;/li&gt;
&lt;li&gt;While diffusion model solves the dataset distribution P(ğ—) by minimizing the KL Divergence.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;(2023-08-04)&lt;/p&gt;
&lt;h3 id=&#34;vae&#34;&gt;VAE
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;VAE also wants to get the distribution of dataset P(ğ—), and an ğ± is generated by a latent variable ğ³.&lt;/p&gt;
&lt;p&gt;Therefore, based on Bayes theorem, p(ğ±) = p(ğ³) p(ğ±|ğ³) / p(ğ³|ğ±), where p(ğ³) is the prior.&lt;/p&gt;
&lt;p&gt;And p(ğ³|ğ±) is &lt;strong&gt;intractable&lt;/strong&gt; because in p(ğ³|ğ±) = p(ğ³)p(ğ±|ğ³) / p(ğ±), the p(ğ±) can&amp;rsquo;t be computed through âˆ«f(ğ±,ğ³)dğ³ since ğ³ is high dimensional continuous.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;By introducing an approximated posterior q(ğ³|ğ±), log p(ğ±) = ELBO + KL-divergence.&lt;/p&gt;
&lt;p&gt;$log p(ğ±) = E_{q(ğ³|ğ±)} log \frac{p(ğ±,ğ³)}{q(ğ³|ğ±)} + âˆ« q(ğ³|ğ±) log \frac{q(ğ³|ğ±)}{p(ğ³)} dğ³$&lt;/p&gt;
&lt;p&gt;The KL-divergence can be integrated analytically.&lt;/p&gt;
&lt;p&gt;ELBO is an expectation w.r.t q(ğ³|ğ±), which can technically be estimated using Monte Carlo sampling directly.&lt;/p&gt;
&lt;p&gt;But when sampled q(ğ³â±|ğ±) is around 0, the variance of $log\ q(ğ³|ğ±)$ would be high and make its gradint unstable, then cause the optimization difficult.
And the function to be estimated $log(\frac{p_Î¸(ğ±,ğ³)}{q_Ï†(ğ³|ğ±)})$ involves two approximate models containing a lot error.&lt;/p&gt;
&lt;p&gt;Thus, it&amp;rsquo;s not feasible to approximate ELBO directly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To approximate ELBO, we analyse the &lt;strong&gt;generative model&lt;/strong&gt; (Decoder) p(ğ±|ğ³).&lt;/p&gt;
&lt;p&gt;Base on Bayes theorem, p(ğ±|ğ³) = p(ğ±) p(ğ³|ğ±)/p(ğ³).&lt;/p&gt;
&lt;p&gt;By introducing the posterior approximation q(ğ³|ğ±), p(ğ±|ğ³) can derive:
E(log p(ğ±|ğ³)) = ELBO + KL-divergence, i.e.,&lt;/p&gt;
&lt;p&gt;$E_{q(ğ³|ğ±)}[ log p(ğ±|ğ³)] = E_{q(ğ³|ğ±)}[ log(\frac{p(ğ³|ğ±) p(ğ±)}{q(ğ³|ğ±)})] + âˆ« q(ğ³|ğ±) log \frac{q(ğ³|ğ±)}{p(ğ³)} dğ³$&lt;/p&gt;
&lt;p&gt;Given ğ³, the likelihood p(ğ±|ğ³) is supposed to be maximized. (The probiblity that the real ğ± is sampled should be maximum.)&lt;/p&gt;
&lt;p&gt;Therefore, the parameters Î¸ of generative model p(ğ±|ğ³) should be optimized via &lt;strong&gt;MLE&lt;/strong&gt; (cross-entropy) loss.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now since ELBO = E(log p(ğ±|ğ³)) - KL-divergence and KL-div is known, ELBO will be obtained by just computing E(log p(ğ±|ğ³)).&lt;/p&gt;
&lt;p&gt;E(log p(ğ±|ğ³)) can be estimated by MC:
sample a ğ³ then compute log p(ğ±|ğ³), and repeat N times, take average.&lt;/p&gt;
&lt;p&gt;The approximated E(log p(ğ±|ğ³)) should be close to the original ğ±, so there is a &lt;strong&gt;MSE&lt;/strong&gt; loss to optimize the parameters Ï• of the distribution of ğ³.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(2023-10-30) ğ³&amp;rsquo;s distribution needs to be learned as well for sampling ğ±.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But MC sampling is not differentiable, so Ï• cannot be optimized through gradient descent.&lt;/p&gt;
&lt;p&gt;Therefore, reparameterization considers that ğ³ comes from a differentiable determinstic transform of Îµ, a random noise, i.e.,
ğ³ = Î¼ + ÏƒÎµ.&lt;/p&gt;
&lt;p&gt;Then, parameters (Î¼, ÏƒÂ²) of ğ³&amp;rsquo;s distribution (Encoder) will be optimized by MSE.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;forward-process&#34;&gt;Forward process
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The forward diffusion process is like the &amp;ldquo;Encoder&amp;rdquo; p(ğ³|ğ±) in VAE:&lt;/p&gt;
$$q(ğ³|ğ±) â‡’ q(ğ±â‚œ | ğ±â‚œâ‚‹â‚)$$&lt;p&gt;The distribution of image ğ±â‚œ at timestep t is determined by the image ğ±â‚œâ‚‹â‚ at the previous timestep, where smaller t means less noise.&lt;/p&gt;
&lt;p&gt;Specifically, ğ±â‚œ follows a normal distribution with a mean of $\sqrt{1-Î²â‚œ}ğ±â‚œâ‚‹â‚$ and a variance of $\sqrt{Î²â‚œ}ğˆ$:&lt;/p&gt;
$$q(ğ±â‚œ | ğ±â‚œâ‚‹â‚) = N(ğ±â‚œ; \sqrt{1-Î²â‚œ} ğ±â‚œâ‚‹â‚, \sqrt{Î²â‚œ}ğˆ)$$&lt;p&gt;ğ±â‚œ is similar to ğ±â‚œâ‚‹â‚ because its mean is around ğ±â‚œâ‚‹â‚.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An image ğ± is  a &amp;ldquo;vector&amp;rdquo;, and each element of it is a pixel.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As timestep t increase, Î²â‚œ increases and (1-Î²â‚œ) decreases, which indicates
the variance gets larger and the mean value gets smaller.&lt;/p&gt;
&lt;p&gt;Intuitively, the value of the original pixel xâ‚œâ‚‹â‚ is &lt;strong&gt;fading&lt;/strong&gt; and more pixels become outliers resulting in a wider range of variation around the mean.&lt;/p&gt;
&lt;script&gt;type=&#34;text/tikz&#34;
\begin{tikzpicture}[scale=1.5]
  \def\meanA{1}
  \def\sdA{0.5}
  \def\meanB{0.6}
  \def\sdB{0.9}
  \def\xmin{-2}
  \def\xmax{4}
  \def\ymin{-0.1}
  \def\ymax{0.8}

  \draw[-&gt;] (\xmin-.2,0) -- (\xmax+.2,0) node[right] {$x$};
  \draw[-&gt;] (0,\ymin-.1) -- (0,\ymax+.1) node[above] {$y$};

  \draw[domain=\xmin:\xmax,samples=100,smooth,variable=\x,blue] plot ({\x},{1/(\sdA*sqrt(2*pi))*exp(-((\x-\meanA)^2)/(2*\sdA^2))});

  \draw[dashed] (\meanA,\ymin) -- (\meanA,\ymax);

  \filldraw[black] (\meanA,\ymax) circle (1pt);

  \node[above right] at (\meanA,\ymax) {$f(\mu_A)=\frac{1}{\sigma_A\sqrt{2\pi}}$};

  \node[below right] at (\xmax,\ymin) {$f(x)=\frac{1}{\sigma_A\sqrt{2\pi}}e^{-\frac{(x-\mu_A)^2}{2\sigma_A^2}}$};

  \draw[domain=\xmin:\xmax,samples=100,smooth,variable=\x,red] plot ({\x},{1/(\sdB*sqrt(2*pi))*exp(-((\x-\meanB)^2)/(2*\sdB^2))});

  \draw[dashed] (\meanB,\ymin) -- (\meanB,\ymax);

  \filldraw[black] (\meanB,\ymax) circle (1pt);

  \node[above right] at (\meanB,\ymax) {$f(\mu_B)=\frac{1}{\sigma_B\sqrt{2\pi}}$};

  \node[below right] at (\xmax,\ymin) {$f(x)=\frac{1}{\sigma_B\sqrt{2\pi}}e^{-\frac{(x-\mu_B)^2}{2\sigma_B^2}}$};

\end{tikzpicture}
&lt;/script&gt;
&lt;script type=&#34;text/tikz&#34;&gt;
\begin{tikzpicture}[scale=1.2]
  % Background
  \fill [white] (-2.5,-0.5) rectangle (4.5,1.5); % Adjust the rectangle size if needed

  % Axes
  \draw[-&gt;] (-2.5,0) -- (4.5,0) node[below] {$x$};
  \draw[-&gt;] (0,0) -- (0,1.2) node[left] {$y$};

  % Red bell curve
  \draw[red, thick, smooth, domain=-2:4, samples=100]
      plot (\x, {exp(-((\x-1)^2)/(2*0.4^2))/(0.4*sqrt(2*pi))});

  % Blue bell curve
  \draw[blue, thick, smooth, domain=-2:4, samples=100]
      plot (\x, {exp(-((\x-0.7)^2)/(2*0.8^2))/(0.8*sqrt(2*pi))});

  % Axis labels
  \node[below] at (4,0) {$x$};
  \node[left] at (0,1) {$y$};

  % Legend
  \draw[red, thick] (0.2,-1.2) -- (1.2,-1.2) node[right] {$\mu=1, \sigma^2=0.4$};
  \draw[blue, thick] (0.2,-1.7) -- (1.2,-1.7) node[right] {$\mu=0.7, \sigma^2=0.8$};
\end{tikzpicture}
&lt;/script&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;By introducing a notation $Î± = 1-Î²â‚œ$, the t-step evolution from ğ±â‚€ to ğ±â‚œ can be simplied to a &lt;strong&gt;single expression&lt;/strong&gt; instead of sampling t times iteratively.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Replace (1-Î²â‚œ) with Î±, the distribution becomes:&lt;/p&gt;
&lt;p&gt;$q(ğ±â‚œ | ğ±â‚œâ‚‹â‚) = N(ğ±â‚œ; \sqrt{Î±â‚œ} ğ±â‚œâ‚‹â‚, (1-Î±â‚œ)ğˆ)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Based on the &lt;strong&gt;reparameterization trick&lt;/strong&gt;, a sample from the distribution is:&lt;/p&gt;
&lt;p&gt;$ğ±â‚œ = \sqrt{Î±â‚œ} ğ±â‚œâ‚‹â‚ + \sqrt{1-Î±â‚œ} Îµ$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Similarly, $ğ±â‚œâ‚‹â‚ = \sqrt{Î±â‚œâ‚‹â‚} ğ±â‚œâ‚‹â‚‚ + \sqrt{1-Î±â‚œâ‚‹â‚} Îµ$, and plug it into ğ±â‚œ.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then $ğ±â‚œ = \sqrt{Î±â‚œâ‚‹â‚} ( \sqrt{Î±â‚œ} ğ±â‚œâ‚‹â‚‚ + \sqrt{1-Î±â‚œâ‚‹â‚} Îµ ) + \sqrt{1-Î±â‚œ} Îµ$.
Now, the &lt;strong&gt;mean&lt;/strong&gt; becomes $\sqrt{Î±â‚œÎ±â‚œâ‚‹â‚} ğ±â‚œâ‚‹â‚‚$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Given variance = 1 - (mean/ğ±)Â² in the above normal distribution $N(ğ±â‚œ; \sqrt{Î±â‚œ} ğ±â‚œâ‚‹â‚, (1-Î±â‚œ)ğˆ)$,
and here mean = $\sqrt{Î±â‚œÎ±â‚œâ‚‹â‚} ğ±â‚œâ‚‹â‚‚$,&lt;/p&gt;
&lt;p&gt;the standard deviation should be $\sqrt{1 - Î±â‚œÎ±â‚œâ‚‹â‚}$, then ğ±â‚œ becomes:&lt;/p&gt;
&lt;p&gt;$ğ±â‚œ = \sqrt{Î±â‚œÎ±â‚œâ‚‹â‚} ğ±â‚œâ‚‹â‚‚ + \sqrt{1 - Î±â‚œÎ±â‚œâ‚‹â‚} Îµ$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeatedly substituting intermediate states, the ğ±â‚œ can be represented with ğ±â‚€ :&lt;/p&gt;
&lt;p&gt;$ğ±â‚œ = \sqrt{Î±â‚œÎ±â‚œâ‚‹â‚ ... Î±â‚} ğ±â‚€ + \sqrt{1 - Î±â‚œÎ±â‚œâ‚‹â‚ ... Î±â‚} Îµ$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Denote the cumulative product &amp;ldquo;Î±â‚œÎ±â‚œâ‚‹â‚ &amp;hellip; Î±â‚&amp;rdquo; as $\bar aâ‚œ$,
the ğ±â‚œ can be reached in one-shot.&lt;/p&gt;
&lt;p&gt;$ğ±â‚œ = \sqrt{\bar aâ‚œ} ğ±â‚€ + \sqrt{1 - \bar aâ‚œ} Îµ$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The distribution of ğ±â‚œ given ğ±â‚€ is:&lt;/p&gt;
&lt;p&gt;$q(ğ±â‚œ | ğ±â‚€) = N(ğ±â‚œ; \sqrt{\bar aâ‚œ} ğ±â‚€, (1 - \bar aâ‚œ)ğˆ)$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With this expression, the deterministic forward process is ready-to-use and only the reverse process needs to be learned by a network.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;That&amp;rsquo;s why in the formula below, they &amp;ldquo;reverse&amp;rdquo; the forward q(ğ±â‚œ|ğ±â‚œâ‚‹â‚) to q(ğ±â‚œâ‚‹â‚|ğ±â‚œ) resulting in the equation only containing &amp;ldquo;reverse process&amp;rdquo;: ğ±â‚œâ‚‹â‚|ğ±â‚œ,
which then can be learned by narrowing the gap between q(ğ±â‚œâ‚‹â‚|ğ±â‚œ) and p(ğ±â‚œâ‚‹â‚|ğ±â‚œ).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;reverse-process&#34;&gt;Reverse process
&lt;/h3&gt;&lt;p&gt;The reverse diffusion process is like the Decoder in VAE.&lt;/p&gt;
$$p(ğ±|ğ³) â‡’ p(ğ±â‚œâ‚‹â‚ğ±â‚œâ‚‹â‚‚..ğ±â‚€ | ğ±â‚œ)$$&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Given a noise image ğ±â‚œ, the distribution of less-noise image ğ±â‚œâ‚‹â‚ is&lt;/p&gt;
&lt;p&gt;$p(ğ±â‚œâ‚‹â‚ | ğ±â‚œ) = N(ğ±â‚œâ‚‹â‚; Î¼_Î¸(ğ±â‚œ, t), Î£_Î¸(ğ±â‚œ, t))$&lt;/p&gt;
&lt;p&gt;where the variance can be a fixed schedule as Î²â‚œ, so only the mean $Î¼_Î¸(ğ±â‚œ, t)$ needs to be learned with a network.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vlb&#34;&gt;VLB
&lt;/h3&gt;&lt;p&gt;VLB is the loss to be minimized.
VLB gets simplied by:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Applying Bayes rule to &amp;ldquo;reverse&amp;rdquo; the direction of the forward process, which
becomes &amp;ldquo;forward denoising&amp;rdquo; steps q(ğ±â‚œâ‚‹â‚ | ğ±â‚œ), because
it&amp;rsquo;s from a noise image to a less-noise image;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adding extra conditioning on ğ±â‚€ for each &amp;ldquo;forward denosing&amp;rdquo; step q(ğ±â‚œâ‚‹â‚ | ğ±â‚œ, ğ±â‚€).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Derivation by step:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Diffusion model wants a set of parameter ğ›‰ letting the likelihood of the &lt;strong&gt;original image&lt;/strong&gt; ğ±â‚€ maximum.&lt;/p&gt;
$$\rm Î¸ = arg max_Î¸\ log\ p_Î¸(ğ±â‚€)$$&lt;p&gt;With adding a minus sign, the objective turns to find the minimum:&lt;/p&gt;
&lt;p&gt;-log p(ğ±â‚€) = -ELBO - KL-divergence&lt;/p&gt;
$$
  \begin{aligned}
  &amp; -log p(ğ±â‚€) \left( = -log \frac{p(ğ±â‚€, ğ³)}{p(ğ³|ğ±â‚€)} \right) \\\
  &amp;= -log \frac{p(ğ±_{1:T}, ğ±â‚€)}{p(ğ±_{1:T} | ğ±â‚€)} \\\
  &amp; \text{(Introduce &#34;approximate posterior&#34; q :)} \\\
  &amp;= -(log \frac{ p(ğ±_{1:T}, ğ±â‚€) }{ q(ğ±_{1:T} | ğ±â‚€)} 
    \ + log (\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{1:T} | ğ±â‚€)}) ) \\\
  \end{aligned}
  $$&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Note that $q(ğ±_{1:T} | ğ±â‚€)$ represents a &lt;strong&gt;joint distribution&lt;/strong&gt; of N conditional distributions ğ±â‚œ and ğ±â‚œâ‚‹â‚.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is the &lt;strong&gt;step-by-step&lt;/strong&gt; design that makes training a network to learn the data distribution possible.
Meanwhile, the sampling process also has to be step-by-step.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Compute expection w.r.t. $q(ğ±_{1:T} | ğ±â‚€)$ for both side.&lt;/p&gt;
$$
  E_{q(ğ±_{1:T} | ğ±â‚€)} [ -log p(ğ±â‚€) ] \\\
  \ = E_{q(ğ±_{1:T} | ğ±â‚€)} \left[-log \frac{ p(ğ±_{0:T}) }{ q(ğ±_{1:T} | ğ±â‚€)}\right]
  \ + E_{q(ğ±_{1:T} | ğ±â‚€)} \left[-log (\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{1:T} | ğ±â‚€)})\right]
  $$&lt;p&gt;Expectation is equivalent to integration.&lt;/p&gt;
$$
  \begin{aligned}
  &amp; \text{LHS:}
    âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * (-log p(ğ±â‚€)) dğ±_{1:T} = -log p(ğ±â‚€) \\\
  &amp; \text{RHS:}
  \ = E_{q(ğ±_{1:T} | ğ±â‚€)} \left[-log \frac{ p(ğ±_{0:T}) }{ q(ğ±_{1:T} | ğ±â‚€)}\right] \\\ 
  &amp; + âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * \left(-log (\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{1:T} | ğ±â‚€)})\right) dğ±_{1:T} 
  \end{aligned}
  $$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since KL-divergence is non-negative, there is:&lt;/p&gt;
&lt;p&gt;-log p(ğ±â‚€) â‰¤ -log p(ğ±â‚€) + KL-divergence =&lt;/p&gt;
$$
  \begin{aligned}
  &amp;  -log p(ğ±â‚€) + D_{KL}( q(ğ±_{1:T} | ğ±â‚€) || p(ğ±_{1:T} | ğ±â‚€) ) \\\
  &amp;= -log p(ğ±â‚€) 
  \ + âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * \left(log (\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{1:T} | ğ±â‚€)})\right) dğ±_{1:T}
  \end{aligned}
  $$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Break apart the denominator $p(ğ±_{1:T} | ğ±â‚€)$ of the argument in the KL-divergence&amp;rsquo;s logarithm based on Bayes rule:&lt;/p&gt;
$$p(ğ±_{1:T} | ğ±â‚€) = \frac{p(ğ±_{1:T}, ğ±â‚€)}{p(ğ±â‚€)} = \frac{p(ğ±_{0:T})}{p(ğ±â‚€)}$$&lt;p&gt;Plug it back to KL-divergence:&lt;/p&gt;
$$
  \begin{aligned}
  &amp;âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * \left( log(\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{1:T} | ğ±â‚€)})\right) dğ±_{1:T} \\\
  &amp;= âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * log (\frac{q(ğ±_{1:T} | ğ±â‚€) p(ğ±â‚€)}{p(ğ±_{0:T})}) dğ±_{1:T} \\\
  &amp;= âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * [ log(p(ğ±â‚€) + log(\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{0:T})})] dğ±_{1:T}\\\
  &amp;= âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * log(p(ğ±â‚€) dğ±_{1:T} \\\
  &amp;\quad  + âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * log(\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{0:T})}) dğ±_{1:T} \\\
  &amp;= log p(ğ±â‚€) + âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€) * log(\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{0:T})}) dğ±_{1:T}
  \end{aligned}
  $$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plug this decomposed KL-divergence into the above inequality, and the incomputable log-likelihood (-log p(ğ±â‚€)) can be canceled,
resulting in the &lt;strong&gt;Variational Lower Bound (VLB)&lt;/strong&gt;:&lt;/p&gt;
$$-log p(ğ±â‚€) â‰¤ âˆ«_{ğ±_{1:T}} q(ğ±_{1:T} | ğ±â‚€)\ log(\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_{0:T})}) dğ±_{1:T}$$&lt;p&gt;The argument of log is a ratio of the forward process and the reverse process.&lt;/p&gt;
&lt;p&gt;The numerator is the distribution of $ğ±_{1:T}$ given the &lt;strong&gt;starting point&lt;/strong&gt; ğ±â‚€.
To make the numerator and denominator have symmetric steps, the starting point of the reverse process $p(ğ±_T)$ can be separated out.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Separate out $p(ğ±_T)$ from the denominator by rewriting the conditional probability as a &lt;strong&gt;cumulative product&lt;/strong&gt;:&lt;/p&gt;
$$
  p(ğ±_{0:T}) = p(ğ±_T) Î _{t=1}^T p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)
  $$&lt;p&gt;Plug it back into the logarithm of the VLB, and &lt;strong&gt;break&lt;/strong&gt; the numerator joint distribution as a &lt;strong&gt;product of N-1 steps&lt;/strong&gt; as well:&lt;/p&gt;
$$
  log(\frac{q(ğ±_{1:T} | ğ±â‚€)}{p(ğ±_T) Î _{t=1}^T p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)}) 
  \= log \frac{ Î _{t=1}^T q(ğ±â‚œ|ğ±â‚œâ‚‹â‚)}{ p(ğ±_T) Î _{t=1}^T p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)} \\\
  \= log \frac{ Î _{t=1}^T q(ğ±â‚œ|ğ±â‚œâ‚‹â‚)}{ Î _{t=1}^T p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)} - log p(ğ±_T) \\\
  \= âˆ‘_{t=1}^T log (\frac{q(ğ±â‚œ|ğ±â‚œâ‚‹â‚)}{p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)}) - log\ p(ğ±_T)
  $$&lt;p&gt;This form includes every step rather than only focusing on the distribution of the all events $ğ±_{1:T}$.&lt;/p&gt;
&lt;p&gt;(2023-08-11) DM wants the data distribution, but it doesn&amp;rsquo;t &lt;strong&gt;rebuild&lt;/strong&gt; the distribution transformation directly from Gaussian to data distribution,
but approachs the &lt;strong&gt;corruption&lt;/strong&gt; process step-by-step to reduce the difficulty (variance).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Separate the first item (first step, t=1) from the summation,
so that the &lt;strong&gt;other terms&lt;/strong&gt; can be conditioned on ğ±â‚€, thus reducing the variance:&lt;/p&gt;
$$
  log \frac{q(ğ±â‚|ğ±â‚€)}{p(ğ±â‚€|ğ±â‚)} + âˆ‘_{t=2}^T log (\frac{q(ğ±â‚œ|ğ±â‚œâ‚‹â‚)}{p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)}) - log\ p(ğ±_T)
  $$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reformulate the numerator $q(ğ±â‚œ|ğ±â‚œâ‚‹â‚)$ based on &lt;strong&gt;Bayes rule&lt;/strong&gt;:&lt;/p&gt;
$$
  q(ğ±â‚œ|ğ±â‚œâ‚‹â‚) = \frac{q(ğ±â‚œâ‚‹â‚|ğ±â‚œ)q(ğ±â‚œ)}{q(ğ±â‚œâ‚‹â‚)}
  $$&lt;p&gt;In this form, forward adding noise $q$ and reverse denoising $p$ become the same process from ğ±â‚œ to ğ±â‚œâ‚‹â‚.
Such that, in one pass, the model can both perform forward process and reverse process once.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make each step &lt;strong&gt;conditioned on ğ±â‚€&lt;/strong&gt; to reduce the variance (uncertainty).&lt;/p&gt;
$$
  q(ğ±â‚œ|ğ±â‚œâ‚‹â‚) = \frac{q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€)q(ğ±â‚œ| ğ±â‚€)}{q(ğ±â‚œâ‚‹â‚| ğ±â‚€)}
  $$&lt;p&gt;And this distribution $q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€)$ has a closed-form solution.&lt;/p&gt;
&lt;p&gt;Here is why the first step is separated out:
If t=1, the $q(ğ±â‚|ğ±â‚€)$ conditioned on ğ±â‚€ is:&lt;/p&gt;
$$
  q(ğ±â‚|ğ±â‚€) = \frac{q(ğ±â‚€|ğ±â‚, ğ±â‚€)q(ğ±â‚|ğ±â‚€)}{q(ğ±â‚€|ğ±â‚€)}
  $$&lt;p&gt;There is a loop of $q(ğ±â‚|ğ±â‚€)$ if ğ±â‚€ exists,
and other terms $q(ğ±â‚€|ğ±â‚, ğ±â‚€)$ and $q(ğ±â‚€|ğ±â‚€)$ don&amp;rsquo;t make sense.&lt;/p&gt;
&lt;p&gt;Plug the newly conditioned numerator back to the fraction, and break it apart based on log rule:&lt;/p&gt;
$$
  âˆ‘_{t=2}^T log \frac{q(ğ±â‚œ|ğ±â‚œâ‚‹â‚)}{p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)} 
  \ = âˆ‘_{t=2}^T log \frac{q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€)q(ğ±â‚œ| ğ±â‚€)}{p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)q(ğ±â‚œâ‚‹â‚| ğ±â‚€)} \\\
  \ = âˆ‘_{t=2}^T log \frac{q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€)}{p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)} + âˆ‘_{t=2}^T log \frac{q(ğ±â‚œ| ğ±â‚€)}{q(ğ±â‚œâ‚‹â‚| ğ±â‚€)} \\\
  $$&lt;p&gt;The second term will be simplied to $log \frac{q(ğ±_T| ğ±â‚€)}{q(ğ±â‚| ğ±â‚€)}$&lt;/p&gt;
&lt;p&gt;Then, the variational lower bound becomes:&lt;/p&gt;
$$
  D_{KL}(q(ğ±_{1:T}|ğ±â‚€) || p(ğ±_{0:T})) = \\\
  log \frac{q(ğ±â‚|ğ±â‚€)}{p(ğ±â‚€|ğ±â‚)} 
  \ + âˆ‘_{t=2}^T log \frac{q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€)}{p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)}
  \ + log \frac{q(ğ±_T| ğ±â‚€)}{q(ğ±â‚| ğ±â‚€)} 
  \ - log\ p(ğ±_T) \\\
  \ \\\
  \ = âˆ‘_{t=2}^Tlog \frac{ q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€) }{ p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)}
  \ + log \frac{q(ğ±_T| ğ±â‚€)}{p(ğ±â‚€|ğ±â‚)} 
  \ - log\ p(ğ±_T) \\\
  \ \\\
  \ = âˆ‘_{t=2}^T log \frac{ q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€) }{ p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)}
  \ + log \frac{q(ğ±_T| ğ±â‚€)}{p(ğ±_T)} 
  \ - log p(ğ±â‚€|ğ±â‚)
  $$&lt;p&gt;Write this formula as KL-divergence, so that a concrete expression can be determined later.&lt;/p&gt;
&lt;font style=&#39;color: red&#39;&gt;
How are those two fractions written as KL-divergence?
&lt;/font&gt;
$$
  \begin{aligned}
  &amp; âˆ‘_{t=2}^T D_{KL} (q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€) || p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)) \\\
  &amp; + D_{KL} (q(ğ±_T| ğ±â‚€) || p(ğ±_T)) \\\
  &amp; - log\ p(ğ±â‚€|ğ±â‚)
  \end{aligned}
  $$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;loss-function&#34;&gt;Loss function
&lt;/h3&gt;&lt;p&gt;The VLB to be minimized is eventually derived as a MSE loss function between the actual noise and the predicted noise.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;$D_{KL} (q(ğ±_T| ğ±â‚€) || p(ğ±_T))$ can be &lt;strong&gt;ignored&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$q(ğ±_T| ğ±â‚€)$ has no learnable parameters because it just adds noise following a schedule.&lt;/li&gt;
&lt;li&gt;And $p(ğ±_T)$ is the noise image sampled from normal distribution.
Since $q(ğ±_T| ğ±â‚€)$ is the eventual image which is supposed to follow the normal distribution,
this KL-divergence should be small.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, the loss only contains the other two terms:&lt;/p&gt;
$$L = âˆ‘_{t=2}^T D_{KL} (q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€) || p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)) - log\ p(ğ±â‚€|ğ±â‚)$$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$D_{KL} (q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€) || p(ğ±â‚œâ‚‹â‚|ğ±â‚œ))$ is the MSE between the actual noise and the predicted noise.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For the reverse pass, the distribution of the &lt;strong&gt;denoised&lt;/strong&gt; image $p(ğ±â‚œâ‚‹â‚|ğ±â‚œ)$ has a parametric expression:&lt;/p&gt;
$$p(ğ±â‚œâ‚‹â‚|ğ±â‚œ) = N(ğ±â‚œâ‚‹â‚; Î¼_Î¸(ğ±â‚œ,t), Î£_Î¸(ğ±â‚œ,t)) \\\ = N(ğ±â‚œâ‚‹â‚; Î¼_Î¸(ğ±â‚œ,t), Î²ğˆ)$$&lt;p&gt;where Î£ is fixed as Î²â‚œğˆ, and only the mean $Î¼_Î¸(ğ±â‚œ,t)$ will be learned and represented by a network (output) through the MSE loss of noise as below.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For the (&amp;ldquo;reversed&amp;rdquo;) forward pass, the distribution of &lt;strong&gt;noise-added&lt;/strong&gt; image $q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€)$ has a closed-form solution,
which can be written as a similar expression as p(ğ±â‚œâ‚‹â‚|ğ±â‚œ):
&lt;font style=&#34;color: red&#34;&gt;What&amp;rsquo;s the derivation?&lt;/font&gt;&lt;/p&gt;
$$
     q(ğ±â‚œâ‚‹â‚|ğ±â‚œ, ğ±â‚€) =
     N(ğ±â‚œâ‚‹â‚; \tilde Î¼â‚œ(ğ±â‚œ,ğ±â‚€), \tilde Î²â‚œğˆ) \\\
     \ \\\
     \tilde Î²â‚œ = \frac{1- \bar Î±â‚œâ‚‹â‚}{1-\bar Î±â‚œ} â‹… Î²â‚œ \\\ 
     \ \\\
     \tilde Î¼(ğ±â‚œ,ğ±â‚€) = \frac{\sqrt{Î±â‚œ} (1-\bar Î±â‚œâ‚‹â‚) }{1-\bar Î±â‚œ} ğ±â‚œ 
     \ + \frac{\sqrt{\bar Î±â‚œâ‚‹â‚} Î²â‚œ}{1-\bar Î±â‚œ} ğ±â‚€ \\\
     \ \\\
     \rm Is there \sqrt{Î±â‚œ} or \sqrt{\bar Î±â‚œ} ?
     $$&lt;p&gt;where the $\tilde Î²â‚œ$ is fixed, so only consider the $\tilde Î¼(ğ±â‚œ,ğ±â‚€)$, which can
be simplified by the &lt;strong&gt;one-step forward&lt;/strong&gt; process expression:
$ğ±â‚œ = \sqrt{\bar Î±â‚œ} ğ±â‚€ + \sqrt{1 - \bar Î±â‚œ} Îµ$&lt;/p&gt;
$$
     ğ±â‚€ = \frac{ğ±â‚œ - \sqrt{1 - \bar Î±â‚œ} Îµ}{\sqrt{\bar Î±â‚œ}} 
     $$&lt;p&gt;Plug ğ±â‚€ into $\tilde Î¼(ğ±â‚œ,ğ±â‚€)$, then the mean of the noise-added image &lt;strong&gt;doesn&amp;rsquo;t depend&lt;/strong&gt; on ğ±â‚€ anymore:&lt;/p&gt;
$$
     \begin{aligned}
     \tilde Î¼(ğ±â‚œ,ğ±â‚€) 
     &amp; = \frac{\sqrt{Î±â‚œ} (1-\bar Î±â‚œâ‚‹â‚) }{1-\bar Î±â‚œ} ğ±â‚œ 
       \ + \frac{\sqrt{\bar Î±â‚œâ‚‹â‚} Î²â‚œ}{1-\bar Î±â‚œ} 
       \ \frac{ğ±â‚œ - \sqrt{1 - \bar Î±â‚œ} Îµ}{\sqrt{\bar Î±â‚œ}} \\\
       \ \\\
     &amp; =  ???\ How \ to \ do? \ ??? \\\
     &amp; = \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ)
     \end{aligned}
     $$&lt;p&gt;The mean of the distribution from which the noise-added image (ğ±â‚œ,ğ±â‚€) at timestep t get sampled out is subtracting some random noise from image ğ±â‚œ.&lt;/p&gt;
&lt;p&gt;ğ±â‚œ is known from the forward process schedule, and the $\tilde Î¼(ğ±â‚œ,ğ±â‚€)$ is the &lt;strong&gt;target&lt;/strong&gt; for the network to optimize weights
to make the predicted mean $Î¼_Î¸(ğ±â‚œ,t)$ same as $\tilde Î¼(ğ±â‚œ,ğ±â‚€)$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since network only output Î¼, the KL-divergence in the loss function can be simplified in favor of using MSE:&lt;/p&gt;
$$
     Lâ‚œ = \frac{1}{2Ïƒâ‚œÂ²} \\| \tilde Î¼(ğ±â‚œ,ğ±â‚€) - Î¼_Î¸(ğ±â‚œ,t) \\|Â²
     $$&lt;p&gt;This MSE indicates that the noise-added image in the forward process and the noise-removed image in the reverse process should be &lt;strong&gt;as close as possible&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Since the &lt;strong&gt;actual&lt;/strong&gt; mean $\tilde Î¼(ğ±â‚œ,ğ±â‚€) = \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ)$,
where ğ±â‚œ is known, as it&amp;rsquo;s the input to the network.
So the model is essentially estimating the actual $Îµ$ (random &lt;strong&gt;noise&lt;/strong&gt;) every time.&lt;/p&gt;
&lt;p&gt;Hence, the &lt;strong&gt;predicted&lt;/strong&gt; mean $Î¼_Î¸(ğ±â‚œ,t)$ by the model can be written in the same form as $\tilde Î¼(ğ±â‚œ,ğ±â‚€)$, where only the noise $Îµ_Î¸$ has parameters:&lt;/p&gt;
$$Î¼_Î¸(ğ±â‚œ,t) = \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ_Î¸((ğ±â‚œ,t)))$$&lt;p&gt;Therefore, the loss term becomes:&lt;/p&gt;
$$
     Lâ‚œ = \frac{1}{2Ïƒâ‚œÂ²} \\| \tilde Î¼(ğ±â‚œ,ğ±â‚€) - Î¼_Î¸(ğ±â‚œ,t) \\|Â² \\\
     \ = \frac{1}{2Ïƒâ‚œÂ²} \left\\| \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ)
     \ - \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ_Î¸(ğ±â‚œ,t)) \right\\|Â² \\\
     \ = \frac{Î²â‚œÂ²}{2Ïƒâ‚œÂ² Î±â‚œ (1-\bar Î±â‚œ)} \\|Îµ - Îµ_Î¸(ğ±â‚œ,t) \\|Â²
     $$&lt;p&gt;Disregarding the scaling factor can bring better sampling quality and easier implementation, so the final loss for the KL-divergence is MSE between actual noise and predicted noise at time t:&lt;/p&gt;
$$\\|Îµ - Îµ_Î¸(ğ±â‚œ,t) \\|Â²$$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the mean $Î¼_Î¸(ğ±â‚œ,t)$ has predicted out based on ğ±â‚œ and t, a &amp;ldquo;cleaner&amp;rdquo; image can be sampled from the distribution:&lt;/p&gt;
$$
     N(ğ±â‚œâ‚‹â‚; Î¼_Î¸(ğ±â‚œ,t), \sigma_Î¸(ğ±â‚œ,t)) =
     N(ğ±â‚œâ‚‹â‚; \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ_Î¸(ğ±â‚œ,t), Î²â‚œğˆ)
     $$&lt;div id=&#34;Sampling&#34;&gt;&lt;/div&gt;
By using reparameterization trick, this sampled image is: 
$$
     ğ±â‚œâ‚‹â‚ = Î¼_Î¸(ğ±â‚œ,t) + ÏƒÎµ
     \ = \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ_Î¸(ğ±â‚œ,t) + \sqrt{Î²â‚œ}Îµ
     $$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The last term $log p(ğ±â‚€|ğ±â‚)$ in the VLB is the predicted distribution for the original image ğ±â‚€.
Its goodness is measured by a &lt;strong&gt;probability&lt;/strong&gt;
that the &lt;strong&gt;original&lt;/strong&gt; image $ğ±â‚€$ gets sampled from the estimated distribution $N(x; Î¼_Î¸â±(ğ±â‚,1), Î²â‚)$.&lt;/p&gt;
&lt;p&gt;The probability of an image should be a product of &lt;strong&gt;total D pixels&lt;/strong&gt;.
And the probability a pixel should be an &lt;strong&gt;integral&lt;/strong&gt; over an interval [Î´â‚‹, Î´â‚Š] of the PDF curve:&lt;/p&gt;
$$
   p_Î¸(ğ±â‚€|ğ±â‚) = âˆ_{i=1}^D âˆ«_{Î´â‚‹(xâ‚€â±)}^{Î´â‚Š(xâ‚€â±)} N(x; Î¼_Î¸â±(ğ±â‚,1), Î²â‚) dx
   $$&lt;ul&gt;
&lt;li&gt;where $xâ‚€$ is the pixel&amp;rsquo;s ground-truth.&lt;/li&gt;
&lt;li&gt;$N(x; Î¼_Î¸â±(ğ±â‚,1), Î²â‚)$ is the distribution to be integrated.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This interval is determined based on the &lt;strong&gt;actual pixel&lt;/strong&gt; value as:&lt;/p&gt;
$$
   Î´â‚Š(x) = 
   \begin{cases}
   âˆ &amp; \text{if x = 1} \\\ x+\frac{1}{255} &amp; \text{if x &lt; 1}
   \end{cases}, \quad
   Î´â‚‹(x) = 
   \begin{cases}
   -âˆ &amp; \text{if x = -1} \\\ x-\frac{1}{255} &amp; \text{if x &gt; -1}
   \end{cases}
   $$&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The original pixel range [0,255] has been normalized to [-1, 1] to align with the standard normal distribution $p(x_T) \sim N(0,1)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If the actual value is 1, the integral upper bound in the distribution is âˆ, and the lower bound is 1-1/255 = 0.996, the width of the interval is from 0.996 to infinity.&lt;/p&gt;
&lt;p&gt;If the actual value is 0.5, the upper bound is 0.5+1/255, and the lower bound is 0.5-1/255, the width of the interval is 2/255.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;pic: area of the true pixel region in two predicted distributions.&lt;/p&gt;
&lt;p&gt;If the area &lt;strong&gt;around the actual pixel value&lt;/strong&gt; under the predicted distribution PDF curve is large, the predicted distribution is good.
Howerver, if the area around real pixel value is small, the estimated mean is wrongly located.&lt;/p&gt;
&lt;p&gt;Hence, this probability (log-likelihood) should be maximized, and by condering the minus sign in front of it, the corresponding loss term comes.&lt;/p&gt;
&lt;p&gt;However, the authors &lt;strong&gt;got rid of&lt;/strong&gt; this loss term $-log p(ğ±â‚€|ğ±â‚)$ when training the network.
And the consequense is at inference time, the final step from ğ±â‚ to ğ±â‚€ doesn&amp;rsquo;t add noise, because this step &lt;strong&gt;wasn&amp;rsquo;t get optimized&lt;/strong&gt;.
Therefore, The difference from other sampling steps is that the predicted ğ±â‚€ doesn&amp;rsquo;t plus random noise.&lt;/p&gt;
$$
   \begin{aligned}
   \text{t&gt;1:}\quad
   ğ±_{t-1} &amp;= \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ_Î¸(ğ±â‚œ,t) + \sqrt Î²â‚œ Îµ) \\\
   \text{t=1:}\quad
   ğ±_{t-1} &amp;= \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{Î²â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ_Î¸(ğ±â‚œ,t))
   \end{aligned}
   $$&lt;p&gt;A simple reason is that we don&amp;rsquo;t want to add noise to the final denoised clear output image ğ±â‚€. Otherwise, the generated image is low-quality.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The complete loss function is MSE:&lt;/p&gt;
$$
\begin{aligned}
\rm L_{simple} &amp;= E_{t,ğ±â‚€,Îµ} [ || Îµ - Îµ_Î¸(ğ±â‚œ,t)||Â² ]  \\\
 &amp;= E_{t,ğ±â‚€,Îµ} [ || Îµ - Îµ_Î¸( \sqrt{\bar aâ‚œ} ğ±â‚€ + \sqrt{1 - \bar aâ‚œ} Îµ, t) ||Â² ]
\end{aligned}
$$&lt;ul&gt;
&lt;li&gt;t is sampled from a uniform distribution between 1 and t;&lt;/li&gt;
&lt;li&gt;ğ±â‚œ is the one-step forward process.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;algorithms&#34;&gt;Algorithms
&lt;/h2&gt;&lt;p&gt;DDPM paper&lt;/p&gt;
&lt;p&gt;Training a model:&lt;/p&gt;
&lt;pre class=&#34;pseudocode&#34; data-line-number=true&gt;\begin{algorithm}
\caption{Training}
\begin{algorithmic}
\REPEAT
  \STATE Sample a t from U(0,T)
  \STATE Select an input image ğ±â‚€ from dataset
  \STATE Sample a noise from N(0,ğˆ)
  \STATE Perform gradient descent with loss: \\\\
  $||Îµ - Îµ_Î¸(\sqrt{\bar aâ‚œ} ğ±â‚€ + \sqrt{1 - \bar aâ‚œ} Îµ, t)||Â²$
\UNTIL{converge}
\end{algorithmic}
\end{algorithm}
&lt;/pre&gt;

&lt;p&gt;Sampling from the learned data distribution by means of reparameterization trick:&lt;/p&gt;
&lt;pre class=&#34;pseudocode&#34; data-line-number=true&gt;\begin{algorithm}
\caption{Sampling}
\begin{algorithmic}
\STATE Sample a noise image $ğ±_T \sim N(0,ğˆ)$
\FOR{t = T:1}
  \COMMENT{Remove noise step-by-step}
  \IF{t=1}
    \STATE Îµ=0
  \ELSE
    \STATE Îµ ~ N(0,ğˆ)
  \ENDIF

  \STATE $ğ±â‚œâ‚‹â‚ = \frac{1}{\sqrt{Î±â‚œ}} (ğ±â‚œ - \frac{1-Î±â‚œ}{\sqrt{1 - \bar Î±â‚œ}} Îµ_Î¸(ğ±â‚œ,t) + \sqrt{Ïƒâ‚œ}Îµ$
  \COMMENT{Reparam trick}

\ENDFOR
\RETURN ğ±â‚€
\end{algorithmic}
\end{algorithm}
&lt;/pre&gt;

&lt;p&gt;In this reparametrization formula change Î²â‚œ and $\sqrt{Î²â‚œ}$ to 1-Î±â‚œ and Ïƒâ‚œ,
which are different from the &lt;a class=&#34;link&#34; href=&#34;#Sampling&#34; &gt;above equation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Training and Sampling share the common pipeline:&lt;/p&gt;



&lt;div class=&#34;goat svg-container &#34;&gt;
  
    &lt;svg
      xmlns=&#34;http://www.w3.org/2000/svg&#34;
      font-family=&#34;Menlo,Lucida Console,monospace&#34;
      
        viewBox=&#34;0 0 328 89&#34;
      &gt;
      &lt;g transform=&#39;translate(8,16)&#39;&gt;
&lt;path d=&#39;M 24,16 L 40,16&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 96,16 L 112,16&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;polygon points=&#39;48.000000,16.000000 36.000000,10.400000 36.000000,21.600000&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 40.000000, 16.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;72.000000,32.000000 60.000000,26.400000 60.000000,37.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 64.000000, 32.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;120.000000,16.000000 108.000000,10.400000 108.000000,21.600000&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 112.000000, 16.000000)&#39;&gt;&lt;/polygon&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;ğ±&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â‚œ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â€–&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;U&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;Îµ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;N&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â‹®&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;Îµ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;80&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;80&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;_&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;88&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;Î¸&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â€–&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;104&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;Â²&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;Îµ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;_&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;Î¸&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â‹¯&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â–¶&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;Î¼&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;_&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;Î¸&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;ğ±&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â‚œ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;,&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;240&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;264&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â‹¯&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;272&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â–¶&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;288&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;ğ±&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;296&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â‚œ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;304&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â‚‹&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;312&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â‚&lt;/text&gt;
&lt;/g&gt;

    &lt;/svg&gt;
  
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;improvements&#34;&gt;Improvements
&lt;/h2&gt;&lt;p&gt;Improvements from OpenAI&amp;rsquo;s 2021 papers.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Learn a scale factor for interpolating the upper and lower bound to get a flexible variance:&lt;/p&gt;
$$Î£_Î¸(xâ‚œ,t) = exp(v\ log Î²â‚œ +(1-v)\ log(1- \tilde{Î²â‚œ}))$$&lt;p&gt;v is learned by adding an extra loss term $Î» L_{VLB}$, and Î»=0.001.&lt;/p&gt;
$$L_{hybrid} = E_{t,ğ±â‚€,Îµ} [ || Îµ - Îµ_Î¸(ğ±â‚œ,t)||Â² ] + Î» L_{VLB}$$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use cosine noise schedule $f(t)=cos(\frac{t/T+s}{1+s}â‹…Ï€/2)Â²$ in favor of linear schedule.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;div id=&#34;2015&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/1503.03585&#34;&gt;Deep Unsupervised Learning using Nonequilibrium Thermodynamics, 2015&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;div id=&#34;2020&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;Denoising Diffusion Probabilistic Models, 2020&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;div id=&#34;2102&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2102.09672&#34;&gt;Improved Denoising Diffusion Probabilistic Models, 2021 Feb&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;div id=&#34;2105&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2105.05233&#34;&gt;Diffusion Models Beat GANs on Image Synthesis, 2021 May&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>watch: DM - DLAI | How Diffusion Models Work</title>
        <link>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/d-vid-dlai/</link>
        <pubDate>Sun, 09 Jul 2023 17:00:00 +0000</pubDate>
        
        <guid>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/d-vid-dlai/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.deeplearning.ai/diffusion-models/lesson/1/introduction&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Course page&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;sampling&#34;&gt;Sampling
&lt;/h2&gt;&lt;p&gt;Steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Sample a random noise image from &lt;strong&gt;normal&lt;/strong&gt; distribution;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the trained network to predict the &lt;strong&gt;noise&lt;/strong&gt; as opposed to the meaningful object for &lt;strong&gt;one step&lt;/strong&gt;;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use DDPM algorithm to compute noise-level &lt;strong&gt;scaling factors&lt;/strong&gt; given a timestep:
&lt;code&gt;s1, s2, s3 = ddpm_scaling(t)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Subtract&lt;/strong&gt; the predicted noise from noise image and add extra noise,
&lt;code&gt;sample = s1 * (sample - s2 * predicted_noise) + s3 * extra_noise&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeat steps 2 to 4 to remove noise &lt;strong&gt;progressively&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;samples&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N_imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;timesteps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timesteps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# reshape to match input image (N_imgs, 3, height, height)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timesteps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)[:,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# extra noise (except for the first step)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn_like&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;samples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# predict noise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;eps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn_model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;samples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# remove noise and add extra noise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;samples&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;denoise_add_noise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;samples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;eps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Adding extra noise before removing noise in the next step avoids collapsing to the average thing of the training dataset.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;unet&#34;&gt;UNet
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;UNet can output images of the same size as the input, and assign the image feature onto each pixel.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compress image for compact representation;&lt;/li&gt;
&lt;li&gt;Down sampling once, number of channel doubles&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Also UNet allows incorporating addtional information during the decoding period.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Each time up-sampling, the sample is multiplied with context embeddings and plus time embeddings.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Time embedding indicates timestep of the feature vector, so with that, the &amp;ldquo;time-dependent&amp;rdquo; noise level can be determined.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Context embedding can be text description, so the UNet will be guided to generate specific output.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;



&lt;div class=&#34;goat svg-container &#34;&gt;
  
    &lt;svg
      xmlns=&#34;http://www.w3.org/2000/svg&#34;
      font-family=&#34;Menlo,Lucida Console,monospace&#34;
      
        viewBox=&#34;0 0 448 489&#34;
      &gt;
      &lt;g transform=&#39;translate(8,16)&#39;&gt;
&lt;path d=&#39;M 120,32 L 144,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,32 L 248,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 280,32 L 296,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 328,32 L 360,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 248,432 L 296,432&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 0,48 L 0,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,80 L 16,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 24,48 L 24,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 40,80 L 40,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 48,48 L 48,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 64,80 L 64,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 72,48 L 72,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 88,80 L 88,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,48 L 168,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,224 L 168,272&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,368 L 168,416&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 192,96 L 192,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 192,272 L 192,320&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 192,416 L 192,464&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,48 L 200,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,224 L 200,272&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,368 L 200,416&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,96 L 224,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,272 L 224,320&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,416 L 224,464&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 264,64 L 264,272&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 312,64 L 312,416&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 376,48 L 376,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 400,96 L 400,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 0,80 L 16,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,416 L 192,464&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 0,48 L 16,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 24,80 L 40,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,368 L 192,416&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,416 L 224,464&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 24,48 L 40,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 48,80 L 64,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,368 L 224,416&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 48,48 L 64,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 72,80 L 88,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,272 L 192,320&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 72,48 L 88,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,224 L 192,272&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,272 L 224,320&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,224 L 224,272&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,96 L 192,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,48 L 192,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,96 L 224,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,48 L 224,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 376,96 L 400,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 376,48 L 400,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;polygon points=&#39;152.000000,32.000000 140.000000,26.400000 140.000000,37.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 144.000000, 32.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;256.000000,32.000000 244.000000,26.400000 244.000000,37.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 248.000000, 32.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;272.000000,64.000000 260.000000,58.400002 260.000000,69.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 264.000000, 64.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;320.000000,64.000000 308.000000,58.400002 308.000000,69.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 312.000000, 64.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;368.000000,32.000000 356.000000,26.400000 356.000000,37.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 360.000000, 32.000000)&#39;&gt;&lt;/polygon&gt;
&lt;path d=&#39;M 264,272 A 16,16 0 0,1 248,288&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 312,416 A 16,16 0 0,1 296,432&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;f&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;h&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;4&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;h&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;80&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;80&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;88&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;2&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;C&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;340&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;T&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;340&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;1&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;h&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;340&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;340&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;x&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;212&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;356&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;264&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â¨‚&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;312&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â¨&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;328&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;336&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;336&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;344&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;344&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;352&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;352&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;360&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;368&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;368&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;376&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;1&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;384&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;392&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;392&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;400&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;2&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;400&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;h&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;408&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;416&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;424&#39; y=&#39;164&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;/g&gt;

    &lt;/svg&gt;
  
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# embed context and timestep&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cemb1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contextembed1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;view&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_feat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;temb1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timeembed1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;view&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_feat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;up2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;up&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cemb1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;up1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;temb1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;down2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;hr&gt;
&lt;p&gt;(2023-07-10)&lt;/p&gt;
&lt;h2 id=&#34;training&#34;&gt;Training
&lt;/h2&gt;&lt;p&gt;Train the UNet to identify the noise that was applied to the image.&lt;/p&gt;
&lt;p&gt;UNet can segment image (classify each pixel), so here is it used to identify whether every pixel is noise or not?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No, it&amp;rsquo;s used to make each pixel carried with extracted or introduced features.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Training steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sample a random timestep (noise-level) to make noise;&lt;/li&gt;
&lt;li&gt;Add the known noise onto a random training image;&lt;/li&gt;
&lt;li&gt;UNet takes as input the noise image and predicts the applied noise as output;&lt;/li&gt;
&lt;li&gt;Loss is the difference between the true noise and the predicted noise&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ep&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_epoch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dataloader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# perturb data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;timesteps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;noise&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn_like&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;x_pert&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;perturb_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;noise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# use network to recover noise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pred_noise&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn_model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_pert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;timesteps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# loss is MSE&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mse_loss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pred_noise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;noise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zero_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;hr&gt;
&lt;p&gt;(2023-07-11)&lt;/p&gt;
&lt;h2 id=&#34;controling&#34;&gt;Controling
&lt;/h2&gt;&lt;p&gt;Use embedding vector to control the predicted noise.&lt;/p&gt;
&lt;p&gt;Embedding is a vector (a set of numbers) that is a representation for something in another space.&lt;/p&gt;
&lt;p&gt;Embeddings can perform arithmetic operations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Paris   : &lt;br&gt;
- France  : &lt;br&gt;
+ England : &lt;br&gt;
= London  :&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Noise is what should be removed from the image.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Once the noise is fully subtracted out, what left is the generated image.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By injecting context embeddings into decoder, the output feature vector of the predicted noise becomes specific for that given context.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For example, the noise corresponding to &amp;ldquo;A ripe avocado&amp;rdquo; is pixels that are &lt;strong&gt;not&lt;/strong&gt; &amp;ldquo;A ripe avocado&amp;rdquo;, and they&amp;rsquo;ll be removed eventually.&lt;/p&gt;



&lt;div class=&#34;goat svg-container &#34;&gt;
  
    &lt;svg
      xmlns=&#34;http://www.w3.org/2000/svg&#34;
      font-family=&#34;Menlo,Lucida Console,monospace&#34;
      
        viewBox=&#34;0 0 344 185&#34;
      &gt;
      &lt;g transform=&#39;translate(8,16)&#39;&gt;
&lt;path d=&#39;M 72,16 L 104,16&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 184,32 L 296,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,64 L 48,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,64 L 256,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 64,80 L 80,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 112,80 L 128,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 192,80 L 208,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 272,80 L 288,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,96 L 48,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,96 L 256,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,128 L 48,128&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 64,144 L 96,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 96,144 L 296,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,160 L 48,160&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,64 L 16,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,128 L 16,160&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 48,64 L 48,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 48,128 L 48,160&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 96,96 L 96,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 152,32 L 152,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 168,48 L 168,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,64 L 224,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 256,64 L 256,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 312,48 L 312,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 312,96 L 312,128&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;polygon points=&#39;104.000000,96.000000 92.000000,90.400002 92.000000,101.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 96.000000, 96.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;112.000000,16.000000 100.000000,10.400000 100.000000,21.600000&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 104.000000, 16.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;136.000000,80.000000 124.000000,74.400002 124.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 128.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;160.000000,64.000000 148.000000,58.400002 148.000000,69.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(90.000000, 152.000000, 64.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;176.000000,64.000000 164.000000,58.400002 164.000000,69.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(90.000000, 168.000000, 64.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;216.000000,80.000000 204.000000,74.400002 204.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 208.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;296.000000,80.000000 284.000000,74.400002 284.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 288.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;320.000000,96.000000 308.000000,90.400002 308.000000,101.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 312.000000, 96.000000)&#39;&gt;&lt;/polygon&gt;
&lt;path d=&#39;M 184,32 A 16,16 0 0,0 168,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 296,32 A 16,16 0 0,1 312,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 312,128 A 16,16 0 0,1 296,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;&#39;&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;A&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;v&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;&#39;&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;â¨&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;E&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;C&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;U&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;N&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;x&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;240&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;240&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;304&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;312&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;320&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;328&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;/g&gt;

    &lt;/svg&gt;
  
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And because the embedding vectors can be mixed, once the &lt;strong&gt;mixed noise&lt;/strong&gt; is removed, what is left is the combination of two objects, i.e. the thing that the context embedding stands for.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For example, an embedding vector of &amp;ldquo;Avocado armchair&amp;rdquo; has the information of both &amp;ldquo;avocado&amp;rdquo; and &amp;ldquo;armchair&amp;rdquo;, so its context will lead the model to predict the noise that is neither &amp;ldquo;avocado&amp;rdquo; nor &amp;ldquo;armchair&amp;rdquo;.&lt;/p&gt;



&lt;div class=&#34;goat svg-container &#34;&gt;
  
    &lt;svg
      xmlns=&#34;http://www.w3.org/2000/svg&#34;
      font-family=&#34;Menlo,Lucida Console,monospace&#34;
      
        viewBox=&#34;0 0 384 153&#34;
      &gt;
      &lt;g transform=&#39;translate(8,16)&#39;&gt;
&lt;path d=&#39;M 80,16 L 96,16&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,64 L 48,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,64 L 232,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 328,64 L 360,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 64,80 L 96,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 160,80 L 184,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 248,80 L 264,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 296,80 L 312,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,96 L 48,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,96 L 232,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 328,96 L 360,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 48,128 L 264,128&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,64 L 16,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 48,64 L 48,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 128,32 L 128,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,64 L 200,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 232,64 L 232,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 280,96 L 280,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 328,64 L 328,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 360,64 L 360,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 32,104 L 32,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;polygon points=&#39;104.000000,16.000000 92.000000,10.400000 92.000000,21.600000&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 96.000000, 16.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;104.000000,80.000000 92.000000,74.400002 92.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 96.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;136.000000,64.000000 124.000000,58.400002 124.000000,69.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(90.000000, 128.000000, 64.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;192.000000,80.000000 180.000000,74.400002 180.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 184.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;272.000000,80.000000 260.000000,74.400002 260.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 264.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;288.000000,96.000000 276.000000,90.400002 276.000000,101.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 280.000000, 96.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;320.000000,80.000000 308.000000,74.400002 308.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 312.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;path d=&#39;M 32,112 A 16,16 0 0,0 48,128&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 280,112 A 16,16 0 0,1 264,128&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;&#39;&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;A&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;v&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;h&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;&#39;&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;C&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;E&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;U&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;N&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;x&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;280&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;âŠ–&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;336&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;344&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;352&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;/g&gt;

    &lt;/svg&gt;
  
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Context can be one-hot encoded vector for indicating categories, which will result in a specific class of images.&lt;/p&gt;
&lt;h2 id=&#34;speeding-up&#34;&gt;Speeding Up
&lt;/h2&gt;&lt;p&gt;DDIM skips some timesteps, so it breaks Markov chain process, where each timestep is probablisticly dependent on the previous one.&lt;/p&gt;
&lt;p&gt;There is a hyper-parameter &lt;code&gt;step_size&lt;/code&gt; to decide how many timesteps are skipped.&lt;/p&gt;
&lt;p&gt;DDIM performs better than DDPM &lt;strong&gt;under&lt;/strong&gt; 500 timesteps.
The quality of images from DDIM may differs as opposed to DDPM.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2010.02502&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;em&gt;Denoising Diffusion implict model&lt;/em&gt;&lt;/a&gt;  predicts a &amp;ldquo;rough sketch&amp;rdquo; of the final output, and then it refines it with the denoising process.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>images</title>
        <link>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/imgs/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://blog.zichen.uk/post/writenotes/model/imagen/diffusion/imgs/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
