<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Source video: æ·±åº¦å­¦ä¹ -å•ƒèŠ±ä¹¦0103ä¼ªé€†çŸ©é˜µæœ€å°äºŒä¹˜ (2021-07-22) - ç§‘ç ”å°ç°ç°
(2023-02-04)
Solve linear regression For a n-dimensional linear regression problem,
There are N input samples: xâ‚,xâ‚‚,&amp;hellip;,$x_N$, where each sample is a n-dimension vector xáµ¢âˆˆ â„â¿ Their corresponding target outputs are: yâ‚,yâ‚‚,&amp;hellip;,$y_N$, where each output is a scalar yáµ¢âˆˆ â„ Hence, these data can be represented as a linear system:
$$ \begin{cases} xâ‚â‚aâ‚ &#43; xâ‚â‚‚aâ‚‚ &#43; &amp;hellip; &#43; xâ‚â‚™aâ‚™ = yâ‚ \\ xâ‚‚â‚aâ‚ &#43; xâ‚‚â‚‚aâ‚‚ &#43; &amp;hellip; &#43; xâ‚‚â‚™aâ‚™ = yâ‚ \\ \vdots \\ x_{N1}aâ‚ &#43; x_{N2}aâ‚‚ &#43; &amp;hellip; &#43; x_{Nn}aâ‚™ = y_N \\ \end{cases} $$'>
<title>memo: Calc | Pseudo-Inverse</title>

<link rel='canonical' href='https://zichen34.github.io/writenotes/calc/pseudo-inverse/'>

<link rel="stylesheet" href="/scss/style.min.8191399262444ab68b72a18c97392f5349be20a1615d77445be51e974c144cff.css"><meta property='og:title' content='memo: Calc | Pseudo-Inverse'>
<meta property='og:description' content='Source video: æ·±åº¦å­¦ä¹ -å•ƒèŠ±ä¹¦0103ä¼ªé€†çŸ©é˜µæœ€å°äºŒä¹˜ (2021-07-22) - ç§‘ç ”å°ç°ç°
(2023-02-04)
Solve linear regression For a n-dimensional linear regression problem,
There are N input samples: xâ‚,xâ‚‚,&amp;hellip;,$x_N$, where each sample is a n-dimension vector xáµ¢âˆˆ â„â¿ Their corresponding target outputs are: yâ‚,yâ‚‚,&amp;hellip;,$y_N$, where each output is a scalar yáµ¢âˆˆ â„ Hence, these data can be represented as a linear system:
$$ \begin{cases} xâ‚â‚aâ‚ &#43; xâ‚â‚‚aâ‚‚ &#43; &amp;hellip; &#43; xâ‚â‚™aâ‚™ = yâ‚ \\ xâ‚‚â‚aâ‚ &#43; xâ‚‚â‚‚aâ‚‚ &#43; &amp;hellip; &#43; xâ‚‚â‚™aâ‚™ = yâ‚ \\ \vdots \\ x_{N1}aâ‚ &#43; x_{N2}aâ‚‚ &#43; &amp;hellip; &#43; x_{Nn}aâ‚™ = y_N \\ \end{cases} $$'>
<meta property='og:url' content='https://zichen34.github.io/writenotes/calc/pseudo-inverse/'>
<meta property='og:site_name' content='Zichen Wang'>
<meta property='og:type' content='article'><meta property='article:section' content='WriteNotes' /><meta property='article:published_time' content='2023-02-04T12:23:00-05:00'/><meta property='article:modified_time' content='2023-02-04T12:23:00-05:00'/>
<meta name="twitter:title" content="memo: Calc | Pseudo-Inverse">
<meta name="twitter:description" content="Source video: æ·±åº¦å­¦ä¹ -å•ƒèŠ±ä¹¦0103ä¼ªé€†çŸ©é˜µæœ€å°äºŒä¹˜ (2021-07-22) - ç§‘ç ”å°ç°ç°
(2023-02-04)
Solve linear regression For a n-dimensional linear regression problem,
There are N input samples: xâ‚,xâ‚‚,&amp;hellip;,$x_N$, where each sample is a n-dimension vector xáµ¢âˆˆ â„â¿ Their corresponding target outputs are: yâ‚,yâ‚‚,&amp;hellip;,$y_N$, where each output is a scalar yáµ¢âˆˆ â„ Hence, these data can be represented as a linear system:
$$ \begin{cases} xâ‚â‚aâ‚ &#43; xâ‚â‚‚aâ‚‚ &#43; &amp;hellip; &#43; xâ‚â‚™aâ‚™ = yâ‚ \\ xâ‚‚â‚aâ‚ &#43; xâ‚‚â‚‚aâ‚‚ &#43; &amp;hellip; &#43; xâ‚‚â‚™aâ‚™ = yâ‚ \\ \vdots \\ x_{N1}aâ‚ &#43; x_{N2}aâ‚‚ &#43; &amp;hellip; &#43; x_{Nn}aâ‚™ = y_N \\ \end{cases} $$">
    <link rel="shortcut icon" href="/favicon-32x32.png" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu238e2fe759432347fa5dd53661ac4381_131637_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Zichen Wang</a></h1>
            <h2 class="site-description"></h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/zichen34'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://twitter.com/luckily1640'
                        target="_blank"
                        title="Twitter"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/aboutme/' >
                
                
                
                <span>About</span>
            </a>
        </li>
        
        
        <li >
            <a href='/writenotes/' >
                
                
                
                <span>WriteNotes</span>
            </a>
        </li>
        
        
        <li >
            <a href='/page/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#solve-linear-regression">Solve linear regression</a></li>
    <li><a href="#shift-from-ğ—-to-ğ—áµ€ğ—">Shift from ğ— to ğ—áµ€ğ—</a></li>
    <li><a href="#is-ğ—áµ€ğ—-invertible">Is ğ—áµ€ğ— invertible?</a></li>
    <li><a href="#effect-of-the-regularization-term">Effect of the regularization term</a></li>
    <li><a href="#proof">Proof</a></li>
    <li><a href="#gpu-solve-inverse">GPU Solve Inverse</a></li>
    <li><a href="#how-to-solve-inverse-matrix">How to solve inverse matrix?</a></li>
    <li><a href="#estimate-polynomial-by-ls">Estimate Polynomial by LS</a></li>
    <li><a href="#weighted-least-squares">Weighted least squares</a></li>
    <li><a href="#mls-for-resampling">MLS for Resampling</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/memo/" style="background-color: #6e57d2; color: #fff;">
                memo
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/writenotes/calc/pseudo-inverse/">memo: Calc | Pseudo-Inverse</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Feb 04, 2023</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    10 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p>Source video: <a class="link" href="https://www.bilibili.com/video/BV1364y1678r/"  target="_blank" rel="noopener"
    >æ·±åº¦å­¦ä¹ -å•ƒèŠ±ä¹¦0103ä¼ªé€†çŸ©é˜µæœ€å°äºŒä¹˜ (2021-07-22) - ç§‘ç ”å°ç°ç°</a></p>
<p>(2023-02-04)</p>
<h2 id="solve-linear-regression">Solve linear regression</h2>
<p>For a n-dimensional linear regression problem,</p>
<ul>
<li>There are N input samples: xâ‚,xâ‚‚,&hellip;,$x_N$, where each sample is a n-dimension vector xáµ¢âˆˆ â„â¿</li>
<li>Their corresponding target outputs are:  yâ‚,yâ‚‚,&hellip;,$y_N$, where each output is a scalar yáµ¢âˆˆ â„</li>
</ul>
<p>Hence, these data can be represented as a linear system:</p>
<p>$$
\begin{cases}
xâ‚â‚aâ‚ + xâ‚â‚‚aâ‚‚ + &hellip; + xâ‚â‚™aâ‚™ = yâ‚ \\
xâ‚‚â‚aâ‚ + xâ‚‚â‚‚aâ‚‚ + &hellip; + xâ‚‚â‚™aâ‚™ = yâ‚ \\
\vdots \\
x_{N1}aâ‚ + x_{N2}aâ‚‚ + &hellip; + x_{Nn}aâ‚™ = y_N \\
\end{cases}
$$</p>
<p>Further, this system can be represented with matrix and vector:</p>
<p>$$
\begin{bmatrix}
xâ‚â‚ &amp; xâ‚â‚‚ &amp; â€¦ &amp; xâ‚â‚™ \\
xâ‚‚â‚ &amp; xâ‚‚â‚‚ &amp; â€¦ &amp; xâ‚‚â‚™ \\
â‹® &amp; â‹® &amp; â‹± &amp; â‹® \\
x_{N1} &amp; x_{N2} &amp; â€¦ &amp; x_{Nn}
\end{bmatrix}
\begin{bmatrix}
aâ‚ \\ aâ‚‚ \\ â‹® \\ aâ‚™
\end{bmatrix} =
\begin{bmatrix}
yâ‚ \\ yâ‚‚ \\ â‹® \\ y_N
\end{bmatrix}
$$</p>
<p>The objective of the linear regression is to solve the weights vector:
$[ ^{^{aâ‚}_{aâ‚‚}} _{^{\ â}_{aâ‚™}} ]$
from the linear equation: $ğ—_{NÃ—n} ğš_{nÃ—1} = ğ˜_{NÃ—1}$.</p>
<p>If N=n (the coefficient matrix is a square matrix), and the data matrix $ğ—_{NÃ—n}$ is a <strong>invertible matrix</strong>,
then there will be ğš=ğ—â»Â¹ğ˜, such that the weights vector is determined directly.</p>
<p>But in general, the number of samples N is not equal to the number of features n (N â‰  n),
that is ğ— is not invertible and ğš cannot be represented as ğ—â»Â¹ğ˜.</p>
<h2 id="shift-from-ğ—-to-ğ—áµ€ğ—">Shift from ğ— to ğ—áµ€ğ—</h2>
<p>Therefore, when the ğš cannot be reached directly, the solution should be as close to the optimal as possible.</p>
<p>That means the objective is to minimize the distance of two vectors:</p>
<p>J=â€–ğ—ğš-ğ˜â€–Â² (without constraints)</p>
<p>And the optimal solution is obtained when</p>
<p>âˆ‚J/âˆ‚ğš = ğ—áµ€(ğ—ğš-ğ˜) = 0 â‡’ ğ—áµ€ğ—ğš = ğ—áµ€ğ˜.</p>
<p>Now, the previous ğ— is shifted to here ğ—áµ€ğ— âˆˆ â„â¿á•â¿, which is a <strong>square matrix</strong>.
And if ğ—áµ€ğ— is invertible, then the optimal ğš can be calculated in one-shot.</p>
<h2 id="is-ğ—áµ€ğ—-invertible">Is ğ—áµ€ğ— invertible?</h2>
<p>An invertible matrix has to satisfy 2 conditions:
it&rsquo;s a square matrix and its rank equals to the number of variables n (#columns).</p>
<p>According to this video, there are two cases:</p>
<ol>
<li>
<p>If N &gt; n, for example N=5, n=3, then (ğ—áµ€ğ—)â‚ƒâ‚“â‚ƒ is inverible generally. So</p>
<p>ğš=(ğ—áµ€ğ—)â»Â¹ğ—áµ€ğ˜,</p>
<p>where the coefficient in front of ğ˜, (ğ—áµ€ğ—)â»Â¹ğ—áµ€, is called the <strong>pseudo-inverse matrix</strong>.
And ğš = (ğ—áµ€ğ—)â»Â¹ğ—áµ€ğ˜ is called the least-square solution. (æœ€å°äºŒä¹˜è§£)</p>
<p>(Because ğ— has no inverse matrix, so we find its &ldquo;pseudo&rdquo; inverse matrix. Or if ğ— is invertible, ğ—â»Â¹=(ğ—áµ€ğ—)â»Â¹ğ—áµ€, they&rsquo;re equivalent, but the latter suits more general scenarios.). <br></p>
</li>
<li>
<p>If $N &lt; n$, for example N=3, n=5, then (ğ—áµ€ğ—)â‚…â‚“â‚… is not invertible, because:</p>
<p>rank(ğ—áµ€ğ—) â‰¤ rank(ğ—â‚ƒâ‚“â‚…) â‰¤ N=3 $&lt;$ n=5.</p>
<p>In this case, ğš cannot be calculated as (ğ—áµ€ğ—)â»Â¹ğ—áµ€ğ˜.</p>
</li>
</ol>
<p>The problem can be understood that there are too many parameters (n is too high). When the parameters are much more than samples, there will be overfitting.
And one of the solutions is regularization.</p>
<h2 id="effect-of-the-regularization-term">Effect of the regularization term</h2>
<p>Since the reason why the optimal solution of the loss function J cannot be solved in one-shot is that there are too many parameters,
a regularization is added to the loss funciton as follows:</p>
<p>$$J = â€–ğ—ğš-ğ˜â€–Â² + Î»â€–ğšâ€–Â², Î»&gt;0$$</p>
<p>Then the derivative becomes:</p>
<p>âˆ‚J/âˆ‚ğš = ğ—áµ€ğ—ğš - ğ—áµ€ğ˜ + Î»ğš = 0.</p>
<p>By moving items, the equation becomes:</p>
<p>(ğ—áµ€ğ— + Î»ğˆ)ğš = ğ—áµ€ğ˜,</p>
<p>where the (ğ—áµ€ğ— + Î»ğˆ) is invertible.
The proof is as follows.</p>
<h2 id="proof">Proof</h2>
<p>Since ğ—áµ€ğ— is a symmetric matrix, it can be diagonalized. Thus, ğ—áµ€ğ— can be written as:</p>
<p>$$
ğ—áµ€ğ— = ğâ»Â¹
\begin{bmatrix}
Î»â‚ &amp;   &amp;    \\
&amp; â‹± &amp;    \\
&amp;   &amp; Î»â‚™
\end{bmatrix}
ğ
$$</p>
<p>The determinant of ğ—áµ€ğ— is: <br>
|ğ—áµ€ğ—| = |ğâ»Â¹| â‹… |$^{^{Î»â‚}_{\quad â‹±}} _{\qquad Î»â‚™}$| â‹… |ğ|
= Î»â‚ â‹… Î»â‚‚ â€¦ â‹… Î»â‚™</p>
<p>And Î»â‚, Î»â‚‚ â€¦, Î»â‚™ are the eigen values for the ğ—áµ€ğ—</p>
<p>Then the invertibility can be judged from this determinant:</p>
<ul>
<li>
<p>If |ğ—áµ€ğ—| = 0, then ğ—áµ€ğ— is not invertible,
because there are some zero lines in the matrix (after elementary row operations), that means rank(ğ—áµ€ğ—) &lt; n.</p>
</li>
<li>
<p>But if |ğ—áµ€ğ—| &gt; 0, the matrix ğ—áµ€ğ— is invertible, because it has full rank,
which is equal to the number of lines of rows.
<span style="font-size:10px"><a class="link" href="https://www.bilibili.com/video/BV1ci4y1975D"  target="_blank" rel="noopener"
    >ã€ä¿—è¯´çŸ©é˜µã€‘è¡Œåˆ—å¼ç­‰äº0æ„å‘³ç€ä»€ä¹ˆï¼Ÿä½ ä¸€å®šè¦äº†è§£å“¦~ - æ™“ä¹‹è½¦é«˜å±±è€å¸ˆ-bilibili</a></span></p>
</li>
</ul>
<p>Analyze the two cases without and with adding the regularization term:</p>
<ol>
<li>
<p>Only the ğ—áµ€ğ—:</p>
<ul>
<li>
<p>Let this matrix be enclosed by a non-zero real row vector ğ›‚áµ€
and its column vector ğ›‚ to constuct a quadratic form: ğ›‚áµ€(ğ—áµ€ğ—)ğ›‚,
which is used to characterize the definiteness of ğ—áµ€ğ—.
<span style="font-size:10px"><a class="link" href="https://en.wikipedia.org/wiki/Definite_matrix"  target="_blank" rel="noopener"
    >Definite matrix -wiki</a></span></p>
</li>
<li>
<p>Based on the combination law of the matrix multiplication, it can be written as: (ğ›‚áµ€ğ—áµ€)(ğ—ğ›‚) = (ğ—ğ›‚)áµ€(ğ—ğ›‚), which is the norm of the vector ğ—ğ›‚. <br></p>
</li>
<li>
<p>Because the norm is â‰¥ 0 definitely, the ğ›‚áµ€(ğ—áµ€ğ—)ğ›‚ â‰¥ 0 (indicating ğ—áµ€ğ— is positive semi-definite matrix).</p>
</li>
<li>
<p>Based on the properties of quadratic form, eigen values Î»áµ¢ of ğ—áµ€ğ— are all â‰¥ 0</p>
</li>
</ul>
<p>Then the above determinant is |ğ—áµ€ğ—|= Î»â‚ â‹… Î»â‚‚ â€¦ â‹… Î»â‚™ â‰¥ 0, so when |ğ—áµ€ğ—| = 0, the rank of the matrix ğ—áµ€ğ— is not full (â‰  n), so the matrix ğ—áµ€ğ— is not invertible.</p>
</li>
<li>
<p>For ğ—áµ€ğ—+Î»ğˆ (where Î» is a hyper-parameter), it can be considered as a matrix:</p>
<ul>
<li>A quadratic form is constructed as: ğ›‚áµ€(ğ—áµ€ğ—+Î»ğˆ)ğ›‚ = (ğ›‚áµ€ğ—áµ€)(ğ—ğ›‚) + Î»ğ›‚áµ€ğ›‚.</li>
<li>The second item is always &gt;0 because ğ›‚ is not a zero vector, so its norm ğ›‚áµ€ğ›‚ &gt; 0.</li>
<li>Therefore, the matrix (ğ—áµ€ğ—+Î»ğˆ) is a positive definite matrix.
The eigen values Î»áµ¢ of (ğ—áµ€ğ—+Î»ğˆ) are all &gt; 0.</li>
</ul>
<p>The determinant of ğ—áµ€ğ—+Î»ğˆ is the product of its eigen values, i.e., the determinant |ğ—áµ€ğ—+Î»ğˆ|&gt;0. So the matrix ğ—áµ€ğ—+Î»ğˆ has full rank, and ğ—áµ€ğ—+Î»ğˆ is invertible.</p>
<p>Therefore, the optimal solution can be solved as ğš = (ğ—áµ€ğ— + Î»ğˆ)â»Â¹ ğ—áµ€ğ˜. This is called the &ldquo;least square - least norm solution&rdquo;. (æœ€å°äºŒä¹˜-æœ€å°èŒƒæ•°è§£)</p>
<p>L2 regularization is originally added to make the ğ—áµ€ğ— invertible.</p>
</li>
</ol>
<p>(bilibili search: &ldquo;ä¼ªé€†çŸ©é˜µ&rdquo;)</p>
<p>todo: <a class="link" href="https://www.bilibili.com/video/BV14G411n7HY/"  target="_blank" rel="noopener"
    >01 2ã€æœ€å°äºŒä¹˜ä¸pcaï¼ˆæ–°ï¼‰ - æ·±åº¦ä¹‹çœ¼å®˜æ–¹è´¦å·-bilibili</a></p>
<p>todo: <a class="link" href="https://www.bilibili.com/video/BV1ns411r7dE/"  target="_blank" rel="noopener"
    >ã€ç†Ÿè‚‰ã€‘çº¿æ€§ä»£æ•°çš„æœ¬è´¨ - 06 - é€†çŸ©é˜µã€åˆ—ç©ºé—´ä¸é›¶ç©ºé—´ - 3B1B -bili</a></p>
<p>todo: <a class="link" href="https://www.bilibili.com/video/BV1gm4y1Q7hA/"  target="_blank" rel="noopener"
    >ã€26 æ·±å…¥ç†è§£é€†çŸ©é˜µã€‘- cf98982002 -bili</a></p>
<hr>
<h2 id="gpu-solve-inverse">GPU Solve Inverse</h2>
<p>Use GPU to solve inverse faster?</p>
<p>(DDG search: &ldquo;çŸ©é˜µæ±‚é€† gpu&rdquo;)</p>
<ul>
<li>The acceleration ratio of GPU to CPU is more than 16 times. <a class="link" href="#zhihu-%e5%86%af%e5%8d%9a%e5%a3%ab" >â´</a>.
<div id="zhihu-å†¯åšå£«"><a href="https://zhuanlan.zhihu.com/p/320545275">GPUçŸ©é˜µè®¡ç®—æ˜¯å¦ä¼šæ›´å¿«ï¼Ÿï¼ˆåŸºäºPytorchï¼‰ - åŠä¸ªå†¯åšå£«çš„æ–‡ç«  - çŸ¥ä¹</a></div>
</li>
</ul>
<hr>
<h2 id="how-to-solve-inverse-matrix">How to solve inverse matrix?</h2>
<div id="zhihu-ç–¯ç‹‚ç»…å£«"><a href="https://www.zhihu.com/question/356880062/answer/2135670915">æ±‚é€†çŸ©é˜µçš„4ç§æ–¹æ³•? - ç–¯ç‹‚ç»…å£«çš„å›ç­” - çŸ¥ä¹</a></div>
<ol>
<li>Gaussian Eliminate</li>
<li>LU decomposition, commenly used by computer because it can be performed parallelly.</li>
<li>SVD decomposition</li>
<li>QR decomposition</li>
</ol>
<hr>
<h2 id="estimate-polynomial-by-ls">Estimate Polynomial by LS</h2>
<p>(2024-06-10)</p>
<ul>
<li>
<p>Least-square can be used to approximate the <strong>coefficients</strong> of a polynomial.</p>
<p>The optimal polynomial corresponds to the minimum error between the <strong>observed and predicted</strong> values.</p>
<p><a class="link" href="https://www.cnblogs.com/zzk0/p/10468502.html#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"  target="_blank" rel="noopener"
    >Example</a></p>
<p>Given a point set as below, use a <strong>linear polynomial</strong> to fit the data:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nv">x</span> <span class="o">=</span> <span class="o">[</span>0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">y</span> <span class="o">=</span> <span class="o">[</span>0, 4, 5, 14, 15, 14.5, 14, 12, 10, 5, 4<span class="o">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The general form of a linear polynomial is: ax + b*1 = y, a and b are the coefficients to be estimated:</p>
<p>$$
\begin{bmatrix}
0 &amp; 1 \\ 0.1 &amp; 1 \\ 0.2 &amp; 1 \\ 0.3 &amp; 1 \\ â‹¯
\end{bmatrix}
\begin{bmatrix} a \\  b \end{bmatrix} =
\begin{bmatrix} 0 \\ 4 \\ 5 \\ 14 \\ â‹¯
\end{bmatrix}
$$</p>
<p>$$XA = Y$$</p>
<ul>
<li>
<p>Obviously, the 2 axes (column space) of X cannot be &ldquo;recombined&rdquo; to produce Y space.
In other words, the $[^a_b]$ that makes the equation hold doesn&rsquo;t exist.</p>
<p>Therefore, the objective is shifted to minimize the error between Y_pred and target Y.</p>
</li>
<li>
<p>Project the target Y to the column space of X resulting in Y&rsquo; (that will be approximated by A&rsquo;), and the error: Y&rsquo;-Y is
<strong>orthogonal</strong> to the column space of X, as the error can&rsquo;t be explained by the X&rsquo;s space
(Don&rsquo;t know a theoretical explanation yet).</p>
</li>
<li>
<p>Since Y&rsquo;-Y is orthogonal to X, there is:</p>
<p>$$\begin{aligned}
X^T(Y&rsquo;-Y)=0 \\ X^T(XA&rsquo;-Y) = 0
\end{aligned}$$</p>
<p>The best coefficients A&rsquo; is:</p>
<p>$$A&rsquo;=(X^T X)^{-1} X^TY$$</p>
</li>
</ul>
</li>
<li>
<p>Use a quadratic polynomial axÂ²+bx+c=y to fit the data:</p>
<p>$$
\begin{bmatrix}
0 &amp; 0 &amp; 1 \\ 0.01 &amp; 0.1 &amp; 1 \\ 0.04 &amp; 0.2 &amp; 1 \\ 0.09 &amp; 0.3 &amp; 1 \\ â‹¯
\end{bmatrix}
\begin{bmatrix} a \\  b \\ c \end{bmatrix} =
\begin{bmatrix} 0 \\ 4 \\ 5 \\ 14 \\ â‹¯
\end{bmatrix}
$$</p>
<ul>
<li>xÂ² (e.g., 0.01), x (e.g., 0.1), and 1 are the 3 basis functions that are combined with various ratios to form multiple <strong>basiss</strong>.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>The optimal coefficients of a polynomial can also be found by solving the equation that
the <strong>partial derivative</strong> of the error w.r.t. <strong>each coefficient</strong> equals 0.</p>
<p>Derivation referring to: <small>
<a class="link" href="http://www.nealen.com/projects/mls/asapmls.pdf"  target="_blank" rel="noopener"
    >An As-Short-As-Possible Introduction to the Least Squares, Weighted Least Squares and Moving Least Squares Methods for Scattered Data Approximation and Interpolation (may 2004) - Andy Nealen</a></small></p>
<p>Use a quadratic bivariate polynomial to fit a point set (ğ±áµ¢,yáµ¢)</p>
<p>$$
\|Y&rsquo; - Y\|^2
$$</p>
<p>$$
Î± = \big[ âˆ‘_{i=1}^N \big( b(xáµ¢)â‹… b(xáµ¢)^T \big) \big]^{-1} â‹… âˆ‘_{i=1}^N \big( b(xáµ¢) â‹… yáµ¢ \big)
$$</p>
<ul>
<li><code>b</code> means a <strong>basis</strong> (system), i.e., a series of basis functions.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="weighted-least-squares">Weighted least squares</h2>
<p>(2024-06-11)</p>
<ul>
<li>The value at each <strong>new</strong> point is predicted based on an approximated <strong>polynomial</strong>,
which is found by minimizing the difference between the training point and predicted values,
and the differences are <strong>weighted</strong> according to the distance from the new point to each training point.</li>
</ul>
<p>(2024-05-31)</p>
<ul>
<li>
<p>Consider some samples (errors) are more <strong>important</strong>, and the importance is determined by the sample&rsquo;s <strong>neighbors</strong>:</p>
<p>$$J_{LS} = \sum_{i=1}^N wáµ¢ (\^yáµ¢ - yáµ¢)^2$$</p>
<ul>
<li>
<p>Assume the target function has a &ldquo;Compact Support&rdquo;. Thus, each sample is only affected by its neighbors within the local support.
<small><a class="link" href="https://www.cnblogs.com/zzk0/p/10468502.html"  target="_blank" rel="noopener"
    >ç§»åŠ¨æœ€å°äºŒä¹˜æ³•åœ¨ç‚¹äº‘å¹³æ»‘å’Œé‡é‡‡æ ·ä¸­çš„åº”ç”¨-åšå®¢å›­-æ¥·å“¥</a></small></p>
</li>
<li>
<p>By only considering a narrow region, each sample has a variance $Ïƒáµ¢Â²$. And the weights can be the <strong>reciprocal</strong> of the variance $\frac{1}{Ïƒáµ¢Â²}$:</p>
<p>In other words, WLS takes the <strong>correlation</strong> of adjacent errors into account.
<a class="link" href="https://en.wikipedia.org/wiki/Weighted_least_squares"  target="_blank" rel="noopener"
    >Wikipedia</a></p>
</li>
<li>
<p>Other reasons analysis: <a class="link" href="https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/24/lecture-24--25.pdf"  target="_blank" rel="noopener"
    >Lecture 24-25: Weighted and Generalized Least Squares - CMU</a>
(Found in <a class="link" href="https://duckduckgo.com/?q=weighted&#43;least&#43;squares&amp;ia=web"  target="_blank" rel="noopener"
    >DDG</a>)</p>
</li>
</ul>
</li>
<li>
<p>Examples of fitting circle, line, curves with IRLS: <small>
<a class="link" href="https://blog.csdn.net/weixin_43763292/article/details/127839786"  target="_blank" rel="noopener"
    >æœ€å°äºŒä¹˜æ³•ï¼ŒåŠ æƒæœ€å°äºŒä¹˜æ³•ï¼Œè¿­ä»£é‡åŠ æƒæœ€å°äºŒä¹˜æ³• (å«ä»£ç )ã€æœ€å°äºŒä¹˜çº¿æ€§æ±‚è§£ã€‘</a></small></p>
</li>
</ul>
<hr>
<h2 id="mls-for-resampling">MLS for Resampling</h2>
<p>(2024-06-10)</p>
<ul>
<li>
<p>The value of a new point is computed based on the input point set:
<a class="link" href="https://www.cnblogs.com/zzk0/p/10468502.html#%E4%BE%8B%E5%AD%904"  target="_blank" rel="noopener"
    >Example</a></p>
<ol>
<li>
<p>Given a point set: (xâ‚,yâ‚), (xâ‚‚,yâ‚‚), (xâ‚ƒ,yâ‚ƒ), &hellip;($x_N,y_N$);</p>
</li>
<li>
<p>Predict the value y&rsquo; of a <strong>new</strong> point x&rsquo; based on the approximated <strong>polynomial</strong>,
which is found by minimizing the error between the y_pred (evaluated by the approximated polynomial) and the true y values for N points.
This minimization process can be performed with a one-shot expression, i.e., pseudo inverse in least squares.</p>
</li>
<li>
<p>The error of each point is scaled by a weight:</p>
<p>$$\sum_{i=1}^N w_i (y_i - y&rsquo;)^2$$</p>
<p>where the weight is determined based on the distance from the <strong>new</strong> point to the training input point:</p>
<p>$$
w =
\begin{cases}
0, &amp; \text{dist&lt;0} \\
\frac{2}{3} - 4 dist^2 + 4 dist^3, &amp; \text{0â‰¤distâ‰¤0.5} \\
\frac{4}{3} - 4 dist + 4 dist^2 - \frac{4}{3} dist^3, &amp; \text{0.5&lt;distâ‰¤1} \\
\end{cases}
$$</p>
</li>
<li>
<p>The optimal <strong>coefficients</strong> vector ğ›‚ of a certain polynoimal is solved based on a &ldquo;pseudo-inverse form&rdquo; expression:
(<a class="link" href="http://www.nealen.com/projects/mls/asapmls.pdf"  target="_blank" rel="noopener"
    >Derivation</a>)</p>
<p>$$
Î± = \big[ âˆ‘_{i=1}^N Î¸(s) \big( b(xáµ¢)â‹… b(xáµ¢)^T \big) \big]^{-1} â‹… âˆ‘_{i=1}^N \big( Î¸(s) b(xáµ¢) â‹… yáµ¢ \big)
$$</p>
<ul>
<li><code>s</code> is the distance from the new point to the point i.</li>
</ul>
</li>
</ol>
<p>Code for resampling with MLS fitting the input point set with a <strong>linear</strong> polynomial:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">w</span><span class="p">(</span><span class="n">dis</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">dis</span> <span class="o">=</span> <span class="n">dis</span> <span class="o">/</span> <span class="mf">0.3</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">dis</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">dis</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">2</span><span class="o">/</span><span class="mi">3</span> <span class="o">-</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">dis</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">dis</span><span class="o">**</span><span class="mi">3</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">dis</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">4</span><span class="o">/</span><span class="mi">3</span> <span class="o">-</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">dis</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">dis</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">4</span><span class="o">/</span><span class="mi">3</span> <span class="o">*</span> <span class="n">dis</span><span class="o">**</span><span class="mi">3</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">mls</span><span class="p">(</span><span class="n">x_</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">sumxx</span> <span class="o">=</span> <span class="n">sumx</span> <span class="o">=</span> <span class="n">sumxf</span> <span class="o">=</span> <span class="n">sumf</span> <span class="o">=</span> <span class="n">sumw</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Iterate every training point to calc coeffs</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">weight</span> <span class="o">=</span> <span class="n">w</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">x_</span> <span class="o">-</span> <span class="n">a</span><span class="p">))</span>   <span class="c1"># dist2weight</span>
</span></span><span class="line"><span class="cl">        <span class="n">sumw</span> <span class="o">+=</span> <span class="n">weight</span>
</span></span><span class="line"><span class="cl">        <span class="n">sumx</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">weight</span>
</span></span><span class="line"><span class="cl">        <span class="n">sumxx</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">a</span> <span class="o">*</span> <span class="n">weight</span>
</span></span><span class="line"><span class="cl">        <span class="n">sumf</span> <span class="o">+=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">weight</span>
</span></span><span class="line"><span class="cl">        <span class="n">sumxf</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span> <span class="o">*</span> <span class="n">weight</span>
</span></span><span class="line"><span class="cl">    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">sumw</span><span class="p">,</span> <span class="n">sumx</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                  <span class="p">[</span><span class="n">sumx</span><span class="p">,</span> <span class="n">sumxx</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">    <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">sumf</span><span class="p">,</span> <span class="n">sumxf</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">ans</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Calculate y-value at the new point</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ans</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ans</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Input point set for training:</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mf">14.5</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Re-Sampling (for plotting the curve):</span>
</span></span><span class="line"><span class="cl"><span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">yy</span> <span class="o">=</span> <span class="p">[</span><span class="n">mls</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">xx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="n">dpi</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">facecolor</span><span class="o">=</span><span class="s2">&#34;white&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div>
  
  
  
  
    
    
    
    
     
    
    
     
    
    <img src= /writenotes/calc/img/MLS_resampling.png width=50%>
    
    
  

</li>
</ul>
<ul>
<li>
<p>MLS smoothing (å¹³æ»‘) means &ldquo;recomputing&rdquo; the y-value at each <strong>input</strong> (training) point x using the found polynomial.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">y_smooth</span> <span class="o">=</span> <span class="p">[</span><span class="n">mls</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_smooth</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><figure><img src="https://i.ibb.co/8YMSF7F/MLS-smoothing.png" width="40%"/>
  </figure>

</li>
</ul>

</section>


    <footer class="article-footer">
    

    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css"integrity="sha256-J&#43;iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s="crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js"integrity="sha256-InsNdER1b2xUewP&#43;pKCUJpkhiqwHgqiPXDlIk7GzBu4="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js"integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI="crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>

    

    

    


    
    


    
    

</article>



    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2024 Zichen Wang
    </section>
    
    <section class="powerby">
        
              <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CC BY-SA 4.0</a>
   <br/>
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.16.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
