<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Neural networks with non-iterative learning methods - NCAA技术基础与应用 - 杨易旻 电子与计算机工程系'>
<title>watch: SNN - 杨易旻 | WeChat Live</title>

<link rel='canonical' href='https://zichen34.github.io/writenotes/model/subnetwork/d-vid-%E6%9D%A8%E6%98%93%E6%97%BB221020/'>

<link rel="stylesheet" href="/scss/style.min.8191399262444ab68b72a18c97392f5349be20a1615d77445be51e974c144cff.css"><meta property='og:title' content='watch: SNN - 杨易旻 | WeChat Live'>
<meta property='og:description' content='Neural networks with non-iterative learning methods - NCAA技术基础与应用 - 杨易旻 电子与计算机工程系'>
<meta property='og:url' content='https://zichen34.github.io/writenotes/model/subnetwork/d-vid-%E6%9D%A8%E6%98%93%E6%97%BB221020/'>
<meta property='og:site_name' content='Zichen Wang'>
<meta property='og:type' content='article'><meta property='article:section' content='WriteNotes' /><meta property='article:published_time' content='2023-01-27T10:19:00&#43;00:00'/><meta property='article:modified_time' content='2023-01-27T10:19:00&#43;00:00'/>
<meta name="twitter:title" content="watch: SNN - 杨易旻 | WeChat Live">
<meta name="twitter:description" content="Neural networks with non-iterative learning methods - NCAA技术基础与应用 - 杨易旻 电子与计算机工程系">
    <link rel="shortcut icon" href="/favicon-32x32.png" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu238e2fe759432347fa5dd53661ac4381_131637_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Zichen Wang</a></h1>
            <h2 class="site-description"></h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/zichen34'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://twitter.com/luckily1640'
                        target="_blank"
                        title="Twitter"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/aboutme/' >
                
                
                
                <span>About</span>
            </a>
        </li>
        
        
        <li >
            <a href='/writenotes/' >
                
                
                
                <span>WriteNotes</span>
            </a>
        </li>
        
        
        <li >
            <a href='/page/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#overview">Overview</a>
      <ol>
        <li><a href="#my-research-works">My research works</a></li>
      </ol>
    </li>
    <li><a href="#-single-layer-network-with-non-iterative-learning">Ⅰ. Single-layer network with non-iterative learning</a>
      <ol>
        <li><a href="#starting-with-a-small-idea">Starting with a small idea</a></li>
        <li><a href="#what-is-the-neural-network">What is the Neural Network?</a></li>
        <li><a href="#network-training">Network training</a></li>
        <li><a href="#what-is-extreme-learning-machine">What is Extreme Learning Machine?</a></li>
        <li><a href="#b-elm">B-ELM</a></li>
      </ol>
    </li>
    <li><a href="#-hierarchical-nn-with-subnetwork-neurons">Ⅱ. Hierarchical NN with Subnetwork Neurons</a>
      <ol>
        <li><a href="#single-layer-network-with-subnetwork-neurons">Single-Layer Network with Subnetwork Neurons</a></li>
        <li><a href="#two-layer-network-with-subnetwork-neurons">Two-Layer Network with Subnetwork Neurons</a></li>
        <li><a href="#hierarchical-network-with-subnetwork-neurons">Hierarchical Network with Subnetwork Neurons</a></li>
      </ol>
    </li>
    <li><a href="#-deep-networks-without-iterative-learning">Ⅲ. Deep Networks without iterative learning</a>
      <ol>
        <li><a href="#retraining-dcnn-with-the-non-iterative-strategy">Retraining DCNN with the non-iterative strategy</a></li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/writenotes/model/subnetwork/d-vid-%E6%9D%A8%E6%98%93%E6%97%BB221020/">watch: SNN - 杨易旻 | WeChat Live</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            Neural networks with non-iterative learning methods - NCAA技术基础与应用 - 杨易旻 电子与计算机工程系
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Jan 27, 2023</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    9 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p>下一代国际华人青年学子面对面 第6期 2022年10月20日 周四</p>
<h2 id="overview">Overview</h2>
<ol>
<li>Research work</li>
<li>Suggestions for graduate student (1st year)</li>
</ol>
<p>Research Contribution:</p>
<ol>
<li>
<p><strong>Non-iterative learning strategy for training neural networks</strong>
including single-layer networks, multi-layer networks, autoencoders, hierarchical networks, and deep networks.
All the related publications in this category are my first-author papers</p>
</li>
<li>
<p><strong>The proposed methods for pattern recognition related applications</strong>:
Image Recognition, Video Recognition, Hybrid System Approximation, Robotics System Identification, EEG-brain Signal Processing.
Most the related publications in this category are co-author papers with my HQPs.</p>
</li>
</ol>
<h3 id="my-research-works">My research works</h3>
<p>In the past 10 years, the works about Artificial neural networks：</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th>Theoretical Contributions to ANN</th>
<th>Machine Learning based Applications</th>
</tr>
</thead>
<tbody>
<tr>
<td>Single-layer network with non-iterative learning</td>
<td>Data Analysis and Robotics System Identification (Ph.D.)</td>
</tr>
<tr>
<td>Hierarchical NN with Subnetwork Neurons</td>
<td>Image Recognitions (Post Doctoral Fellow)</td>
</tr>
<tr>
<td>Deep Networks without iterative learning</td>
<td>Pattern Recognition (since 2018)</td>
</tr>
</tbody>
</table></div>
<h2 id="-single-layer-network-with-non-iterative-learning">Ⅰ. Single-layer network with non-iterative learning</h2>
<h3 id="starting-with-a-small-idea">Starting with a small idea</h3>
<p>The labtorary mainly studies robots, control, mechanics.
After 2008 Chinese Winter Storms, they got funding for creating Powerline De-icing robots.</p>
<p>The supervisor (Yaonan Wang): &ldquo;Can you find a Neural Network for Identifying Robotics Dynamic Systems?&rdquo; (in 2009 winter)</p>
<p>Later, I found the following paper:
&ldquo;Universal approximation using incremental constructive feedforward networks with random hidden nodes&rdquo;, By Huang, Guang-Bin et.al (Cannot be found on IEEE)
<a class="link" href="http://extreme-learning-machines.org/pdf/I-ELM.pdf"  target="_blank" rel="noopener"
    >version on elm portal</a></p>
<h3 id="what-is-the-neural-network">What is the Neural Network?</h3>
<p>Single hidden layer feedforward NN:</p>
<div class="mermaid">flowchart BT
subgraph in[Input Layer]
x1((1)) & xe(("...")) & xn((n))
end
subgraph hid[Hidden Layer]
h1(("𝛂₁,♭₁,𝛃₁")) & h2(("𝛂₂,♭₂,𝛃₂")) & he(("......")) & hL(("𝛂L,♭L,𝛃L"))
end
subgraph out[Output Layer]
y1((1)) & ye(("...")) & ym((m))
end
x1 & xn --> h1 & h2 & hL --> y1 & ym
</div>

<ul>
<li>Output of additive hidden neurons:
G(𝐚ᵢ, bᵢ, 𝐱) = g(𝐚ᵢ⋅𝐱+bᵢ)</li>
<li>Output of RBF hidden nodes:
G(𝐚ᵢ, bᵢ, 𝐱) = g‖𝐱-𝐚ᵢ‖</li>
<li>The output function of SLFNs is:
fₗ(𝐱) = ∑ₗ₌₁ᴸ 𝛃ᵢ⋅G(𝐚ᵢ, bᵢ, 𝐱)</li>
</ul>





  
  
  
  
   
  
  
   
  
  <img src= /writenotes/model/subnetwork/img/Yang_SLFN.jpg width=>
  
  


<h3 id="network-training">Network training</h3>
<p>Advantage: Approximate unknown system through learnable parameters.</p>
<p>Mathematical Model:</p>
<ul>
<li>
<p>Approximation capability: Any continuous target function f(x) can be approximated by Single-layer feedforward network with appropriate parameters (𝛂,♭,𝛃).
In other words, given any small positive value e, for SLFN with enough number of hidden nodes, we have: <br>
‖f(𝐱)-fₗ(𝐱)‖ &lt; e</p>
</li>
<li>
<p>In real applications, target function f(𝐱) is usually unknown. One wishes that unknown f could be approximated by the trained network fₗ(𝐱).</p>
</li>
</ul>
<h3 id="what-is-extreme-learning-machine">What is Extreme Learning Machine?</h3>
<p>Feed forward random network without using BP to train, such that it has a good real-time performance. And it fits the real-time robot task exactly.</p>
<h3 id="b-elm">B-ELM</h3>
<p>(2011) &ldquo;Bidirectional ELM for regression problem and its learning effectiveness&rdquo;, IEEE Trans. NNLS., 2012
<a class="link" href="https://ieeexplore.ieee.org/document/6222007"  target="_blank" rel="noopener"
    >paper</a></p>
<p>(23-02-10) This the inception of his subnetwork series work, and I was supposed to read this brief firt.
<a class="link" href="../ReadLit/B-note-B-ELM.md" >paperNote</a></p>





  
  
  
  
   
  
  
   
  
  <img src= /writenotes/model/subnetwork/img/Yang_B-ELM.jpeg width=>
  
  


<p><strong>Motivation</strong></p>
<ul>
<li>
<p>Original ELM has 3 kinds of parameters: 𝐚 is called the &ldquo;input weights&rdquo;, b is the bias, 𝛃 is the &ldquo;output weights&rdquo;,
which are consistent with earlier feedfoward network, though current single-layer feedfoward network has removed the 𝛃.</p>
<p>The 1st layer in ELM is generated randomly and the 2nd layer is constructed based on Moore-Penrose inverse without iteration.</p>
<div class="mermaid">flowchart LR
in((X)) --> lyr1["Layer1:\n 𝐚ⁿ, b\n Random\n Generated"]
--> weightSum1(("X⋅𝐚ⁿ + b")) --> act[Activation\n Function\n g]
--> z(("g(X⋅𝐚ⁿ+b)")) --> lyr2["Layer2:\n 𝛃"] 
--> weightSum2(("O =\n 𝛃⋅g(X⋅𝐚ⁿ+b)\n =T"))
-.->|"𝛃 =\n g(X⋅𝐚ⁿ+b)⁻¹T"| lyr2
classDef lyrs fill:#ff9
class lyr1,act,lyr2 lyrs;
</div>

</li>
<li>
<p>Bidirectional ELM</p>
<p>In original ELM, the 𝐚ⁿ,b are random numbers, but they can be yield if pulling the error back further, that is doing twice more inverse computation.
Therefore, in order to calculate the 𝐚ⁿ,b, there are 3 times inverse computation: for output weights 𝛃, activation function g(⋅) and activation z (X⋅𝐚ⁿ+b) respectively.</p>
<div class="mermaid">%%{ init: { 'flowchart': { 'curve': 'bump' } } }%%
flowchart LR
in((X)) --> lyr1["Layer1:\n 𝐚ⁿ, b\n Random\n Generated"]
--> weightSum1(("X⋅𝐚ⁿ + b")) --> act[Activation\n Function\n g]
--> z(("g(X⋅𝐚ⁿ+b)")) --> lyr2["Layer2:\n 𝛃"] --> out(("O =\n 𝛃⋅g(X⋅𝐚ⁿ+b)\n =T"))
-.->|"𝛃 =\n g(X⋅𝐚ⁿ+b)⁻¹T"| lyr2
classDef lyrs fill:#ff9
class lyr1,act,lyr2 lyrs;

out -.-> |"X⋅𝐚ⁿ+b =\n g⁻¹ T 𝛃⁻¹"|weightSum1
out -.-> |"𝐚ⁿ =\n X⁻¹ (g⁻¹ T 𝛃⁻¹ -b ),\n b = mse(O-T)"|lyr1 
</div>

<ol>
<li>𝛃 = [g(X⋅𝐚ⁿ+b)]⁻¹T</li>
<li>X⋅𝐚ⁿ+b = g⁻¹ T 𝛃⁻¹</li>
<li>𝐚ⁿ = X⁻¹ (g⁻¹ T 𝛃⁻¹ -b ), and b = mse(O-T)</li>
</ol>
</li>
</ul>
<p>The error is surprisingly small even with few hidden nodes.
Compared with the original ELM, the required neurons in this method are reduced by 100-400 times, and the testing error reduced 1%-3%, and also the training time reduced 26-250 times over 10 datasets.</p>
<p><strong>Major differences</strong></p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th></th>
<th>Randomized Networks</th>
<th>Bidirectional ELM</th>
</tr>
</thead>
<tbody>
<tr>
<td>Classifier</td>
<td>ELM; Echo State Netowrk;<br> Random Forest;<br> Vector Functional-link Network</td>
<td>Only works for regression task</td>
</tr>
<tr>
<td>Performance</td>
<td></td>
<td>Similar performance;<br> Faster speed;<br> Less required neurons</td>
</tr>
<tr>
<td>Learning strategy</td>
<td>(Semi-)Randomized input weights;<br> Non-iterative training;<br> Single-layer network</td>
<td>Non-iterative training;<br> Single-layer network;<br> Calculated weights in a network</td>
</tr>
</tbody>
</table></div>
<h2 id="-hierarchical-nn-with-subnetwork-neurons">Ⅱ. Hierarchical NN with Subnetwork Neurons</h2>
<h3 id="single-layer-network-with-subnetwork-neurons">Single-Layer Network with Subnetwork Neurons</h3>
<p>In 2014, deep learning is becoming popular. How to extend the B-ELM as a multi-layer network? <br>
&ldquo;Extreme Learning Machine With Subnetwork Hidden Nodes for Regression and Classification&rdquo;.
<a class="link" href="https://ieeexplore.ieee.org/document/8627989"  target="_blank" rel="noopener"
    >paper</a>; <a class="link" href="https://zichen34.github.io/writenotes/model/subnetwork/b-note-elm-subnet/" >paperNote</a></p>
<p><strong>Motivation</strong></p>
<div class="mermaid">flowchart TB
base[Bidirectional ELM] --> theory[Theoretical Contributions on ANN] & app[Industrial Applications]
theory --> multilyr[1. Two-layer Neural Networks?\n 2. Hierarchical Neural Networks?]
app --> tasks[1. Feature Extraction\n 2. Dimension Reduction\n 3. Image Recognition]
</div>

<p>Pull the residual error back to multiple B-ELMs sequentially:</p>
<div class="mermaid">flowchart LR
in((X)) --> lyr11 & lyr21 & lyrN1

subgraph net1[B-ELM 1]
lyr11["𝐚¹,b¹"] ==>|"X⋅𝐚¹+b¹"| act1[g] ==>|"g(X⋅𝐚¹+b¹)"|lyr12["𝛃¹"] ==>|"𝛃¹⋅g(X⋅𝐚¹+b¹)"| out(("O ➔ T\n E=T"))
-.-> lyr12 -.-> act1 -.-> lyr11
lyr11 --> act1 --> lyr12 
end
lyr12 --> out1(("O¹➔T\n E=T-O¹")) -.-> lyr22

subgraph net2[B-ELM 2]
lyr22["𝛃²"] -.-> act2[g] -.-> lyr21["𝐚²,b²"]
lyr21 -->|"X⋅𝐚² + b²"|act2 -->|"g(X⋅𝐚²+b²)"|lyr22 
end
lyr22--> out2(("O²+O¹➔T\n E=T-(O²+O¹)")) 

out2 -.->|"Solve\n multiple\n B-ELMs"| outn-1(("E=T-∑ᵢ₌₁ᴺ⁻¹ Oⁱ"))-.->lyrN2
%%out2 -.-> lyrn2
%%subgraph nets[multiple B-ELMs]
%%lyrn2["𝛃ⁿ"] -.-> actn[g] -.-> lyrn1["𝐚ⁿ,bⁿ"]
%%lyrn1 -->|"X⋅𝐚ⁿ + bⁿ"|actn -->|"g(X⋅𝐚ⁿ+bⁿ)"|lyrn2
%%end
%%lyrn2 --> outn-1(("E=T-∑ᵢ₌₁ᴺ⁻¹ Oⁱ"))-.->lyrN2

subgraph netN["B-ELM N"]
lyrN2["𝛃ᴺ"] -.-> actN[g] -.-> lyrN1["𝐚ᴺ,bᴺ"]
lyrN1 -->|"X⋅𝐚ᴺ + bᴺ"|actN -->|"g(X⋅𝐚ᴺ+bᴺ)"|lyrN2 
end
lyrN2--> outN(("∑ᵢ₌₁ᴺ Oⁱ➔T"))

classDef lyrs fill:#ff9
class lyr11,act1,lyr12,lyr21,act2,lyr22,lyrN1,actN,lyrN2 lyrs;
linkStyle 9,10,11,15,16,17,22,23,24 stroke:#0af,stroke-width:3px
%%classDef node font-size:20px;
</div>

<p>Dotted links are computation with inverse.
<font color="#0bf">Cyan links</font> is the second feedforward using the updated parameters to give a trustworthy result O¹.
The objective is to approach the target T, so there is a residual error E=T-O¹.
Then another B-ELM (with same structure) is used to reduce the error continuously.
And this time, the prediction is O²+O¹, which is the approximation of T.
Here, the residual error is E=T-(O²+O¹)</p>
<p>Repeatedly pulling the residual error to a new B-ELM N times is equivalent to N SLFNs. But B-ELM is fast without iteration and less computation with a few hidden nodes in each SLFN.</p>
<p>Based on original SLFN structure, each node contains a SLFN.</p>





  
  
  
  
   
  
  
   
  
  <img src= /writenotes/model/subnetwork/img/Yang_Subnetwork_Nodes.jpeg width=>
  
  


<h3 id="two-layer-network-with-subnetwork-neurons">Two-Layer Network with Subnetwork Neurons</h3>
<p>(2015) How to extend the Single-layer network with subnetwork nodes system to a two-layer network system?</p>
<p>A general two-layer system was built in paper: &ldquo;Multilayer Extreme Learning Machine with Subnetwork Hidden Neurons for Representation Learning&rdquo;
<a class="link" href="https://ieeexplore.ieee.org/abstract/document/7295596"  target="_blank" rel="noopener"
    >paper</a>; <a class="link" href="https://zichen34.github.io/writenotes/model/subnetwork/b-note-elm-mltlyr/" >paperNote</a></p>





  
  
  
  
   
  
  
   
  
  <img src= /writenotes/model/subnetwork/img/Yang_Two-layers_ELM.jpeg width=>
  
  


<p>Though it only contains two &ldquo;general&rdquo; layers, this system includes hundreds of networks, and it&rsquo;s fast due to the modest quantity and no iteration.</p>
<p>Compared with ELM and B-ELM, it got better performance over 35 datasets:</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th></th>
<th>Classification (vs ELM)</th>
<th>Regression (vs B-ELM)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Required Neurons</td>
<td>Reduced 2-20 times</td>
<td>Reduced 13-20%</td>
</tr>
<tr>
<td>Metrics</td>
<td>Accuracy increase 1-17%</td>
<td>Testing error reduced 1-8%</td>
</tr>
<tr>
<td>Training Speed</td>
<td>faster 25-200times</td>
<td>faster 5-20%</td>
</tr>
</tbody>
</table></div>
<p>Two-layer network system can perform image compression or reconstruciton, etc.
This method is better than Deep Belief Network on small datasets.
But it&rsquo;s inferior than deep learning with transfer learning technics on huge datasets.</p>
<h3 id="hierarchical-network-with-subnetwork-neurons">Hierarchical Network with Subnetwork Neurons</h3>
<p>&ldquo;Features combined from hundreds of mid-layers: Hierarchical networks with subnetwork nodes&rdquo; IEEE Trans. NNLS, 2019.
<a class="link" href="https://ieeexplore.ieee.org/document/8627989"  target="_blank" rel="noopener"
    >paper</a></p>





  
  
  
  
   
  
  
   
  
  <img src= /writenotes/model/subnetwork/img/Yang_Hierarchical_Network.jpeg width=>
  
  


<p>From a single-layer network with subnetwork neurons to the multi-layer network, and then to a neural network system, these 3 papers cost 5 years or so.</p>
<p>Compared with deep learning network, it&rsquo;s extremely fast and performs well on small datasets, like Scene15, Caltech101, Caltech256.
But for large datasets, deep learning is the winner.</p>
<p>&ldquo;Somewhat regretfully, I turned to deep learning a bit late. But been hesitant to do research along this approach.&rdquo;</p>
<p><strong>Major differences between ours and Deep Networks</strong></p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th></th>
<th>SGD based methods in DCNN</th>
<th>Moore-Penrose inverse matrix based methods</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hyper params</td>
<td>lr; momentum; bs; L2 regulariation; epochs</td>
<td>L2 regularization (non-sensitive)</td>
</tr>
<tr>
<td>Performance</td>
<td>higher performance in Computer Vision tasks (with huge datasets);<br> GPU-based computation resource;<br> More parameters;<br> More required training time</td>
<td>Faster learning speed/less tuning;<br> Promising performance in Tabular Datasets;<br> Less over-fitting problem.</td>
</tr>
</tbody>
</table></div>
<h2 id="-deep-networks-without-iterative-learning">Ⅲ. Deep Networks without iterative learning</h2>
<p>Since 2018: How to combine the non-iterative method (M-P inverse matrix) with deep convolutional network to gain advantages? This took 2-3 years.</p>
<p>This is the age of Deep Learning.</p>
<ul>
<li>
<p>Interesting 20 years of cycles</p>
<ul>
<li>Rosenblatt&rsquo;s Perceptron proposed in mid of 1950s, sent to &ldquo;winter&rdquo; in 1970s.</li>
<li>Back-Propagation and Hopfield Network Proposed in 1970s, reaching research peak in mid of 1990s.</li>
<li>Support vector machines proposed in 1995, reaching research peak early this century.</li>
</ul>
</li>
<li>
<p>There are exceptional cases:</p>
<ul>
<li>Most basic deep learning algorithms proposed in 1960s-1980s, becoming popular only since 2012 (for example, LeNet proposed in 1989).</li>
</ul>
</li>
</ul>
<p>ImageNet pushed deep learning, because only when the huge network structure of deep learning meets the matched huge dataset, it can achive good performance.</p>
<p>The success of deep learning enlist three factors: 1. NN structure and algorithm; 2. Big data; 3. GPU availability.</p>
<p>Hundreds of layers result in tedious training time. &ldquo;The study intensity is infinitely small and the study duration is infinitely large.&rdquo;</p>
<blockquote>
<p>&ldquo;The improvement space of deep neural network is limited. So can we introduce non-iterative learning strategies for training deep networks&rdquo;</p>
</blockquote>
<p>Training speed is more important for scientific research than accuracy.
And also it&rsquo;s necessary to reduce the dependence on GPUs and the involvement of undeterministic hyper parameters (lr,bs,&hellip;)</p>
<h3 id="retraining-dcnn-with-the-non-iterative-strategy">Retraining DCNN with the non-iterative strategy</h3>
<p>(2019): &ldquo;Recomputation of the dense layers for the performance improvement of DCNN.&rdquo; IEEE TPAMI, 2020.
<a class="link" href="https://ieeexplore.ieee.org/document/8718406"  target="_blank" rel="noopener"
    >link</a></p>
<p><strong>Motivation</strong></p>
<div class="mermaid">graph LR
base["1. Two-layer Neural Networks\n 2. Hierarchical Neural Networks"]
--> explore["1. Deep learning withe non-iterative method"]
</div>






  
  
  
  
   
  
  
   
  
  <img src= /writenotes/model/subnetwork/img/Yang_NonIterative&#43;CNN.jpeg width=>
  
  


<p>In a DCNN, the first few layers are convolutional layers, maxpooling, then there&rsquo;re 3 or 1 dense layer.</p>
<blockquote>
<p>If I cannot train all of the hundreds layers in my non-iterative method, can I train only certain layers that are easy trained with my method, rather the SGD?</p>
</blockquote>





  
  
  
  
   
  
  
   
  
  <img src= /writenotes/model/subnetwork/img/Yang_Retrain_FC_CNN.jpeg width=>
  
  


<p>Only the fully-connected layers are trained by non-iterative method (inverse matrix), and the rest of layers are trained by gradient descent (SGD, SGDM, Adam).</p>
<p>On some medium-size datasets(CIFAR10, CIFAR100, SUN397), this approach brought a moderate improvement because there are only 3 dense layer out of a 50/100-layer network (most of layers are trained with SGD), but speeds up the training.</p>
<p>One layer can be trained within 1-2 seconds.</p>

</section>


    <footer class="article-footer">
    

    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css"integrity="sha256-J&#43;iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s="crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js"integrity="sha256-InsNdER1b2xUewP&#43;pKCUJpkhiqwHgqiPXDlIk7GzBu4="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js"integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI="crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>

    

    
      <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
      <script>
        mermaid.initialize({ startOnLoad: true });
      </script>
    

    


    
    


    
    

</article>



    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2024 Zichen Wang
    </section>
    
    <section class="powerby">
        
              <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CC BY-SA 4.0</a>
   <br/>
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.16.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
