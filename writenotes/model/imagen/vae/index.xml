<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>VAE on Zichen Wang</title>
        <link>https://zichen34.github.io/writenotes/model/imagen/vae/</link>
        <description>Recent content in VAE on Zichen Wang</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language><atom:link href="https://zichen34.github.io/writenotes/model/imagen/vae/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>read: VAE</title>
        <link>https://zichen34.github.io/writenotes/model/imagen/vae/b-note-vae/</link>
        <pubDate>Wed, 07 Jun 2023 10:00:00 +0000</pubDate>
        
        <guid>https://zichen34.github.io/writenotes/model/imagen/vae/b-note-vae/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1312.6114&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Arxiv&lt;/a&gt;
| &lt;a class=&#34;link&#34; href=&#34;https://keras.io/examples/generative/vae/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Code-keras&lt;/a&gt;
| &lt;a class=&#34;link&#34; href=&#34;https://github.com/bojone/vae/blob/master/cvae_keras.py&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Code-cvae&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Another paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1906.02691&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;em&gt;An Introduction to Variational Autoencoders&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Recognition model with parameters φ, $q_φ(𝐳|𝐱)$, approximates the intractable posterior distribution;&lt;/p&gt;
&lt;p&gt;Generative model with parameters θ, $p_θ(𝐳)p_θ(𝐱|𝐳)$, maps a latent variable to a &amp;ldquo;sample&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;directed probabilistic model&lt;/p&gt;
&lt;p&gt;The distribution of an i.i.d. dataset with latent variables P(𝐗,𝐙)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;continuous latent variables with intractable posterior distributions&lt;/p&gt;
&lt;p&gt;The latent variable 𝐳 per datapoint is continuous, so its posterior distribution $p_θ(𝐳|𝐱)$ cannot be computed explicitly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reparameterization of the variational lower bound yields a lower bound estimator&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lower bound estimator can be optimized using SGD,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Variational Bayesian approach involves the optimization of an approximation to the intractable posterior.&lt;/p&gt;
&lt;p&gt;Use q(𝐳) to approximate $p_θ(𝐳|𝐱)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mean-field approach requires analytical solutions of expectations w.r.t. the approximate posterior&lt;/p&gt;
&lt;p&gt;𝔼_{q(𝐳)} [  ]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;q(𝐳) is also intractable&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;h3 id=&#34;problem-scenario&#34;&gt;Problem scenario&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Each sample is generated by two steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;sample a 𝐳 from prior distribution $p_{θ^*}(𝐳)$&lt;/li&gt;
&lt;li&gt;Sample an 𝐱 from the conditional distribution $p_{θ^*}(𝐱|𝐳)$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;where θ* is the true parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Intractability:&lt;/p&gt;
&lt;p&gt;The integral of the marginal likelihood $p_θ(𝐱) = ∫ p_θ(𝐳) p_θ(𝐱|𝐳) d𝐳 = ∫ p_θ(𝐱,𝐳) d𝐳$ cannot be computed,
because 𝐳 is a high-dimensional continuous variable.&lt;/p&gt;
&lt;p&gt;Such that the true posterior density $p_θ(𝐳|𝐱) = \frac{ p_θ(𝐱|𝐳) p_θ(𝐳) }{ p_θ(𝐱) }$ is also intractable,
because the denominator marginal likelihood cannot be computed.&lt;/p&gt;
&lt;p&gt;That means the EM algorithm cannot be used,
because in each iteration the introduced prior distribution q(𝐳) needs to be equal to $p_θ(𝐳|𝐱)$, which however is intractable.&lt;/p&gt;
&lt;p&gt;And any reasonable mean-field variational bayesian algorithms are intractable,
where the $p_θ(𝐳|𝐱)$ is used as the objective of approximating by q(𝐳), but it doesn&amp;rsquo;t work for $p_θ(𝐳|𝐱)$ that cannot be computed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A large dataset:&lt;/p&gt;
&lt;p&gt;Sampling-based methods, e.g. Monte Carlo EM, would be too slow,
because sampling is performed on every datapoint.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Three meaningful problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Estimating the parameter θ of the distribution via MLE or MAP can allow mimicking the data-generating process: Sample 𝐳 first then sample the x from the conditional distribution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;MLE try to find the θ that makes the probability of dataset X &lt;strong&gt;given Z&lt;/strong&gt; maximum.
MLE is to estimate &lt;strong&gt;parameter&lt;/strong&gt; θ, while VAE is to estimate the &lt;strong&gt;distribution&lt;/strong&gt; of X.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MAP believe that the θ having the maximum posterior probability given a dataset likelihood p(X|θ) and prior probability p(θ) according to, $p(θ|X) = \frac{p(X|θ) p(θ)}{p(X)}$, is the most possible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;EM algorithm uses MLE to find the &lt;strong&gt;parameter&lt;/strong&gt; θ of a probabilistic model involving latent variable,
where assume the prior probability q(𝐳) = posterior probability $p_θ(𝐳|𝐱)$ of the latent variable, then apply MLE find optimal θ.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Approximating the &lt;strong&gt;posterior probability&lt;/strong&gt; $p_θ(𝐳|𝐱)$ given an observed value 𝐱 and a choice of parameters θ is useful for encoding data.&lt;/p&gt;
&lt;p&gt;The latent variable 𝐳 can be regarded as a latent representation of a datapoint 𝐱.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Approximating the &lt;strong&gt;marginal likelihood&lt;/strong&gt; $p_θ(𝐱)$ enable to perform those inference tasks where the prior p(𝐱) is required, e.g. image denoising and inpainting.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above three goals can be tackled by a recognition model $q_φ(𝐳|𝐱)$,
which is an approximation to the intractable posterior probability $p_θ(𝐳|𝐱)$&lt;/p&gt;
&lt;p&gt;The recognition model $q_φ(𝐳|𝐱)$ is a probabilistic &lt;strong&gt;encoder&lt;/strong&gt;, which produces a distribution over &lt;strong&gt;all&lt;/strong&gt; possible values of 𝐳 with given a datapoint 𝐱.&lt;/p&gt;
&lt;p&gt;(Each datapoint 𝐱 corresponds to a distribution $q_φ(𝐳|𝐱)$ with some parameters (e.g., μ,σ).)&lt;/p&gt;



&lt;div class=&#34;goat svg-container &#34;&gt;
  
    &lt;svg
      xmlns=&#34;http://www.w3.org/2000/svg&#34;
      font-family=&#34;Menlo,Lucida Console,monospace&#34;
      
        viewBox=&#34;0 0 376 169&#34;
      &gt;
      &lt;g transform=&#39;translate(8,16)&#39;&gt;
&lt;path d=&#39;M 32,48 L 40,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 104,48 L 112,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,48 L 232,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 296,48 L 304,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,64 L 128,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 128,64 L 152,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 208,64 L 320,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 320,64 L 344,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 16,16 L 16,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 208,16 L 208,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;polygon points=&#39;24.000000,16.000000 12.000000,10.400000 12.000000,21.600000&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 16.000000, 16.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;160.000000,64.000000 148.000000,58.400002 148.000000,69.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 152.000000, 64.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;216.000000,16.000000 204.000000,10.400000 204.000000,21.600000&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 208.000000, 16.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;352.000000,64.000000 340.000000,58.400002 340.000000,69.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 344.000000, 64.000000)&#39;&gt;&lt;/polygon&gt;
&lt;path d=&#39;M 72,16 A 16,16 0 0,0 56,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 72,16 A 16,16 0 0,1 88,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 264,16 A 16,16 0 0,0 248,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 264,16 A 16,16 0 0,1 280,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 32,48 A 16,16 0 0,0 16,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 56,32 A 16,16 0 0,1 40,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 88,32 A 16,16 0 0,0 104,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 112,48 A 16,16 0 0,1 128,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 224,48 A 16,16 0 0,0 208,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 248,32 A 16,16 0 0,1 232,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 280,32 A 16,16 0 0,0 296,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 304,48 A 16,16 0 0,1 320,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐳&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;D&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;|&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐱&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;f&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;y&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;v&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;E&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;80&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;80&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;80&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;88&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;88&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;88&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;104&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;104&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;104&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐱&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;f&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐳&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐳&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐱&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;|&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;D&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐳&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;f&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;240&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;240&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;y&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;240&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;256&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;256&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;256&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;264&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;264&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;272&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;272&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;v&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;272&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;D&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;280&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;280&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;280&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;288&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;288&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;288&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;296&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;296&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;304&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;304&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;304&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;312&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;320&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;320&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐳&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;320&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;328&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;f&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;328&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;344&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐱&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;360&#39; y=&#39;68&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝐱&lt;/text&gt;
&lt;/g&gt;

    &lt;/svg&gt;
  
&lt;/div&gt;
&lt;p&gt;A 𝐳 produces a conditional distribution p(𝐱|𝐳), from which a datapoint 𝐱 is generated. So the generative model $p_θ(𝐱|𝐳)$ is called probabilistic &lt;strong&gt;decoder&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;(2023-07-09)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;So a training step is: sampling a 𝐳 from distribution p(𝐳|𝐱), then with this 𝐳, find the parameter θ that makes the probability p(𝐱|𝐳) largest based on MLE.
That&amp;rsquo;s why the loss funciton has a cross-entropy term that measures the likelihood of output 𝐱&amp;rsquo;, i.e., log p(𝐱|𝐳).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;According to KL-divergence $-q(𝐳) log \frac{p(𝐳|𝐱)}{q(𝐳)}$, the approximated posterior q(𝐳) is supposed to equal the real posterior p(𝐳|𝐱),
which, however, is intractable.
So the authors use network and reparameterization to estimate the parameters (mean, variance) of the posterior.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(I think) 𝐳 sampled from posterior can be one value or multiple times and doing average.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;22-the-variational-bound&#34;&gt;2.2 The Variational bound&lt;/h3&gt;
&lt;p&gt;The marginal likelihood of the dataset with N datapoints is a sum over the marginal likelihoods of individual datapoints:&lt;/p&gt;
&lt;p&gt;$log\ p_θ(𝐱⁽¹⁾, &amp;hellip;, 𝐱⁽ᴺ⁾ ) = ∑ᵢ₌₁ᴺ log\ p_θ(𝐱⁽ⁱ⁾)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Rewrite it by introducing posterior approximation $q_φ(𝐳|𝐱⁽ⁱ⁾)$ to make up KL divergence:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;amp;log\ p_θ(𝐱⁽ⁱ⁾)  \\
&amp;amp;= log\ (\frac{p_θ(𝐱⁽ⁱ⁾|𝐳) p_θ(𝐳)}{p_θ(𝐳|𝐱⁽ⁱ⁾)} ) \\
&amp;amp;= log\ (p_θ(𝐱⁽ⁱ⁾|𝐳) p_θ(𝐳)) - log\ p_θ(𝐳|𝐱⁽ⁱ⁾) \\
&amp;amp;= log\ (p_θ(𝐱⁽ⁱ⁾|𝐳) p_θ(𝐳)) - log\ p_θ(𝐳|𝐱⁽ⁱ⁾) \\
&amp;amp;\quad  + log\ q_φ(𝐳|𝐱⁽ⁱ⁾) - log\ q_φ(𝐳|𝐱⁽ⁱ⁾) \\
&amp;amp;= log\ \frac{p_θ(𝐱⁽ⁱ⁾|𝐳) p_θ(𝐳)}{q_φ(𝐳|𝐱⁽ⁱ⁾)} - log\ \frac{p_θ(𝐳|𝐱⁽ⁱ⁾)}{q_φ(𝐳|𝐱⁽ⁱ⁾)}\\
\end{aligned}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute &lt;strong&gt;expectations&lt;/strong&gt; w.r.t. the approximate posterior $q_φ(𝐳|𝐱)$ for both side:&lt;/p&gt;
&lt;p&gt;$$
∫q_φ(𝐳|𝐱⁽ⁱ⁾) log\ p_θ(𝐱⁽ⁱ⁾) d𝐳 = \\
∫q_φ(𝐳|𝐱⁽ⁱ⁾) \left[log\ \frac{p_θ(𝐱⁽ⁱ⁾|𝐳) p_θ(𝐳)}{q_φ(𝐳|𝐱⁽ⁱ⁾)} - log\ \frac{p_θ(𝐳|𝐱⁽ⁱ⁾)}{q_φ(𝐳|𝐱⁽ⁱ⁾)} \right] d𝐳
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Left-hand side remains marginal likelihood $log\ p_θ(𝐱⁽ⁱ⁾)$ (i.e. $𝔼_{q_φ(𝐳|𝐱⁽ⁱ⁾)} [ log\ p_θ(𝐱⁽ⁱ⁾) ]$) because p(x) has nothing to do with z.&lt;/p&gt;
&lt;p&gt;While right-hand side is the &lt;strong&gt;lower bound&lt;/strong&gt; plus &lt;strong&gt;KL divergence&lt;/strong&gt;: &lt;div id=&#34;eq2&#34;&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;amp; log\ p_θ(𝐱⁽ⁱ⁾) = \\
&amp;amp; ∫q_φ(𝐳|𝐱⁽ⁱ⁾) log\ \frac{p_θ(𝐱⁽ⁱ⁾|𝐳) p_θ(𝐳)}{q_φ(𝐳|𝐱⁽ⁱ⁾)} d𝐳 \\
&amp;amp;\quad - ∫q_φ(𝐳|𝐱⁽ⁱ⁾) log\ \frac{p_θ(𝐳|𝐱⁽ⁱ⁾)}{q_φ(𝐳|𝐱⁽ⁱ⁾)} d𝐳 \\
&amp;amp; = ℒ(θ,φ; 𝐱⁽ⁱ⁾) + D_{KL} ( q_φ(𝐳|𝐱⁽ⁱ⁾) || p_θ(𝐳|𝐱⁽ⁱ⁾ ) \\
&amp;amp;  \\
&amp;amp; = 𝔼_{q_φ(𝐳|𝐱⁽ⁱ⁾)} [log\ p_θ(𝐱⁽ⁱ⁾,𝐳) - log\ q_φ(𝐳|𝐱⁽ⁱ⁾)] \\
&amp;amp;\quad + D_{KL} ( q_φ(𝐳|𝐱⁽ⁱ⁾) || p_θ(𝐳|𝐱⁽ⁱ⁾ ) \quad (2)
\end{aligned}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In another way, the lower bound can also be written as eq.(3): &lt;div id=&#34;eq3&#34;&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;𝓛$(θ,φ; 𝐱⁽ⁱ⁾) = -D_{KL} ( q_φ(𝐳|𝐱⁽ⁱ⁾) || p_θ(𝐳) ) + 𝔼_{q_φ(𝐳|𝐱⁽ⁱ⁾)} [log\ p_θ(𝐱⁽ⁱ⁾|𝐳)]$&lt;/p&gt;
&lt;p&gt;whose derivation starts from the conditional probability $p_θ(𝐱⁽ⁱ⁾|𝐳)$:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The likelihood of the i-th datapoint:
$$
\begin{aligned}
&amp;amp; log(p_θ(𝐱⁽ⁱ⁾|𝐳))  \\
&amp;amp;= log( \frac{p_θ(𝐳|𝐱⁽ⁱ⁾)p_θ(𝐱⁽ⁱ⁾))}{p_θ(𝐳)} )\\
&amp;amp;= log( \frac{ p_θ(𝐳|𝐱⁽ⁱ⁾)p_θ(𝐱⁽ⁱ⁾)* q_φ(𝐳|𝐱⁽ⁱ⁾) ) }{ p_θ(𝐳)*q_φ(𝐳|𝐱⁽ⁱ⁾) } ) \\
&amp;amp;= log( \frac{ p_θ(𝐳|𝐱⁽ⁱ⁾)p_θ(𝐱⁽ⁱ⁾)}{q_φ(𝐳|𝐱⁽ⁱ⁾)} ) -
log( \frac{p_θ(𝐳)}{q_φ(𝐳|𝐱⁽ⁱ⁾)} )
\end{aligned}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the expectation w.r.t. approximate posterior $q_φ(𝐳|𝐱⁽ⁱ⁾)$:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;amp; ∫q_φ(𝐳|𝐱⁽ⁱ⁾)\ log(p_θ(𝐱⁽ⁱ⁾|𝐳)) d𝐳 = \\
&amp;amp; ∫q_φ(𝐳|𝐱⁽ⁱ⁾) log( \frac{ p_θ(𝐳|𝐱⁽ⁱ⁾)p_θ(𝐱⁽ⁱ⁾)}{q_φ(𝐳|𝐱⁽ⁱ⁾)})d𝐳\\
&amp;amp; \quad - ∫q_φ(𝐳|𝐱⁽ⁱ⁾) log( \frac{p_θ(𝐳)}{q_φ(𝐳|𝐱⁽ⁱ⁾)} ) d𝐳 \\
&amp;amp; \\
&amp;amp; 𝔼_{q_φ(𝐳|𝐱⁽ⁱ⁾)} [log\ p_θ(𝐱⁽ⁱ⁾|𝐳))] = \\
&amp;amp; \quad ℒ(θ,φ; 𝐱⁽ⁱ⁾) + D_{KL} ( q_φ(𝐳|𝐱⁽ⁱ⁾ || p_θ(𝐳))
\end{aligned}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, using Monte Carlo to estimate gradient of 𝓛 (an expectation) will bring high variance.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;23-sgvb-estimator-and-aevb-algo&#34;&gt;2.3 SGVB estimator and AEVB algo&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;A practical estimator of the lower bound 𝓛 of the likelihood and its derivatives w.r.t. the parameters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(With some mild conditions for a selected approximate posterior distribution $q_φ(𝐳|𝐱)$,)&lt;/p&gt;
&lt;p&gt;Consider a variable $\~𝐳$ that comes from $\~𝐳 = g_φ$(𝛆,𝐱) with 𝛆 ~ p(𝛆),
follows the posterior distribution $\~𝐳 \sim q_φ(𝐳|𝐱)$ (or not conditioned distribution $q_φ(𝐳)$). &lt;br&gt;
And $g_φ$(𝛆,𝐱) is a &lt;strong&gt;deterministic differentiable transformation&lt;/strong&gt; of an (auxiliary) noise variable 𝛆.&lt;/p&gt;
&lt;p&gt;Since $\~𝐳$ is a transformation of 𝛆, $\~𝐳$ follows the distribution p(𝛆) as well.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Monte Carlo estimation&lt;/p&gt;
&lt;p&gt;Therefore, using Monte Carlo (i.e., averaging the L sampled values) to approximate an expectation of some function $f(𝐳)$ w.r.t. the posterior approximation $q_φ(𝐳|𝐱⁽ⁱ⁾)$ becomes:&lt;/p&gt;
&lt;p&gt;$$
𝔼_{q_φ(𝐳|𝐱⁽ⁱ⁾)} [f(𝐳)] = 𝔼_{p(ε)} [f( g_φ(ε, 𝐱⁽ⁱ⁾) )] \\
≃  \frac{1}{L} ∑ₗ₌₁ᴸ f( g_φ(ε⁽ˡ⁾, 𝐱⁽ⁱ⁾) ),
$$
where 𝛆⁽ˡ⁾~ p(𝛆).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Approximate lower bound with &lt;a class=&#34;link&#34; href=&#34;#eq2&#34; &gt;eq. (2)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The version A of SGVB estimator comes from eq. (2), the lower bound 𝓛 should be finally equal to that ELBO expectation,
𝓛ᴬ (𝛉,𝛗,𝐱⁽ⁱ⁾) ≃ 𝓛 (𝛉,𝛗,𝐱⁽ⁱ⁾) i.e., the KL divergence=0.&lt;/p&gt;
&lt;p&gt;And that expectation can be approximated via Monte Carlo (sampling), so the lower bound is approximated as:&lt;/p&gt;
&lt;p&gt;$$
\~\mathcal L^A (θ,φ,𝐱⁽ⁱ⁾) = \\
\frac{1}{L}  ∑ₗ₌₁ᴸ \left[ log\ p_θ(𝐱⁽ⁱ⁾, 𝐳⁽ⁱ&amp;rsquo;ˡ⁾) - log\ q_φ(𝐳⁽ⁱ&amp;rsquo;ˡ⁾| 𝐱⁽ⁱ⁾) \right] \\
$$&lt;/p&gt;
&lt;p&gt;where $𝐳⁽ⁱ&amp;rsquo;ˡ⁾= g_φ(ε⁽ⁱ&amp;rsquo;ˡ⁾, 𝐱⁽ⁱ⁾))$ and 𝛆⁽ˡ⁾~ p(𝛆)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Approximate lower bound with &lt;a class=&#34;link&#34; href=&#34;#eq3&#34; &gt;eq. (3)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Since the KL-divergence $D_{KL}( q_φ(𝐳|𝐱⁽ⁱ⁾) || p_θ(𝐳) )$ of eq. (3) can be integrated analytically,
it can be substituted into eq. (3), then only that expectation (&amp;ldquo;expected reconstruction error&amp;rdquo; $𝔼_{q_φ(𝐳|𝐱⁽ⁱ⁾)} [log\ p_θ(𝐱⁽ⁱ⁾|𝐳))]$) is approximated,
so the second version of lower bound approximation: 𝓛ᴮ (𝛉,𝛗,𝐱⁽ⁱ⁾) ≃ 𝓛 (𝛉,𝛗,𝐱⁽ⁱ⁾) is more relatively accurate than the version A.&lt;/p&gt;
&lt;p&gt;$$
\tilde{\mathcal L^B} =
-D_{KL}( q_φ(𝐳|𝐱⁽ⁱ⁾) || p_θ(𝐳) ) \\
\qquad + \frac{1}{L}  ∑ₗ₌₁ᴸ log\ p_θ(𝐱⁽ⁱ⁾ | 𝐳⁽ⁱ&amp;rsquo;ˡ⁾)
$$&lt;/p&gt;
&lt;p&gt;where $𝐳⁽ⁱ&amp;rsquo;ˡ⁾= g_φ(ε⁽ⁱ&amp;rsquo;ˡ⁾, 𝐱⁽ⁱ⁾))$ and 𝛆⁽ˡ⁾~ p(𝛆).&lt;/p&gt;
&lt;p&gt;The KL-divergence there can be interpreted as regularizer, and the optimization objective is enlarging the &amp;ldquo;expected negative reconstruction error&amp;rdquo;, i.e., recover original 𝐱 from code 𝐳.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train with minibatches&lt;/p&gt;
&lt;p&gt;Given a dataset 𝐗 with N datapoints, each time M datapoints are drawn as a minibatch,
then the marginal likelihood lower bound of the full dataset batch-by-batch is estimated as:&lt;/p&gt;
&lt;p&gt;$$
\mathcal L(\pmb{θ,φ},𝐱) \simeq \mathcal L^M (\pmb{θ,φ},𝐗ᴹ) =
\frac{N}{M} ∑ᵢ₌₁ᴹ \tilde{\mathcal L} (\pmb{θ,φ},𝐱⁽ⁱ⁾)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;24-reparameterization-trick&#34;&gt;2.4 Reparameterization trick&lt;/h3&gt;
&lt;p&gt;Previously, 𝐳 is sampled directly, then input to model $p_θ(𝐱|𝐳)$, but the parameter φ of the distribution of 𝐳 is not able to be optimized via gradient descent, since Monte Carlo isn&amp;rsquo;t differentiable.&lt;/p&gt;



&lt;div class=&#34;goat svg-container &#34;&gt;
  
    &lt;svg
      xmlns=&#34;http://www.w3.org/2000/svg&#34;
      font-family=&#34;Menlo,Lucida Console,monospace&#34;
      
        viewBox=&#34;0 0 280 121&#34;
      &gt;
      &lt;g transform=&#39;translate(8,16)&#39;&gt;
&lt;path d=&#39;M 144,48 L 168,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 8,80 L 104,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 104,80 L 120,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 8,16 L 8,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 208,80 L 216,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 228,40 L 236,24&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 208,16 L 216,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 228,56 L 236,72&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;polygon points=&#39;16.000000,16.000000 4.000000,10.400000 4.000000,21.600000&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 8.000000, 16.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;128.000000,80.000000 116.000000,74.400002 116.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 120.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;176.000000,48.000000 164.000000,42.400002 164.000000,53.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 168.000000, 48.000000)&#39;&gt;&lt;/polygon&gt;
&lt;path d=&#39;M 56,32 A 16,16 0 0,0 40,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 56,32 A 16,16 0 0,1 72,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 24,64 A 16,16 0 0,0 8,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 40,48 A 16,16 0 0,1 24,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 72,48 A 16,16 0 0,0 88,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 88,64 A 16,16 0 0,1 104,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;circle cx=&#39;208&#39; cy=&#39;16&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;208&#39; cy=&#39;48&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;208&#39; cy=&#39;80&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;248&#39; cy=&#39;16&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;248&#39; cy=&#39;32&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;248&#39; cy=&#39;48&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;248&#39; cy=&#39;64&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;248&#39; cy=&#39;80&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;32&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;,&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;88&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;q&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;ᵩ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;104&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;M&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;.&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;C&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;.&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;θ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;x&lt;/text&gt;
&lt;/g&gt;

    &lt;/svg&gt;
  
&lt;/div&gt;
&lt;p&gt;Instead of sampling the 𝐳 directly, but the 𝐳 is derived from the sampled 𝛆,
based on the deterministic differentiable transformation:
𝐳 = gᵩ(𝛆, 𝐱).&lt;/p&gt;



&lt;div class=&#34;goat svg-container &#34;&gt;
  
    &lt;svg
      xmlns=&#34;http://www.w3.org/2000/svg&#34;
      font-family=&#34;Menlo,Lucida Console,monospace&#34;
      
        viewBox=&#34;0 0 408 121&#34;
      &gt;
      &lt;g transform=&#39;translate(8,16)&#39;&gt;
&lt;path d=&#39;M 144,48 L 168,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 288,48 L 304,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 24,64 L 32,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 96,64 L 104,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 8,80 L 120,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 120,80 L 136,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 8,16 L 8,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 336,80 L 344,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 356,40 L 364,24&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 336,16 L 344,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 356,56 L 364,72&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;polygon points=&#39;16.000000,16.000000 4.000000,10.400000 4.000000,21.600000&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 8.000000, 16.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;144.000000,80.000000 132.000000,74.400002 132.000000,85.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 136.000000, 80.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;176.000000,48.000000 164.000000,42.400002 164.000000,53.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 168.000000, 48.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;312.000000,48.000000 300.000000,42.400002 300.000000,53.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 304.000000, 48.000000)&#39;&gt;&lt;/polygon&gt;
&lt;path d=&#39;M 64,32 A 16,16 0 0,0 48,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 64,32 A 16,16 0 0,1 80,48&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 24,64 A 16,16 0 0,0 8,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 48,48 A 16,16 0 0,1 32,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 80,48 A 16,16 0 0,0 96,64&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 104,64 A 16,16 0 0,1 120,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;circle cx=&#39;336&#39; cy=&#39;16&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;336&#39; cy=&#39;48&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;336&#39; cy=&#39;80&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;376&#39; cy=&#39;16&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;376&#39; cy=&#39;32&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;376&#39; cy=&#39;48&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;376&#39; cy=&#39;64&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;376&#39; cy=&#39;80&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;8&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;40&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;48&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;80&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;88&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;104&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;100&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;M&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;.&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;36&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;C&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;.&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;=&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;μ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;+&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;264&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;σ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;272&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;336&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;344&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;352&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;θ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;360&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;376&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;x&lt;/text&gt;
&lt;/g&gt;

    &lt;/svg&gt;
  
&lt;/div&gt;
&lt;p&gt;(The non-differentiable operation (M.C.) is put ahead of the leave nodes on the computational graph.)&lt;/p&gt;
&lt;p&gt;Then the parameters (e.g. μ,σ²) of 𝐳&amp;rsquo;s distribution can be learned by a network with parameters φ.&lt;/p&gt;



&lt;div class=&#34;goat svg-container &#34;&gt;
  
    &lt;svg
      xmlns=&#34;http://www.w3.org/2000/svg&#34;
      font-family=&#34;Menlo,Lucida Console,monospace&#34;
      
        viewBox=&#34;0 0 424 297&#34;
      &gt;
      &lt;g transform=&#39;translate(8,16)&#39;&gt;
&lt;path d=&#39;M 112,16 L 144,16&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 72,80 L 112,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 192,128 L 224,128&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 304,128 L 328,128&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 120,240 L 128,240&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 192,240 L 200,240&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 104,256 L 216,256&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 216,256 L 232,256&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 104,208 L 104,256&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 128,96 L 128,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 160,32 L 160,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 176,144 L 176,176&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 12,72 L 20,56&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 32,32 L 40,16&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 240,160 L 248,144&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 260,120 L 268,104&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 12,24 L 20,40&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 32,64 L 40,80&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 240,96 L 248,112&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 260,136 L 268,152&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;polygon points=&#39;112.000000,208.000000 100.000000,202.399994 100.000000,213.600006&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 104.000000, 208.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;136.000000,112.000000 124.000000,106.400002 124.000000,117.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(90.000000, 128.000000, 112.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;168.000000,112.000000 156.000000,106.400002 156.000000,117.599998&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(90.000000, 160.000000, 112.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;184.000000,144.000000 172.000000,138.399994 172.000000,149.600006&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(270.000000, 176.000000, 144.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;232.000000,128.000000 220.000000,122.400002 220.000000,133.600006&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 224.000000, 128.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;240.000000,256.000000 228.000000,250.399994 228.000000,261.600006&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 232.000000, 256.000000)&#39;&gt;&lt;/polygon&gt;
&lt;polygon points=&#39;336.000000,128.000000 324.000000,122.400002 324.000000,133.600006&#39; fill=&#39;currentColor&#39; transform=&#39;rotate(0.000000, 328.000000, 128.000000)&#39;&gt;&lt;/polygon&gt;
&lt;path d=&#39;M 144,16 A 16,16 0 0,1 160,32&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 112,80 A 16,16 0 0,1 128,96&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 160,208 A 16,16 0 0,0 144,224&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 160,208 A 16,16 0 0,1 176,224&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 120,240 A 16,16 0 0,0 104,256&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 144,224 A 16,16 0 0,1 128,240&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 176,224 A 16,16 0 0,0 192,240&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;path d=&#39;M 200,240 A 16,16 0 0,1 216,256&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39;&gt;&lt;/path&gt;
&lt;circle cx=&#39;0&#39; cy=&#39;16&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;0&#39; cy=&#39;32&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;0&#39; cy=&#39;48&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;0&#39; cy=&#39;64&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;0&#39; cy=&#39;80&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;40&#39; cy=&#39;16&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;40&#39; cy=&#39;80&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;240&#39; cy=&#39;96&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;240&#39; cy=&#39;128&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;240&#39; cy=&#39;160&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;280&#39; cy=&#39;96&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;280&#39; cy=&#39;112&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;280&#39; cy=&#39;128&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;280&#39; cy=&#39;144&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;circle cx=&#39;280&#39; cy=&#39;160&#39; r=&#39;6&#39; stroke=&#39;currentColor&#39; fill=&#39;#fff&#39;&gt;&lt;/circle&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;0&#39; y=&#39;4&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;x&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;16&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;24&#39; y=&#39;52&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;φ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;56&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;μ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;64&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;72&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;88&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;σ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;20&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;²&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;96&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;104&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;(&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;=&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;112&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;)&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;120&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;128&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;μ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;136&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;d&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;+&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;144&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;152&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;σ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;160&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;m&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;168&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;a&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;176&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;p&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;184&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;b&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;192&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;200&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;208&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;g&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;216&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;224&#39; y=&#39;276&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;232&#39; y=&#39;196&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;L&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;240&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;z&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;248&#39; y=&#39;260&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;𝛆&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;256&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;θ&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;264&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;280&#39; y=&#39;84&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;x&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;336&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;R&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;344&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;e&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;352&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;352&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;c&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;352&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;l&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;360&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;360&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;360&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;368&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;368&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;i&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;368&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;376&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;376&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;o&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;376&#39; y=&#39;148&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;s&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;384&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;t&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;384&#39; y=&#39;132&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;n&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;392&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;r&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;400&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;u&lt;/text&gt;
&lt;text text-anchor=&#39;middle&#39; x=&#39;408&#39; y=&#39;116&#39; fill=&#39;currentColor&#39; style=&#39;font-size:1em&#39;&gt;-&lt;/text&gt;
&lt;/g&gt;

    &lt;/svg&gt;
  
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Such that the Monte Carlo estimate of the expectation is differentiable w.r.t. φ.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The reasoning is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For infinitesimals, there is $$q_φ(𝐳|𝐱)∏ᵢdzᵢ = p(\pmb ε)∏ᵢdεᵢ$$;
where zᵢ is one of dimensions, d𝐳 = ∏ᵢ dzᵢ&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Therefore, $∫ q_φ(𝐳|𝐱) f(𝐳) d𝐳$ = ∫p(𝛆) f(𝐳) d𝛆 = ∫ p(𝛆) $f(g_φ$(𝛆,𝐱)) d𝛆&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Monte Carlo sampling approximation: $∫ q_φ(𝐳|𝐱) f(𝐳) d𝐳$ ≃ 1/L ∑ₗ₌₁ᴸ f( gᵩ(𝛆⁽ˡ⁾, 𝐱)), where 𝛆⁽ˡ⁾ ~ p(𝛆)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The transformation (φ) from 𝛆 to 𝐳 can be learned by back-propagation and gradient descent from the reconstruction loss, since the transformation differentiable.&lt;/p&gt;
&lt;p&gt;So the parameters (e.g. μ,σ) of the approximate posterior distribution $q_φ(𝐳|𝐱)$ of 𝐳 can be optimized through φ, and the parameter θ of the generative model is trained jointly.&lt;/p&gt;
&lt;p&gt;This&amp;rsquo;s just a trick, the essence of the algorithm is still the coordinate ascent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Sample a 𝐳 by sampling an 𝛆:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;reparameterize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;logvar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# logvar is log𝛔²&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;std&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;logvar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# (e^{log𝛔²})^½&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;eps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn_like&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mu&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;eps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use 𝐳 to generate 𝐱 with model $p_θ(𝐱|𝐳)$,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;decode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;latent_dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hidden_dims&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;then use 𝐱 to produce 𝐳 with model $q_φ(𝐳|𝐱)$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;encode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hidden_dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;mu&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hidden_dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;latent_dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;logvar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hidden_dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;latent_dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;logvar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With using reparameterization trick, both the two models can be optimized by gradient descent.&lt;/p&gt;
&lt;p&gt;(2024-04-16)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reparameterization trick is a sampling method. It&amp;rsquo;s similar to inverse transform sampling: using a known distribution (uniform) to sample an unknown distribution.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reparameterization trick makes the sampling from an unknown distribution differentiable,
and enables the parameters of the distribution to be optimized.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;loss-func&#34;&gt;Loss func&lt;/h3&gt;
&lt;p&gt;Loss function contains two parts: KL divergence and reconstruction error.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;KL divergence (i.e., cross entropy) can be computed with given the prior and assumed posterior of 𝐳.&lt;/p&gt;
&lt;p&gt;For example, let the prior $\rm p_θ(𝐳) = N(𝐳,𝟎,𝐈)$ and assume the posterior qᵩ(𝐳|𝐱) = N(𝐳; 𝛍, 𝛔²𝐈),
then cross entropy can be derived by plugging them into Gaussian expression.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The reconstruction error is the log likelihood of the input datapoint log p(𝐱|𝐳).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For a datapoint obeying multivariate Bernoulli (Yes or No), the log likelihood of 𝐱 is&lt;/p&gt;
&lt;p&gt;$$
log p(𝐱|𝐳) = log ∏ᵢ₌₁ᴰ yᵢˣⁱ (1-yᵢ)¹⁻ˣⁱ  \\
\          = ∑ᵢ₌₁ᴰ [ xᵢlog yᵢ + (1-xᵢ)log (1-yᵢ) ]
$$&lt;/p&gt;
&lt;p&gt;where yᵢ should be like a probability (need to do sigmoid activation).
So in this case, this loss term is a cross entropy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For a datapoint following multivariate Gaussian distribution N(𝐱; 𝛍, 𝛔²𝐈), refer to &lt;a class=&#34;link&#34; href=&#34;https://www.kexue.fm/archives/5343&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Su, Jianlin&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;amp;p(𝐱|𝐳) = \frac{1}{∏ᵢ₌₁ᴰ \sqrt{2πσᵢ²(𝐳)}}
\rm exp(-\frac{1}{2} ‖\frac{x-\pmb μ(𝐳)}{\pmb σ(𝐳)}‖²) \\
\            \\
&amp;amp;log\ p(𝐱|𝐳) \\
&amp;amp;= log \frac{1}{∏ᵢ₌₁ᴰ \sqrt{2πσᵢ²(𝐳)}}
\ -\frac{1}{2} ‖\frac{x-\pmb μ(𝐳)}{\pmb σ(𝐳)}‖² \\
&amp;amp;= -∑ᵢ₌₁ᴰ log \sqrt{2πσᵢ²(𝐳)} -\frac{1}{2} ‖\frac{x-\pmb μ(𝐳)}{\pmb σ(𝐳)}‖² \\
&amp;amp;= -∑ᵢ₌₁ᴰ [\frac{1}{2} (log2π + logσᵢ²(𝐳))] - \frac{1}{2} ‖\frac{x-\pmb μ(𝐳)}{\pmb σ(𝐳)}‖² \\
&amp;amp;= -\frac{D}{2} log2π -∑ᵢ₌₁ᴰlogσᵢ²(𝐳) -\frac{1}{2} ‖\frac{x-\pmb μ(𝐳)}{\pmb σ(𝐳)}‖² \\
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Normally, the variance 𝛔² will be fixed, so this loss term is only related with mean 𝛍(𝐳):&lt;/p&gt;
&lt;p&gt;-log p(𝐱|𝐳) ~ $\frac{1}{2\pmb σ²}\| 𝐱-\pmb μ(𝐳) \|²$&lt;/p&gt;
&lt;p&gt;Therefore, this loss term is MSE.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>read: Blog - 苏剑林 | VAE-3</title>
        <link>https://zichen34.github.io/writenotes/model/imagen/vae/d-note-vae_3-su/</link>
        <pubDate>Sun, 01 Jan 2023 22:48:00 +0000</pubDate>
        
        <guid>https://zichen34.github.io/writenotes/model/imagen/vae/d-note-vae_3-su/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.kexue.fm/archives/5383&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;变分自编码器（三）：这样做为什么能成？&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;采样一次就够&#34;&gt;采样一次就够&lt;/h2&gt;
&lt;p&gt;先推断学习 z 的后验分布 p(z|x) 的参数，再从分布中采样一个 z，用它计算 x 的后验分布 p(x|z) 的参数，再算从x的后验分布中采样得到 x‘的概率，&lt;/p&gt;
&lt;p&gt;在 VAE 的损失函数：𝓛 = 𝔼_pᐢ(x) [ KL( p(z|x)||q(z) ) + 𝔼_p(z|x) [ -ln q(x|z) ] ]中，&lt;/p&gt;
&lt;p&gt;KL散度的计算是使用神经网络拟合出的z的后验分布（正态分布）的期望和方差，
而第 2 项只采了一个样本 x 做近似，所以这一项变为：-ln q(x|z), z~p(z|x)&lt;/p&gt;
&lt;p&gt;因为 KL 散度也可写成期望：E_p(z|x) [ ln (p(z|x)/q(z)) ]，所以它也可以只采样一个点来近似。所以损失函数就可写为：&lt;/p&gt;
&lt;p&gt;𝓛 = 𝔼_pᐢ(x) [ ln p(z|x) - ln q(z) - ln q(x|z) ], z~p(z|x)          (5)&lt;/p&gt;
&lt;p&gt;苏神说，以上的损失函数也能收敛到相似的结果。&lt;/p&gt;
&lt;h2 id=&#34;似然不能只用一个采样点估计&#34;&gt;似然不能只用一个采样点估计&lt;/h2&gt;
&lt;p&gt;极大似然的公式可以写成期望：
q(x|z) &lt;br&gt;
= arg max_q(x|z) ∫ pᐢ(x) ln (∫ q(x|z) q(z) dz) dx ，数值计算，要乘x的概率&lt;br&gt;
= arg max_q(x|z) 𝔼_pᐢ(x) [ ln ( ∫ q(x|z) q(z) dz) ] ，采样近似求积分&lt;br&gt;
= arg max_q(x|z) 𝔼_pᐢ(x) [ ln (1/K ∑_ₖ₌₁ᴷ q(x|zₖ) ], z1,z2,&amp;hellip;,2ₖ～q(z)&lt;/p&gt;
&lt;p&gt;对这个期望近似：先从先验 q(z) 中采 k 个 z，算积分（求和），再采 1 个 x，求它的概率的对数就行了。&lt;/p&gt;
&lt;p&gt;shuhuai 说是因为 log 的方差大，所以采样太少会失效。
苏神说，因为z 和 x 是一一对应的，如果没有采到 zₖ，那它对应的 xₖ 也就采不出来，概率就算不出来，因为采样是随机的，不能保证每次采的 k 个 z，包含了本 batch 中所有 x 对应的 z，所以容易失效。&lt;/p&gt;
&lt;h2 id=&#34;vae采一个点确实够了&#34;&gt;VAE采一个点确实够了&lt;/h2&gt;
&lt;p&gt;根据对数据集的了解，数据集X本身带有很强的约束，真正独立的维度很少，所以数据集可以被投影到低维空间的一个隐变量上。
这和普通的自编码器一样，也就是 z 与 x 一一对应，也就意味这 p(z|x) 和 q(x|z) 的方差为0。
在引入标准正态形式的先验分布 q(z) 后，粗略地看，只是对隐变量空间做了平移和缩放，所以方差也可以不大。&lt;/p&gt;
&lt;p&gt;因为 x 的后验分布的方差很小，每次采的结果都一样，都是均值 μ(z)。
因为 z 与 x 是一一对应的，所以 z 的后验分布的方差也很小，所以每次从中采的 z 都相同。
所以采样一次，与采样多次没什么差别，期望都是一样的。&lt;/p&gt;
&lt;h2 id=&#34;后验之妙&#34;&gt;后验之妙&lt;/h2&gt;
&lt;p&gt;直接从先验 q(z) 中采样不可行，但在后验分布 p(z|x) 中采样一个点就够了，
因为自编码器里的方差为0，引入 z 的先验（标准正态分布），方差也不会太大。&lt;/p&gt;
&lt;h2 id=&#34;耿直的iwae&#34;&gt;耿直的IWAE&lt;/h2&gt;
&lt;p&gt;重要性加权自编码器 Importance Weighted AutoEncoders &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1509.00519v1.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;arxiv&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;对 p(x) 做了等价变换：乘一个p(z|x),除一个 p(z|x)&lt;/p&gt;
&lt;p&gt;p(x) = ∫ q(x|z) q(z) dz  &lt;br&gt;
= ∫ p(z|x) ⋅ [q(x|z) ⋅ q(z)] / p(z|x) dz  &lt;br&gt;
= 𝔼_p(z|x) [ q(x|z) ⋅ q(z) / p(z|x) ]&lt;/p&gt;
&lt;p&gt;这样，从 q(z) 中采样就变成了从 p(z|x) 中采样，此前已论述了后验分布 p(z|x) 方差较小，所以采样几个点就够了：&lt;/p&gt;
&lt;p&gt;∫ q(x|z) q(z) dz = 1/k ∑ₖ₌₁ᴷ [ q(x|zₖ)q(zₖ)/p(zₖ|x) ], z1,z2,..,zₖ～p(z|x)&lt;/p&gt;
&lt;p&gt;代入似然函数：&lt;/p&gt;
&lt;p&gt;q(x|z)
= arg max_q(x|z) 𝔼_pᐢ(x) [ ln ( ∫ q(x|z) q(z) dz) ] &lt;br&gt;
= arg max_q(x|z) 𝔼_pᐢ(x) [ ln ( 1/k ∑ₖ₌₁ᴷ [ q(x|zₖ)q(zₖ)/p(zₖ|x) ] ) ]&lt;br&gt;
= arg min_{q(x|z),p(z|x)} 𝔼_pᐢ(x) [ -ln ( 1/k ∑ₖ₌₁ᴷ [ q(x|zₖ)q(zₖ)/p(zₖ|x) ] ) ], z1,z2,..,zₖ～p(z|x) ，加个负号，求极小值。&lt;/p&gt;
&lt;p&gt;当 k=1 时，与 (5) 式一样，从这个角度看，IWAE 是VAE的升级版。&lt;/p&gt;
&lt;p&gt;其实，等价变换可以使用 z 的任意分布（只要能采出z就行），&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“选择 p(z|x) 只是因为它有聚焦性，便于采样。而当 k 足够大时，p(z|x) 的具体形式就不重要了”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;IWAE 中削弱了推断模型 p(z|x) 的作用，不去近似后验分布&lt;/p&gt;
</description>
        </item>
        <item>
        <title>read: Blog - 苏剑林 | VAE-2</title>
        <link>https://zichen34.github.io/writenotes/model/imagen/vae/d-note-vae_2-su/</link>
        <pubDate>Fri, 30 Dec 2022 20:07:00 +0000</pubDate>
        
        <guid>https://zichen34.github.io/writenotes/model/imagen/vae/d-note-vae_2-su/</guid>
        <description>&lt;p&gt;笔记 for &lt;a class=&#34;link&#34; href=&#34;https://www.kexue.fm/archives/5343&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;变分自编码器（二）：从贝叶斯观点出发&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;数值计算-vs-采样计算&#34;&gt;数值计算 vs 采样计算&lt;/h2&gt;
&lt;p&gt;数值计算是先给个数列，对里面的每个数求概率p(x⁽ⁱ⁾)，再加权求和 ∑ᵢ₌₀ⁿ x⁽ⁱ⁾p(x⁽ⁱ⁾) (x⁽ⁱ⁾-x⁽ⁱ⁻¹⁾)；
采样计算是先从分布中采样，求采样点概率的平均，所以不需要再乘样本点出现的概率：E[x]≈1/n⋅∑ᵢ₌₀ⁿ x⁽ⁱ⁾, x⁽ⁱ⁾∼p(x)。&lt;/p&gt;
&lt;h2 id=&#34;推导vae-的损失函数&#34;&gt;推导VAE 的损失函数&lt;/h2&gt;
&lt;p&gt;苏神从逼近联合概率 p(x,z) 出发，而不是从逼近z的后验 p(z|x) 出发。
也许是因为沿着 EM 的思路走，就需要对后验 p(z|x) 求近似，所以很多人聚焦于推导 p(z|x)。&lt;/p&gt;
&lt;p&gt;因为想求样本集合 x的分布，&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;但是难以直接描述复杂分布，所以通过引入隐变量把x的分布变成条件分布的叠加，而后可以对隐变量的分布和条件分布做适当简化（比如都假设为正态分布），并且可以用深度学习模型近似求（隐变量）条件分布的参数，即“深度概率图模型”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假设 x 是由 z 生成的，所以求 p(x) 可以通过把联合分布 p(x,z) 中的 p(z) 积掉求得：
p(x) = ∫p(x,z) dz = ∫ p(x|z)p(z) dz&lt;/p&gt;
&lt;p&gt;目标是用一个 q(x,z) 逼近 p(x,z)，又因为 p(z) 是先验（已知），所以当 q(x,z)≈p(x,z) 时，&lt;strong&gt;生成模型 p(x|z)&lt;/strong&gt; 也就学到了，“一举两得”。&lt;/p&gt;
&lt;p&gt;通过最小化 KL 散度逼近：KL( p(x,z) || q(x,z) ) = ∫∫ p(x,z) [ ln (p(x,z)/q(x,z)) ] dz dx，是一个二重积分&lt;/p&gt;
&lt;p&gt;把 p(x,z) 写成 pᐢ(x)⋅p(z|x)，也就是&lt;strong&gt;推断过程&lt;/strong&gt;，由x的先验推出z：&lt;/p&gt;
&lt;p&gt;KL( p(x,z) || q(x,z) )
= ∫∫ pᐢ(x)⋅p(z|x) [ ln ( pᐢ(x)⋅p(z|x) / q(x,z) ) ] dz dx  &lt;br&gt;
= ∫ pᐢ(x) [ ∫ p(z|x) ⋅ ln ( pᐢ(x)⋅p(z|x) / q(x,z) ) dz ] dx  &lt;br&gt;
= 𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln ( pᐢ(x)⋅p(z|x) / q(x,z) ) dz]&lt;/p&gt;
&lt;p&gt;可以蒙特卡罗采样近似求这个期望，也就是把每个样本 x⁽ⁱ⁾ 代入上面中括号里的函数（代入概率密度公式可算出概率值），把函数值求均值。&lt;/p&gt;
&lt;p&gt;这个期望可以进一步简化，把 ln 拆开：
ln ( pᐢ(x)⋅p(z|x) / q(x,z) ) = ln pᐢ(x) + ln (p(z|x)/q(x,z))&lt;/p&gt;
&lt;p&gt;𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln ( pᐢ(x)⋅p(z|x) / q(x,z) ) dz ] &lt;br&gt;
= 𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln pᐢ(x) dz] +
𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln (p(z|x)/q(x,z)) dz]&lt;/p&gt;
&lt;p&gt;上面第 1 个期望：
𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln pᐢ(x) dz] = 𝔼_pᐢ(x) [ ln pᐢ(x)⋅∫ p(z|x) dz ]
= 𝔼_pᐢ(x) [ ln pᐢ(x) ]&lt;/p&gt;
&lt;p&gt;这里的 pᐢ(x) 是根据样本 x⁽⁰⁾, x⁽¹⁾,&amp;hellip;, x⁽ⁿ⁾ 确定的关于 x 的先验分布，是已知的确定的，所以这一项是一个常数。
所以 KL 散度 = 常数 + 一个期望：&lt;/p&gt;
&lt;p&gt;KL( p(x,z) || q(x,z) ) = 常数 + 𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln (p(z|x)/q(x,z)) dz]&lt;/p&gt;
&lt;p&gt;所以最小化KL散度，对应目标函数 𝓛 就是第2个期望：&lt;/p&gt;
&lt;p&gt;𝓛 = KL( p(x,z) || q(x,z) ) - 常数，则𝓛 的下界就是&amp;quot;-常数&amp;quot;: -𝔼_pᐢ(x) [ ln pᐢ(x) ]，
其中 pᐢ(x) 不一定是概率，在连续情况时，pᐢ(x) 是概率密度函数，它可以大于1 也可以小于1，所以下界不一定是非负的，即 loss 可能是负数。&lt;/p&gt;
&lt;p&gt;再把 𝓛 里的 ln 和 q(x,z) 展开：&lt;/p&gt;
&lt;p&gt;𝓛 = 𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln ( p(z|x) / q(x,z) ) dz]  &lt;br&gt;
= 𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln ( p(z|x) / (q(x|z)q(z)) dz ]  &lt;br&gt;
= 𝔼_pᐢ(x) [ ∫ p(z|x) ⋅ ln ( p(z|x)/q(z) ) dz - ∫ p(z|x) ⋅ ln q(x|z) dz]&lt;/p&gt;
&lt;p&gt;把里面的积分写成期望：&lt;/p&gt;
&lt;p&gt;𝓛 = 𝔼_pᐢ(x) [ KL( p(z|x)||q(z) ) + 𝔼_p(z|x) [ -ln q(x|z) ] ]&lt;/p&gt;
&lt;p&gt;括号里的就是 VAE 的损失函数：KL散度（正则化项）+ x的后验按照 z 的后验求期望 &lt;a class=&#34;link&#34; href=&#34;../ML-%e7%99%bd%e6%9d%bf%e6%8e%a8%e5%af%bc%e7%b3%bb%e5%88%97/32-VAE.md&#34; &gt;shuhuai008-30VAE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;不能把括号里面的两项分开看或分开最小化。
如果只令 KL( p(z|x)||q(z) )=0，即每个后验都是标准正态分布，与x无关，导致生成的 x 不准，概率 q(x|z) 会很小，-ln q(x|z) 就会很大。
而如果 -ln q(x|z) 很小，即x后验概率 q(x|z) 大，后验分布 p(z|x) 的峰肯定集中在 x 附近，即 p(z|x) 的方差小，与标准正态的差距大，KL( p(z|x)||q(z) ) 不会小。
所以这两部分 loss 是相互拮抗的，𝓛 要以整体来看。
也就是要推断过程与生成过程相互博弈。&lt;/p&gt;
&lt;h2 id=&#34;算法设计&#34;&gt;算法设计&lt;/h2&gt;
&lt;p&gt;损失函数中未知的分布包括：z 的先验 q(z)，z 的后验 p(z|x)，x 的后验 q(x|z) （x 的先验pᐢ(x) 是已知的）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;为了便于采样，假设 z 的先验分布为标准多元正态分布：q(z)=N(0,I)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用神经网络拟合 z 的后验 p(z|x) 和 x 的后验 q(x|z)。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;计算 z 的后验是推断过程，对应 EM 的 E步：近似求得 p(z|x)；计算 x 的后验是生成过程，对应 EM 的 M步：把z的近似后验代入似然函数，求极大似然时，对应的模型参数。
（EM中用于逼近 p(z|x) 的神经网络的参数是 ϕ；用于逼近 q(x|z) 的神经网络（也可直接求导）的参数是 θ）&lt;/p&gt;
&lt;h3 id=&#34;后验分布近似&#34;&gt;后验分布近似&lt;/h3&gt;
&lt;p&gt;假设 z 的后验是（各分量独立的）一般正态分布，所以需要神经网络逼近它的期望和方差。期望和方差都由 x 决定，即是 x 的函数 μ_ϕ(x), Σ_ϕ(x)&lt;/p&gt;
&lt;p&gt;然后 KL 散度就可以写出来了: 1/2(-logσ² + μ² + σ² -1)，已在VAE第一篇推导过。&lt;a class=&#34;link&#34; href=&#34;https://www.kexue.fm/archives/5253&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;变分自编码器（一）：原来是这么一回事&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;生成模型近似&#34;&gt;生成模型近似&lt;/h3&gt;
&lt;p&gt;对于生成模型部分 q(x|z) 的假设，原作者在论文&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1312.6114&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《Auto-Encoding Variational Bayes》&lt;/a&gt;中，给出了两种方案：二项分布或正态分布。“既要满足概率的定义（归一化），又要容易算，没多少选择”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二项分布&lt;/strong&gt;只有一个参数：&amp;ldquo;抛硬币向上的概率 ρ&amp;rdquo;。所以对于一个 D 维的样本 x，x 的每一维都是个二值的，所以一个输入样本 x 在 z 成立的情况下，发生的概率就是：
q(x|z) = ∏ₖ₌₁ᴰ (ρₖ(z))ˣᵏ (1-ρₖ(z))¹⁻ˣᵏ&lt;/p&gt;
&lt;p&gt;此时的 -ln q(x|z) = ∑ₖ₌₁ᴰ [ -xₖ ln ρₖ(z) - (1-xₖ) ln(1-ρₖ(z)) ]&lt;/p&gt;
&lt;p&gt;也就是说神经网络的输出 ρ(z) 需要是在 0～1 之间（比如用 sigmoid 激活），然后用交叉熵作为损失函数。&lt;/p&gt;
&lt;p&gt;如果假设 q(x|z) 是&lt;strong&gt;正态分布&lt;/strong&gt;，用神经网络估计它的期望 μ_θ(z) 和方差 Σ_θ(z)，于是：
-ln q(x|z) = ½ || (x-μ_θ(z)) / Σ_θ(z) ||² + D/2 ln 2π + ½∑ₖ₌₁ᴰ lnΣ_θ(z)。&lt;/p&gt;
&lt;p&gt;很多时候，训练时方差会固定为一个较小的常数（每次采样都会采到μ），所以神经网络只需估计μ，也就是把 μ 当作生成的 x&amp;rsquo;，则上式重构误差可简化为：
-ln q(x|z) = ½ || (x-μ_θ(z)) / Σ_θ(z) ||²&lt;/p&gt;
&lt;p&gt;x &amp;ndash;&amp;gt; z &amp;ndash;&amp;gt; x&#39;&lt;/p&gt;
&lt;p&gt;综上，对于二值数据，假设 q(x|z) 是伯努利分布（二项分布），可以对 decoder （第2个神经网络）的输出用 sigmoid 激活，并用交叉熵作为损失函数；
而对于一般数据，假设 q(x|z) 是正态分布，则使用 mse 作为损失函数。&lt;/p&gt;
&lt;h3 id=&#34;从后验中采样-z-的技巧&#34;&gt;从后验中采样 z 的技巧&lt;/h3&gt;
&lt;p&gt;损失函数的第 2 项是：𝔼_p(z|x) [ -ln q(x|z) ]，根据蒙特卡罗的思想，这个期望用均值近似：先采样 z，用 z 计算 x 的后验分布 q(x|z)，再从中采样 x 计算它出现概率的对数：-ln q(x|z)，再求均值：&lt;/p&gt;
&lt;p&gt;𝔼_p(z|x) [ -ln q(x|z) ] = -1/n ∑ᵢ₌₁ᴺ ln q(x|zᵢ), zᵢ～p(z|x)&lt;/p&gt;
&lt;p&gt;假设了 p(z|x) 是正态分布，它的参数 μ_ϕ, Σ_ϕ 已由神经网络算出，再使用重参数化技巧就能采样出 z 。&lt;/p&gt;
&lt;p&gt;但是要采样多少个合适呢？因为每个 z 是专属于 1 个 x，所以只从 p(z|x) 中采一个 z 来计算 x 的分布 q(x|z)，再计算 -ln q(x|z)，就是loss值。&lt;/p&gt;
&lt;p&gt;最终：𝓛 = 𝔼_pᐢ(x) [ KL( p(z|x)||q(z) ) -ln q(x|z) ] , z～p(z|x)&lt;/p&gt;
&lt;p&gt;因为每次 epoch 的隐变量都是随机生成的，因此当 epoch 数足够多时，可以保证采样的充分行。苏神试过采样多个的情形，感觉生成的样本没有明显变化。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>sum: VAE</title>
        <link>https://zichen34.github.io/writenotes/model/imagen/vae/c-sum-vae/</link>
        <pubDate>Fri, 26 Aug 2022 00:00:00 +0000</pubDate>
        
        <guid>https://zichen34.github.io/writenotes/model/imagen/vae/c-sum-vae/</guid>
        <description>&lt;p&gt;(2022-12-28)&lt;/p&gt;
&lt;h2 id=&#34;白板推导-vae&#34;&gt;白板推导: VAE&lt;/h2&gt;
&lt;p&gt;Source video：&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV15E411w7Pz/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;【机器学习】白板推导系列(三十二) ～ 变分自编码器(VAE)】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;VAE 和 GMM 一样也是生成模型：隐变量 z 生成观测变量 x，从而学习样本数据 x 本身的分布。不过 VAE 的 z 不是1维的，而是多维的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用 &lt;a class=&#34;link&#34; href=&#34;https://zichen34.github.io/writenotes/calc/ml-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC%E7%B3%BB%E5%88%97/11-gmm/&#34; &gt;EM 解 GMM&lt;/a&gt; 的最优参数 θ 时，假设 z 的后验分布 P(z|x;θ⁽ᵗ⁾) 能够取到，而且因为 z 是离散的，P(x) = ∑ₖ₌₁ᴷP(x,z=Cₖ;θ) 就能算出来，
所以后验 P(z|x)=P(x|z)P(z)/P(x) 也能算出来，其中分子两项是假设的分布。E步把目标函数: &amp;ldquo;最大的期望&amp;rdquo; $E_{P(z|x)} [ log P(x,z|θ) ]$ 写出来，M步对其求导找出（期望最大时的）最佳θ⁽ᵗ⁺¹⁾。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;而 VAE 的 z 是高维连续的，P(x) = $∫_z P(x,z) dz$ 积不出来，后验P(z|x) 就没法用贝叶斯公式导出，但可以用随机梯度下降变分推断(SGVI)近似后验。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;“推断”是从 x 到 z 的过程：用样本 x 修正 z 的先验 P(z) 得到 z 的后验 P(z|x)；而“生成”是从 z 的后验分布 P(z|x) 中采样出 z，再变换成样本的分布 P(x)。&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;flowchart LR; observed((x)) --&gt;|Inference| latent((z)); latent --&gt;|Generation| observed
&lt;/div&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用 q(z|x;ϕ) 逼近后验 P(z|x;θ) 时，要最小化 $KL(q_{ϕ(z|x)} || P_{θ(z|x)})$，在 θ 固定，则似然 P(X) 也固定的情况下，等价于最大化 ELBO：
arg max $E_{qᵩ(z|x)} [ log (P(z,x;θ)/qᵩ(z|x)) ]) ]$。类似广义 EM 的 E步，在 θ 固定的情况下，求后验的近似。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过把联合概率拆开，这个 ELBO 也可写成: $E_{qᵩ(z|x)} [ log P(x|z;θ) ] - KL(q(z|x;ϕ) ||P(z))$。
当 z 的先验分布 P(z) 是标准正态时，那么KL散度就是希望 qᵩ(z|x) 的方差保持为I，不要太小，分布坍缩到一点就是过拟合：x与z一一对应，就变成 AE了，只能对训练样本 x 推出正确的 z。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;求生成模型的最优参数 θ 同样是要使似然期望最大：arg max ELBO（x后验与KL散度同时优化），（没法直接求导）可采用梯度上升法，所以 VAE 是把 EM 的两步合起来了，既逼近后验 p(z|x) 的参数 ϕ，又逼近生成模型 p(x|z) 的参数θ。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在&lt;a class=&#34;link&#34; href=&#34;https://zichen34.github.io/writenotes/calc/ml-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC%E7%B3%BB%E5%88%97/12-%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/&#34; &gt;计算 ELBO 对 ϕ 的梯度&lt;/a&gt;时，∇ᵩL(ϕ) 可以写成一个期望，直接对 z 采样求均值可能由于方差太大而失效（而且采样操作不可导，就无法对z求梯度），
所以先对一个高斯噪声 ε 采样，再根据变换：z=μ_ϕ(x) + Σ_ϕ¹ᐟ²(x)⋅ε 得到 z &lt;a class=&#34;link&#34; href=&#34;https://zichen34.github.io/writenotes/calc/ml-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC%E7%B3%BB%E5%88%97/30-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0/&#34; &gt;(重参数化)&lt;/a&gt;。然后求均值(=梯度)，带入梯度上升公式，更新ϕ。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;训练NN时，输入一个 x，神经网络输出后验分布（编码）p(z|x) 以及采样出一个z。用这个z 通过另一个网络逼近 x 的后验分布（生成模型）p(x|z)，
也就是在学到的 z 成立的情况下，从 p(x|z) 中采到 x 的概率，目标函数就是希望这个概率越大越好，可以假设 x服从二项或正态，把参数代入公式即得概率
或者说，分布 p(x|z) 的&amp;quot;众数&amp;quot; x&amp;rsquo;要与输入 x 的距离越小越好，当方差很小时，众数就是期望，即每次采样都会采到期望 μ(z)，所以以 μ(z) 与 x 的距离作为目标函数。
一个x是多维的，它有自己（维度之间）的分布。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;mermaid&#34;&gt;flowchart LR
subgraph Encoder
x(&#34;Input x&#34;) --&gt; net(&#34;NN-ϕ&#34;) --&gt; a(&#34;μ(x)&#34;) &amp; b(&#34;Σ(x)&#34;)
end
subgraph Decoder
a --&gt; o((&#34;+&#34;)) --&gt; z(&#34;sampled z \n from N(μ(x),Σ(x))&#34;) --&gt; net2(&#34;NN-θ\n(μ(z))&#34;) --&gt;r(&#34;reconstructed\n x&#39;&#34;)
b --&gt; m((&#34;×&#34;)) --&gt; o
ε(&#34;ε～N(0,𝐈)&#34;) --&gt; m
end
&lt;/div&gt;

&lt;p&gt;完整笔记：&lt;a class=&#34;link&#34; href=&#34;https://zichen34.github.io/writenotes/calc/ml-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC%E7%B3%BB%E5%88%97/32-vae/&#34; &gt;shuhuai008-32&lt;/a&gt;；
参考：&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/146944379&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;隐变量模型到EM到变分自编码器 - 我要给主播生猴子 -知乎&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;(2022-12-29)&lt;/p&gt;
&lt;h2 id=&#34;苏剑林-vae一&#34;&gt;苏剑林: VAE（一）&lt;/h2&gt;
&lt;p&gt;Source article：&lt;a class=&#34;link&#34; href=&#34;https://www.kexue.fm/archives/5253&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;变分自编码器（一）：原来是这么一回事-苏剑林&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;通过隐变量 z 求样本 x 的分布：p(x) = ∫_z p(x|z) p(z) dz。
先学习 z 的后验分布 p(z|x)（ &lt;strong&gt;编码&lt;/strong&gt; ），再由它 &lt;strong&gt;生成&lt;/strong&gt; $\^x$，$\^x$应与x一样。&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;flowchart LR
sample(x) --&gt;|&#34;N(μᶿ,Σᶿ)&#34;| latent(&#34;p(z|x)&#34;) --&gt;|&#34;sampling z \n P(x)=Σp(x|z)⋅p(z)？&#34;| recon(x^)
sample -.-|=| recon
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;注意区分先验 p(z) 与后验 p(z|x)。因为假设了后验是正态分布的形式，所以是对 μᶿ,Σᶿ 做重参数化。而先验只出现在正则化项中，不参与后验的训练。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一个样本点x⁽ⁱ⁾对应一个（独立的、多元的）后验分布 p(z|x⁽ⁱ⁾)，这样从中采出的 z 就一定对应这个样本点。所以每个样本有自己的正态分布。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;z 是后验分布的一个采样，采样就会有偏差（方差），导致重构误差不为0。如果不加正则化，为了减小误差，Σ会不断减小到0，退化成AE。
从这个角度看 vae 是 AE 加上噪声，并约束噪声的强度（方差）尽量为1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vae 希望所有的后验分布（”一般正态“）都与标准正态相似：μ=0，Σ=I，采样z时就保证了生成能力。因为各分量独立，所以是d维一元N的加和：
KL( N(μ,Σ)|| N(0,I) ) = ½ Σ [(-logσ² + μ² + σ² -1) ]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重参数化技巧把服从N(μ,Σ)的随机变量 z 的概率拆成一个服从标准正态的变量ε和一个参数变换μ+ε×σ，从而实现虽然采样操作不可导，但它不参与梯度的反向传播。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;条件VAE：样本属于不同的类别-期望不同 &lt;a class=&#34;link&#34; href=&#34;https://github.com/bojone/vae/blob/master/cvae_keras.py&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;cvae代码&lt;/a&gt;：用2个线性层分别拟合μ和Σ，用重参数化技巧采样z，x与x&amp;rsquo;之间的重构损失用了交叉熵 &lt;br&gt;
model：&lt;/p&gt;

  
  
  
  
    
    
    
    
     
    
    
     
    
    &lt;img src= /writenotes/model/imagen/vae/img/cvae.png width=&gt;
    
    
  

&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;mermaid&#34;&gt;flowchart LR
x(x\n original_dim) --&gt;|&#34;Dense\n(intermediate_dim)&#34;| h --&gt;|&#34;Dense\n(latent_dim)&#34;| μ(&#34;z_mean&#34;) &amp; Σ(&#34;z_log_var&#34;);
y(y\n num_classes) --&gt;|&#34;Dense\n(latent_dim)&#34;| yh
μ &amp; Σ --&gt; rp{sampling} --&gt;|reparame\n terization| z --&gt;|&#34;Dense\n (intermediate_dim)&#34;| h_decoded --&gt;|&#34;Dense\n(original_dim)&#34;| x_decoded_mean
&lt;/div&gt;

&lt;hr&gt;
&lt;p&gt;(2022-12-30)&lt;/p&gt;
&lt;h2 id=&#34;苏剑林-vae二&#34;&gt;苏剑林: VAE（二）&lt;/h2&gt;
&lt;p&gt;原文：&lt;a class=&#34;link&#34; href=&#34;https://www.kexue.fm/archives/5343&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;变分自编码器（二）：从贝叶斯观点出发&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;期望的数值计算与采样计算不同：数值计算是先给一个数列 x（其中$x⁰ &amp;lt; x¹ &amp;lt; x²&amp;lt;&amp;hellip;xⁿ$），然后对里面的每个数 x⁽ⁱ⁾ 按它的概率加权求和：E[x]=∫ xp(x) dx。
但如果 x⁽ⁱ⁾ 是分布 p(x) 中的采样，概率大的会被多采几次，样本集合 x 中就包含了概率信息，不用再乘 p(x⁽ⁱ⁾)了：E[x]≈1/n⋅∑ᵢ₌₀ⁿ x⁽ⁱ⁾, x⁽ⁱ⁾∼p(x)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;推导目标函数时，先构造了 p(x,z)=p(z|x)⋅p^(x)，再构造 q(x,z)=q(x|z)q(z)，这两个构造毫无关系，希望它俩互相靠近，而不是为了逼近z的后验p(z|x)。&lt;a class=&#34;link&#34; href=&#34;./WatchVideos/%e8%8b%8f%e5%89%91%e6%9e%97/VAE_2.md&#34; &gt;notes&lt;/a&gt;; (vae三-josh00的评论)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在生成阶段，若假设 p(x|z) 服从二项分布，则重构误差就是交叉熵；若假设 p(x|z) 服从正态分布，则重构误差就是MSE&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;训练时，生成阶段只从 z 的后验分布中采样一个，因为 z 是专属于一个x。P(x)➔ μ_ϕ(x), Σ_ϕ¹ᐟ²(x) ➔ z ➔ μ_θ(z) ➔ x&#39;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;(2022-12-31)&lt;/p&gt;
&lt;h2 id=&#34;苏剑林-vae三&#34;&gt;苏剑林: VAE（三）&lt;/h2&gt;
&lt;p&gt;原文：&lt;a class=&#34;link&#34; href=&#34;https://www.kexue.fm/archives/5383&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;变分自编码器（三）：这样做为什么能成？&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;vae生成时，只采一个z：因为x与z一一对应（自编码器）方差为0，vae引入了先验q(z)=N(0,I)，方差也不会太大，也就是每次采样，结果都一样。如果直接做最大似然p(x|z)，就需要从z的先验p(z)中采多个样本先估计出每个x的似然，再求似然的期望最大化。但如过没采到 zₖ，它对应的 xₖ的似然就是0，ln0是-∞，导致训练失败。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VAE 的重建生成相当于在AE上加了噪声（方差），所以可以生成与原始样本不同的数据。&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;%%{ init: { &#39;flowchart&#39;: { &#39;curve&#39;: &#39;linear&#39; } } }%%
flowchart TB
x[&#34;x\n(样本)&#34;] --&gt; nn[&#34;隐变量的分布 μ(x), Σ(x)&#34;] --&gt; z 
--&gt; nn2[&#34;数据的分布 p(x|z)\n 方差很小&#34;] --&gt; recon[x&#39;\n重建样本]
nn --&gt; |&#34;通过采样，从 “多个” 到 “一个”，&lt;br&gt;从 “无限” 到 “唯一”&#34;| recon 
&lt;/div&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;&#34; &gt;IWAE&lt;/a&gt; 对p(x,z)=∫p(x|z)p(z)dz 做等价变换，从而可从后验p(z|x)中采样z。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;(2023-06-04)&lt;/p&gt;
&lt;h2 id=&#34;pca-与-vae&#34;&gt;PCA 与 VAE&lt;/h2&gt;
&lt;p&gt;They&amp;rsquo;re both learning the distribution of data.&lt;/p&gt;
&lt;p&gt;DDG search: &amp;ldquo;&lt;a class=&#34;link&#34; href=&#34;https://duckduckgo.com/?q=PCA&amp;#43;%E4%B8%8E&amp;#43;VAE&amp;#43;%E5%AF%B9%E6%AF%94&amp;amp;ia=web&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PCA 与 VAE 对比&lt;/a&gt;&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Understanding Variational Autoencoders (VAEs) - Joseph Rocca&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://sannaperzon.medium.com/paper-summary-variational-autoencoders-with-pytorch-implementation-1b4b23b1763a&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Variational Autoencoders explained — with PyTorch Implementation - Sanna Persson&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Instead of mapping the input into a fixed vector, we want to map it into a distribution. &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://lilianweng.github.io/posts/2018-08-12-vae/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;From Autoencoder to Beta-VAE - Lil&amp;rsquo;Log&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>images</title>
        <link>https://zichen34.github.io/writenotes/model/imagen/vae/img/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://zichen34.github.io/writenotes/model/imagen/vae/img/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
