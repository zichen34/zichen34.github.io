<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='ç›¸æœºæ—‹è½¬ (2022-05-22)
åæ ‡ç³»æ—‹è½¬æ˜¯ point æ—‹è½¬çš„é€†ï¼ˆç‚¹é€†æ—¶é’ˆæ—‹è½¬Î¸ ç­‰æ•ˆäºåæ ‡ç³»é¡ºæ—¶é’ˆæ—‹è½¬Î¸ï¼‰
ç‚¹Påœ¨åˆå§‹åæ ‡ç³»ä¸‹çš„åæ ‡ä¸º Pâ‚’ï¼Œåœ¨ç›®æ ‡åæ ‡ç³»ä¸‹çš„åæ ‡ä¸º Pâ‚œï¼Œ ä» Pâ‚’ åˆ° Pâ‚œ ä¸­é—´æ˜¯ target åæ ‡ç³»åœ¨ origin åæ ‡ç³»ä¸‹çš„è¡¨ç¤ºï¼ˆæ–¹å‘å‘é‡ï¼‰[ğ«â‚“ ğ«áµ§]áµ€:
$$ \begin{bmatrix} xâ‚œ \\ yâ‚œ \end{bmatrix} = \begin{matrix} râ‚“: \\ r_y: \end{matrix} \begin{bmatrix} aâ‚ &amp;amp; bâ‚ \\ aâ‚‚ &amp;amp; bâ‚‚ \end{bmatrix} \begin{bmatrix} xâ‚’ \\ yâ‚’ \end{bmatrix} $$
æ¨ªç€çœ‹ï¼šè¡Œå‘é‡ (aâ‚,bâ‚) æ˜¯ target ç³»çš„ x è½´åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ï¼Œ (aâ‚‚,bâ‚‚) æ˜¯ target ç³»çš„ y è½´åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ã€‚ ä¾‹å¦‚ï¼Œä¸‹å›¾ä¸­ origin ç³»æ˜¯ worldï¼Œtarget ç³»æ˜¯ camera:
Original åæ ‡$[^x_y]$åšçº¿æ€§ç»„åˆï¼Œå˜æ¢åˆ°äº† Target åæ ‡ç³»$[^{x_c}_{y_c}]$ã€‚ ç«–ç€çœ‹ï¼šåˆ—å‘é‡ (aâ‚,aâ‚‚) æ˜¯ origin ç³»çš„ x è½´åœ¨ target ç³»ä¸‹çš„æ–¹å‘å‘é‡ï¼Œ (bâ‚,bâ‚‚) æ˜¯ origin ç³»çš„ y è½´åœ¨ target ç³»ä¸‹çš„æ–¹å‘å‘é‡ã€‚'>
<title>memo: Vis | Camera Matrices</title>

<link rel='canonical' href='https://zichen34.github.io/writenotes/vis/camera_matrices/'>

<link rel="stylesheet" href="/scss/style.min.8191399262444ab68b72a18c97392f5349be20a1615d77445be51e974c144cff.css"><meta property='og:title' content='memo: Vis | Camera Matrices'>
<meta property='og:description' content='ç›¸æœºæ—‹è½¬ (2022-05-22)
åæ ‡ç³»æ—‹è½¬æ˜¯ point æ—‹è½¬çš„é€†ï¼ˆç‚¹é€†æ—¶é’ˆæ—‹è½¬Î¸ ç­‰æ•ˆäºåæ ‡ç³»é¡ºæ—¶é’ˆæ—‹è½¬Î¸ï¼‰
ç‚¹Påœ¨åˆå§‹åæ ‡ç³»ä¸‹çš„åæ ‡ä¸º Pâ‚’ï¼Œåœ¨ç›®æ ‡åæ ‡ç³»ä¸‹çš„åæ ‡ä¸º Pâ‚œï¼Œ ä» Pâ‚’ åˆ° Pâ‚œ ä¸­é—´æ˜¯ target åæ ‡ç³»åœ¨ origin åæ ‡ç³»ä¸‹çš„è¡¨ç¤ºï¼ˆæ–¹å‘å‘é‡ï¼‰[ğ«â‚“ ğ«áµ§]áµ€:
$$ \begin{bmatrix} xâ‚œ \\ yâ‚œ \end{bmatrix} = \begin{matrix} râ‚“: \\ r_y: \end{matrix} \begin{bmatrix} aâ‚ &amp;amp; bâ‚ \\ aâ‚‚ &amp;amp; bâ‚‚ \end{bmatrix} \begin{bmatrix} xâ‚’ \\ yâ‚’ \end{bmatrix} $$
æ¨ªç€çœ‹ï¼šè¡Œå‘é‡ (aâ‚,bâ‚) æ˜¯ target ç³»çš„ x è½´åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ï¼Œ (aâ‚‚,bâ‚‚) æ˜¯ target ç³»çš„ y è½´åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ã€‚ ä¾‹å¦‚ï¼Œä¸‹å›¾ä¸­ origin ç³»æ˜¯ worldï¼Œtarget ç³»æ˜¯ camera:
Original åæ ‡$[^x_y]$åšçº¿æ€§ç»„åˆï¼Œå˜æ¢åˆ°äº† Target åæ ‡ç³»$[^{x_c}_{y_c}]$ã€‚ ç«–ç€çœ‹ï¼šåˆ—å‘é‡ (aâ‚,aâ‚‚) æ˜¯ origin ç³»çš„ x è½´åœ¨ target ç³»ä¸‹çš„æ–¹å‘å‘é‡ï¼Œ (bâ‚,bâ‚‚) æ˜¯ origin ç³»çš„ y è½´åœ¨ target ç³»ä¸‹çš„æ–¹å‘å‘é‡ã€‚'>
<meta property='og:url' content='https://zichen34.github.io/writenotes/vis/camera_matrices/'>
<meta property='og:site_name' content='Zichen Wang'>
<meta property='og:type' content='article'><meta property='article:section' content='WriteNotes' /><meta property='article:published_time' content='2022-05-22T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2022-05-22T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="memo: Vis | Camera Matrices">
<meta name="twitter:description" content="ç›¸æœºæ—‹è½¬ (2022-05-22)
åæ ‡ç³»æ—‹è½¬æ˜¯ point æ—‹è½¬çš„é€†ï¼ˆç‚¹é€†æ—¶é’ˆæ—‹è½¬Î¸ ç­‰æ•ˆäºåæ ‡ç³»é¡ºæ—¶é’ˆæ—‹è½¬Î¸ï¼‰
ç‚¹Påœ¨åˆå§‹åæ ‡ç³»ä¸‹çš„åæ ‡ä¸º Pâ‚’ï¼Œåœ¨ç›®æ ‡åæ ‡ç³»ä¸‹çš„åæ ‡ä¸º Pâ‚œï¼Œ ä» Pâ‚’ åˆ° Pâ‚œ ä¸­é—´æ˜¯ target åæ ‡ç³»åœ¨ origin åæ ‡ç³»ä¸‹çš„è¡¨ç¤ºï¼ˆæ–¹å‘å‘é‡ï¼‰[ğ«â‚“ ğ«áµ§]áµ€:
$$ \begin{bmatrix} xâ‚œ \\ yâ‚œ \end{bmatrix} = \begin{matrix} râ‚“: \\ r_y: \end{matrix} \begin{bmatrix} aâ‚ &amp;amp; bâ‚ \\ aâ‚‚ &amp;amp; bâ‚‚ \end{bmatrix} \begin{bmatrix} xâ‚’ \\ yâ‚’ \end{bmatrix} $$
æ¨ªç€çœ‹ï¼šè¡Œå‘é‡ (aâ‚,bâ‚) æ˜¯ target ç³»çš„ x è½´åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ï¼Œ (aâ‚‚,bâ‚‚) æ˜¯ target ç³»çš„ y è½´åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ã€‚ ä¾‹å¦‚ï¼Œä¸‹å›¾ä¸­ origin ç³»æ˜¯ worldï¼Œtarget ç³»æ˜¯ camera:
Original åæ ‡$[^x_y]$åšçº¿æ€§ç»„åˆï¼Œå˜æ¢åˆ°äº† Target åæ ‡ç³»$[^{x_c}_{y_c}]$ã€‚ ç«–ç€çœ‹ï¼šåˆ—å‘é‡ (aâ‚,aâ‚‚) æ˜¯ origin ç³»çš„ x è½´åœ¨ target ç³»ä¸‹çš„æ–¹å‘å‘é‡ï¼Œ (bâ‚,bâ‚‚) æ˜¯ origin ç³»çš„ y è½´åœ¨ target ç³»ä¸‹çš„æ–¹å‘å‘é‡ã€‚">
    <link rel="shortcut icon" href="/favicon-32x32.png" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu238e2fe759432347fa5dd53661ac4381_131637_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Zichen Wang</a></h1>
            <h2 class="site-description"></h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/zichen34'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://twitter.com/luckily1640'
                        target="_blank"
                        title="Twitter"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/aboutme/' >
                
                
                
                <span>About</span>
            </a>
        </li>
        
        
        <li >
            <a href='/writenotes/' >
                
                
                
                <span>WriteNotes</span>
            </a>
        </li>
        
        
        <li >
            <a href='/page/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#ç›¸æœºæ—‹è½¬">ç›¸æœºæ—‹è½¬</a></li>
    <li><a href="#é€è§†æŠ•å½±">é€è§†æŠ•å½±</a></li>
    <li><a href="#æŠ•å½±å˜æ¢">æŠ•å½±å˜æ¢</a></li>
    <li><a href="#ndc-ç©ºé—´">NDC ç©ºé—´</a></li>
    <li><a href="#ç›¸æœºå˜æ¢çŸ©é˜µ">ç›¸æœºå˜æ¢çŸ©é˜µ</a></li>
    <li><a href="#3ä¸ªçŸ©é˜µ">3ä¸ªçŸ©é˜µ</a></li>
    <li><a href="#uvn-æ¨¡å‹">UVN æ¨¡å‹</a></li>
    <li><a href="#cam-coords-system">Cam Coords System</a></li>
    <li><a href="#identify-cam-axes">Identify Cam Axes</a></li>
    <li><a href="#opencv2opengl">OpenCV2OpenGL</a></li>
    <li><a href="#dtu-dataset">DTU dataset</a>
      <ol>
        <li><a href="#original">Original</a></li>
        <li><a href="#mvsnet">MVSNet</a></li>
        <li><a href="#mvsnet-pytorch">MVSNet-PyTorch</a></li>
        <li><a href="#pixelnerf">PixelNeRF</a></li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/memo/" style="background-color: #6e57d2; color: #fff;">
                memo
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/writenotes/vis/camera_matrices/">memo: Vis | Camera Matrices</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">May 22, 2022</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    22 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h2 id="ç›¸æœºæ—‹è½¬">ç›¸æœºæ—‹è½¬</h2>
<p>(2022-05-22)</p>
<p>åæ ‡ç³»æ—‹è½¬æ˜¯ point æ—‹è½¬çš„é€†ï¼ˆç‚¹é€†æ—¶é’ˆæ—‹è½¬Î¸ ç­‰æ•ˆäºåæ ‡ç³»é¡ºæ—¶é’ˆæ—‹è½¬Î¸ï¼‰</p>
<p>ç‚¹Påœ¨åˆå§‹åæ ‡ç³»ä¸‹çš„åæ ‡ä¸º Pâ‚’ï¼Œåœ¨ç›®æ ‡åæ ‡ç³»ä¸‹çš„åæ ‡ä¸º Pâ‚œï¼Œ
ä» Pâ‚’ åˆ° Pâ‚œ ä¸­é—´æ˜¯ <strong>target åæ ‡ç³»åœ¨ origin åæ ‡ç³»ä¸‹çš„è¡¨ç¤º</strong>ï¼ˆæ–¹å‘å‘é‡ï¼‰[ğ«â‚“ ğ«áµ§]áµ€:</p>
<p>$$
\begin{bmatrix}  xâ‚œ \\ yâ‚œ  \end{bmatrix} =
\begin{matrix} râ‚“: \\ r_y: \end{matrix}
\begin{bmatrix} aâ‚ &amp; bâ‚ \\ aâ‚‚ &amp; bâ‚‚ \end{bmatrix}
\begin{bmatrix}  xâ‚’ \\ yâ‚’  \end{bmatrix}
$$</p>
<ul>
<li>
<p>æ¨ªç€çœ‹ï¼šè¡Œå‘é‡ (aâ‚,bâ‚) æ˜¯ target ç³»çš„ x è½´åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ï¼Œ
(aâ‚‚,bâ‚‚) æ˜¯ target ç³»çš„ y è½´åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ã€‚
ä¾‹å¦‚ï¼Œä¸‹å›¾ä¸­ origin ç³»æ˜¯ worldï¼Œtarget ç³»æ˜¯ camera:</p>
<div align="center">




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/coordinate_transform_uofminnesota.png width=>
  
  

</div>
<ul>
<li>Original åæ ‡$[^x_y]$åšçº¿æ€§ç»„åˆï¼Œå˜æ¢åˆ°äº† Target åæ ‡ç³»$[^{x_c}_{y_c}]$ã€‚</li>
</ul>
</li>
<li>
<p>ç«–ç€çœ‹ï¼šåˆ—å‘é‡ (aâ‚,aâ‚‚) æ˜¯ origin ç³»çš„ x è½´åœ¨ target ç³»ä¸‹çš„æ–¹å‘å‘é‡ï¼Œ
(bâ‚,bâ‚‚) æ˜¯ origin ç³»çš„ y è½´åœ¨ target ç³»ä¸‹çš„æ–¹å‘å‘é‡ã€‚</p>
<div align="center">




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/coordinate_transform_uofminnesota_2.png width=>
  
  

</div>
</li>
<li>
<p>ç»¼ä¸Šï¼Œæ—‹è½¬çŸ©é˜µ R (in w2c) æ¨ªç€çœ‹å°±æ˜¯ camera (target) ç³»åœ¨ world ç³»ä¸‹çš„è¡¨ç¤ºï¼Œç«–ç€çœ‹å°±æ˜¯ world (original) ç³»åœ¨ camera ç³»ä¸‹çš„è¡¨ç¤ºã€‚</p>
<ul>
<li>(2023-11-05) æ‰€ä»¥é€šè¿‡è½¬ç½®å°±å¯ä»¥æŠŠ R in w2c åˆ‡æ¢æˆ R in c2wã€‚
ä½†æ˜¯è¦æŠŠ w2c å˜æˆ c2wï¼Œéœ€è¦å¯¹ [R|t] æ•´ä½“æ±‚é€†ã€‚</li>
</ul>
</li>
<li>
<p>æ¬§å‡ é‡Œå¾—å˜æ¢ [R T]ï¼šæ—‹è½¬çŸ©é˜µ R åŠ å¹³ç§»å‘é‡ Tï¼ŒæŠŠç‚¹åœ¨ origin ç³»çš„åæ ‡å˜æˆåœ¨ target ç³»ä¸‹çš„åæ ‡ï¼Œæˆ–è€…è¯´æŠŠ origin ç³»å˜æ¢æˆ target ç³»ã€‚</p>
<p>For example, w2c as below.</p>
<ol>
<li>
<p>å…ˆæ—‹è½¬åå¹³ç§»ï¼šç‚¹åœ¨ origin (world) ç³»ä¸‹çš„åæ ‡å…ˆç»è¿‡ target (camera) ç³»åœ¨ origin ç³»ä¸‹çš„æ–¹å‘å‘é‡ R çš„çº¿æ€§ç»„åˆï¼Œå³
<strong>æŠ•å½±</strong>ï¼ˆåšå†…ç§¯ï¼‰åˆ°äº†ä¸€ä¸ªä¸ target ç³»åæ ‡è½´éƒ½å¹³è¡Œçš„æ–°åæ ‡ç³»ï¼ˆè™šçº¿ï¼‰ä¸‹ï¼Œ
å†åŠ ä¸Šä¸€æ®µå¹³ç§»å‘é‡ Tï¼Œä»è€Œä½¿æ–°åæ ‡æ˜¯ä»¥ target ç³»çš„åŸç‚¹å¼€å§‹ï¼Œæ‰€ä»¥ T å°±æ˜¯ origin ç³»çš„åŸç‚¹åœ¨ target ç³»è§†è§’ä¸‹çš„åæ ‡ã€‚</p>
<div align="center">




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/coordinate_transform_euclidean.png width=>
  
  

</div>
<ul>
<li>
<p>This process is expressed by [R|t]. Conversely,
[R|t] denotes rotation first then translation.</p>
</li>
<li>
<p>(2024-01-09) ğ­ is coordinate measured in the target space,
because ğ­ is simply <strong>added</strong> onto the target coordiantes without &ldquo;recombination&rdquo; of the elementary vectors in a basis.
Therefore, ğ­ is the original center seen from the target space.</p>
</li>
</ul>
</li>
<li>
<p>æˆ–è€…å…ˆå¹³ç§»åæ—‹è½¬ï¼šorigin (world) ç³»ä¸‹çš„åæ ‡å…ˆå‡å» target (camera) ç³»åŸç‚¹åœ¨ origin ç³»ä¸‹çš„åæ ‡ Cï¼Œ
å˜åˆ°äº†ä¸€ä¸ªæ–°åæ ‡ç³»ä¸‹ï¼ˆå…¶åŸç‚¹ä¸ target ç³»åŸç‚¹é‡åˆï¼‰ï¼Œ
å†æ—‹è½¬åˆ°ä¸ target ç³»å„è½´é‡åˆï¼›æ‰€ä»¥ C å°±æ˜¯ camera å…‰å¿ƒåœ¨ world ç³»ä¸‹çš„åæ ‡ã€‚</p>
<div align="center">




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/coordinate_transform_euclidean_2.png width=>
  
  

</div>
<ul>
<li>In this case, R and T can&rsquo;t be written as an augmented matrix, but separate matrices.</li>
</ul>
</li>
</ol>
<ul>
<li>If the given point&rsquo;s coords are world coords, then apply [R|t].
While if point is already in camera space, only apply [R].</li>
</ul>
</li>
<li>
<p>å¯å€ŸåŠ© vanishing points (å¾…å®šç³»æ•°)æ¥æ±‚æ—‹è½¬çŸ©é˜µï¼ˆThis point is at infinite but finite in image.ï¼‰
<a class="link" href="https://www-users.cse.umn.edu/~hspark/CSci5980/Lec2_ProjectionMatrix.pdf"  target="_blank" rel="noopener"
    >Camera Projection Matrix-UofMinnesota</a></p>
</li>
</ul>
<hr>
<h2 id="é€è§†æŠ•å½±">é€è§†æŠ•å½±</h2>
<p>(2022-05-08)</p>
<p>é€è§†æŠ•å½±ï¼ˆå†…å‚çŸ©é˜µKï¼‰æŠŠ camera space ä¸‹çš„åæ ‡æŠ•å½±åˆ°ç„¦å¹³é¢ä¸Šï¼ŒX é™¤ä»¥ Z ä¹˜ä»¥ fï¼ˆå³ä»¥ f/z ä¸ºç³»æ•°å¯¹ x,y åšä¸€ä¸ªç¼©æ”¾ï¼‰ã€‚
å¦‚æœç„¦è·(ç„¦å¹³é¢è·ç¦») f æ˜¯å¸¸æ•°ï¼Œé‚£å°±ç›´æ¥æ˜¯ä¸ z æˆåæ¯”ã€‚</p>
<ul>
<li>(2024-01-31) æ‰€ä»¥ &ldquo;z&rdquo; ä»£è¡¨çš„æ˜¯ &ldquo;Zoom&rdquo; ç¼©æ”¾ï¼šè¿‘å¤§è¿œå°.
<a class="link" href="https://youtu.be/PGtv-dBi2wE?si=nPkrszDNt7-DCdQS&amp;t=16"  target="_blank" rel="noopener"
    >Ray Marching for Dummies! - Ytb - The Art of Code</a></li>
</ul>
<p>ï¼ˆè¿™é‡Œåæ ‡éƒ½æ˜¯ç»å¯¹å€¼ï¼Œä¸è€ƒè™‘åæ ‡ç³»çš„é€‰å–ï¼‰</p>



<div class="goat svg-container ">
  
    <svg
      xmlns="http://www.w3.org/2000/svg"
      font-family="Menlo,Lucida Console,monospace"
      
        viewBox="0 0 264 121"
      >
      <g transform='translate(8,16)'>
<path d='M 40,64 L 48,64' fill='none' stroke='currentColor'></path>
<path d='M 80,64 L 88,64' fill='none' stroke='currentColor'></path>
<path d='M 176,64 L 184,64' fill='none' stroke='currentColor'></path>
<path d='M 80,32 L 80,64' fill='none' stroke='currentColor'></path>
<path d='M 80,64 L 80,96' fill='none' stroke='currentColor'></path>
<path d='M 88,80 L 88,96' fill='none' stroke='currentColor'></path>
<path d='M 144,16 L 144,64' fill='none' stroke='currentColor'></path>
<path d='M 112,48 L 128,16' fill='none' stroke='currentColor'></path>
<path d='M 88,72 L 88,80' fill='none' stroke='currentColor'></path>
<polygon points='48.000000,64.000000 36.000000,58.400002 36.000000,69.599998' fill='currentColor' transform='rotate(180.000000, 40.000000, 64.000000)'></polygon>
<polygon points='96.000000,96.000000 84.000000,90.400002 84.000000,101.599998' fill='currentColor' transform='rotate(90.000000, 88.000000, 96.000000)'></polygon>
<polygon points='152.000000,16.000000 140.000000,10.400000 140.000000,21.600000' fill='currentColor' transform='rotate(270.000000, 144.000000, 16.000000)'></polygon>
<polygon points='192.000000,64.000000 180.000000,58.400002 180.000000,69.599998' fill='currentColor' transform='rotate(0.000000, 184.000000, 64.000000)'></polygon>
<text text-anchor='middle' x='0' y='68' fill='currentColor' style='font-size:1em'>B</text>
<text text-anchor='middle' x='8' y='68' fill='currentColor' style='font-size:1em'>a</text>
<text text-anchor='middle' x='16' y='68' fill='currentColor' style='font-size:1em'>c</text>
<text text-anchor='middle' x='24' y='68' fill='currentColor' style='font-size:1em'>k</text>
<text text-anchor='middle' x='56' y='20' fill='currentColor' style='font-size:1em'>p</text>
<text text-anchor='middle' x='64' y='20' fill='currentColor' style='font-size:1em'>l</text>
<text text-anchor='middle' x='72' y='20' fill='currentColor' style='font-size:1em'>a</text>
<text text-anchor='middle' x='72' y='100' fill='currentColor' style='font-size:1em'>y</text>
<text text-anchor='middle' x='80' y='20' fill='currentColor' style='font-size:1em'>n</text>
<text text-anchor='middle' x='88' y='20' fill='currentColor' style='font-size:1em'>e</text>
<text text-anchor='middle' x='88' y='52' fill='currentColor' style='font-size:1em'>f</text>
<text text-anchor='middle' x='96' y='68' fill='currentColor' style='font-size:1em'>-</text>
<text text-anchor='middle' x='96' y='84' fill='currentColor' style='font-size:1em'>/</text>
<text text-anchor='middle' x='104' y='68' fill='currentColor' style='font-size:1em'>0</text>
<text text-anchor='middle' x='104' y='84' fill='currentColor' style='font-size:1em'>p</text>
<text text-anchor='middle' x='112' y='68' fill='currentColor' style='font-size:1em'>-</text>
<text text-anchor='middle' x='112' y='84' fill='currentColor' style='font-size:1em'>i</text>
<text text-anchor='middle' x='120' y='68' fill='currentColor' style='font-size:1em'>-</text>
<text text-anchor='middle' x='120' y='84' fill='currentColor' style='font-size:1em'>n</text>
<text text-anchor='middle' x='128' y='52' fill='currentColor' style='font-size:1em'>Z</text>
<text text-anchor='middle' x='128' y='68' fill='currentColor' style='font-size:1em'>-</text>
<text text-anchor='middle' x='128' y='84' fill='currentColor' style='font-size:1em'>h</text>
<text text-anchor='middle' x='136' y='68' fill='currentColor' style='font-size:1em'>-</text>
<text text-anchor='middle' x='136' y='84' fill='currentColor' style='font-size:1em'>o</text>
<text text-anchor='middle' x='144' y='4' fill='currentColor' style='font-size:1em'>Y</text>
<text text-anchor='middle' x='144' y='84' fill='currentColor' style='font-size:1em'>l</text>
<text text-anchor='middle' x='152' y='84' fill='currentColor' style='font-size:1em'>e</text>
<text text-anchor='middle' x='200' y='68' fill='currentColor' style='font-size:1em'>F</text>
<text text-anchor='middle' x='208' y='68' fill='currentColor' style='font-size:1em'>r</text>
<text text-anchor='middle' x='216' y='68' fill='currentColor' style='font-size:1em'>o</text>
<text text-anchor='middle' x='224' y='68' fill='currentColor' style='font-size:1em'>n</text>
<text text-anchor='middle' x='232' y='68' fill='currentColor' style='font-size:1em'>t</text>
</g>

    </svg>
  
</div>
<ul>
<li>å› ä¸ºæ™¯ç‰©æ˜¯ <strong>å€’ç½®</strong> çš„ï¼Œæ‰€ä»¥åƒç´ åæ ‡ç³»çš„ y è½´æ˜¯å‘ä¸‹çš„ï¼Ÿ</li>
</ul>
<p>è‹¥é‡‡ç”¨é½æ¬¡åæ ‡ï¼ˆç”¨çŸ©é˜µè¡¨è¾¾é™¤æ³•ï¼‰, å¯¹ [X,Y,Z] åšé€è§†æŠ•å½±å¾—åˆ°çš„æ˜¯ [fX, fY, Z]ï¼Œåˆ™ [u, v, 1] = [fX/Z, fY/Z, 1]ã€‚
å†ä»¥åƒç´ å°ºå¯¸ dx,dy ç¼©æ”¾å¹¶åŠ ä¸Š(+)å…‰å¿ƒåæ ‡ cx,cyï¼ŒæŠŠåŸç‚¹ä»å…‰å¿ƒç§»åˆ°å·¦ä¸Šè§’ï¼ˆåƒç´ ç³»çš„vè½´æ˜¯æœä¸‹çš„ï¼Œæ‰€ä»¥è¿˜éœ€è¦åŠ è´Ÿå·ï¼Ÿï¼‰ï¼Œå°±å˜åˆ°äº†åƒç´ åæ ‡ç³»ä¸‹ï¼š</p>
<p>$$
\begin{bmatrix}  \frac{f}{dx} &amp; 0 &amp; câ‚“ \\ 0 &amp; \frac{f}{dy} &amp; c_y \\ 0 &amp; 0 &amp; 1 \end{bmatrix}
\begin{bmatrix}  X \\ Y \\ Z  \end{bmatrix} =
\begin{bmatrix}  fâ‚“X + câ‚“Z \\ f_yY + c_yZ \\ Z  \end{bmatrix} =
\begin{bmatrix} \frac{fâ‚“X}{Z}+câ‚“ \\ \frac{f_yY}{Z}+c_y \\ 1 \end{bmatrix}
$$</p>
<hr>
<h2 id="æŠ•å½±å˜æ¢">æŠ•å½±å˜æ¢</h2>
<p>æŠ•å½±å˜æ¢ <code>GL_PROJECTION</code> æ˜¯æŠŠ <strong>ç›¸æœºç©ºé—´</strong> ä¸‹çš„ç‚¹ (xâ‚‘,yâ‚‘,zâ‚‘) å˜æ¢åˆ° <strong>å±å¹•ç©ºé—´</strong> çš„ clip åæ ‡ (xc,yc,zc,wc)ï¼š</p>
<div class="table-wrapper"><table><tr>
<td><figure><a href="http://www.songho.ca/opengl/gl_projectionmatrix.html"><img src="http://www.songho.ca/opengl/files/gl_projectionmatrix01.png"/></a>
</figure>
</td>
<td><figure><img src="http://www.songho.ca/opengl/files/gl_frustumclip.png"/>
</figure>
</td>
</table></div>
<ol>
<li>
<p>å…ˆé€è§†æŠ•å½± (1/Zç¼©æ”¾) åˆ°ç›¸æœºçš„ near plane (ç„¦è·ä¸º-n)ã€‚</p>
<div class="table-wrapper"><table><tr>
<td><figure><img src="http://www.songho.ca/opengl/files/gl_projectionmatrix03.png"/>
</figure>
</td>
<td><figure><img src="http://www.songho.ca/opengl/files/gl_projectionmatrix04.png"/>
</figure>
</td>
</table></div>
é€è§†é™¤æ³•éœ€è¦é™¤ä»¥ -zâ‚‘ï¼Œæ‰€ä»¥é½æ¬¡åæ ‡çš„ wâ‚‘ = -zâ‚‘
</li>
<li>
<p>å†æŠŠ x,y çš„å–å€¼èŒƒå›´ï¼š[top,bottom],[left,right] çº¿æ€§å˜æ¢åˆ°[-1,1]ã€‚</p>
<div class="table-wrapper"><table><tr>
<td><figure><img src="http://www.songho.ca/opengl/files/gl_projectionmatrix05.png"/>
</figure>
</td>
<td><figure><img src="http://www.songho.ca/opengl/files/gl_projectionmatrix06.png"/>
</figure>
</td>
</table></div>
</li>
<li>
<p>ä»¤ç›¸æœºç©ºé—´ä¸‹çš„ [near, far] çš„ NDC åæ ‡ç­‰äº [-1, 1]</p>
</li>
<li>
<p>å› ä¸ºæ˜¯ä»ä¸‰ç»´åˆ°ä¸‰ç»´ï¼Œè¦æƒ³ç”¨çŸ©é˜µè¡¨è¾¾é€è§†ç¼©æ”¾å’Œå¹³ç§»ï¼Œå°±éœ€è¦ä½¿ç”¨é½æ¬¡åæ ‡ã€‚</p>
<p>clip åæ ‡æ˜¯ NDC çš„é½æ¬¡å½¢å¼ï¼Œæ‰€ä»¥è¿™ä¸ªçŸ©é˜µï¼ˆ<a class="link" href="http://www.songho.ca/opengl/gl_projectionmatrix.html"  target="_blank" rel="noopener"
    >Projection Matrix</a>ï¼‰
å®Œæˆäº† frustum culling å’Œ NDC å˜æ¢ã€‚</p>
</li>
</ol>
<p>$$
\begin{bmatrix} \frac{2}{r-l}â‹…n &amp; 0 &amp; \frac{r+l}{r-l} &amp; 0 \\
0 &amp; \frac{2}{t-b}â‹…n &amp; \frac{t+b}{t-b} &amp; 0 \\
0 &amp; 0 &amp; -\frac{f+n}{f-n} &amp; -\frac{2fn}{f-n} \\
0 &amp; 0 &amp; -1 &amp; 0 \end{bmatrix}
\begin{bmatrix} xâ‚‘ \\ yâ‚‘ \\ zâ‚‘ \\ 1 \end{bmatrix} =
\begin{bmatrix}  \frac{2}{r-l}â‹…nxâ‚‘ + \frac{r+l}{r-l}â‹…zâ‚‘ \\
\frac{2}{t-b}â‹…nyâ‚‘ + \frac{t+b}{t-b}â‹…zâ‚‘ \\
-\frac{f+n}{f-n}â‹…zâ‚‘ -\frac{2fn}{f-n} \\
-zâ‚‘ \end{bmatrix} =
\begin{bmatrix}  \frac{2}{r-l}â‹…n\frac{xâ‚‘}{-zâ‚‘} + \frac{r+l}{r-l} \\
\frac{2}{t-b}â‹…n\frac{yâ‚‘}{-zâ‚‘} + \frac{t+b}{t-b} \\
\frac{f+n}{f-n} +\frac{2fn}{(f-n)zâ‚‘} \ 1 \end{bmatrix}
$$</p>
<p><a class="link" href="https://www.cs.utexas.edu/~theshark/courses/cs354/lectures/cs354-9.pdf"  target="_blank" rel="noopener"
    >viewing&amp;project-utexas</a></p>
<hr>
<h2 id="ndc-ç©ºé—´">NDC ç©ºé—´</h2>
<ul>
<li>
<p>å±å¹•æ˜¾ç¤ºçš„ä¸–ç•Œæ·±åº¦èŒƒå›´æ˜¯ near,far ä¸¤ä¸ªç„¦å¹³é¢ä¹‹é—´çš„åŒºåŸŸã€‚
openGL ä¸­ä¸¤ç„¦å¹³é¢é—´çš„ z interval è¢«æ˜ å°„åˆ° [-1,1]ï¼Œå³ Normalized Device Coordinatesï¼Œ
å˜æ¢åˆ° NDC åå°±å¯ä»¥æ ¹æ®<code>z_ndc</code>æŠŠè¶…å‡ºèŒƒå›´å¤–çš„ç‰©ä½“è£å‰ªæ‰ã€‚</p>
<p>å±å¹•çª—å£æ˜¾ç¤ºçš„æ˜¯è¿‘ç„¦å¹³é¢ã€‚å¯ä»¥ç”¨ fov æ§åˆ¶è¿‘ç„¦å¹³é¢çš„è¾¹é•¿ï¼Œå¯ä»¥æŠŠå±å¹•çš„ t,b,l,r æ˜ å°„åˆ°è¿‘ç„¦å¹³é¢çš„è¾¹é•¿ [-1,1]ï¼Œè¿™æ ·å±å¹•æ˜¾ç¤ºçš„ç©ºé—´å°±æ˜¯ä¸€ä¸ªç«‹æ–¹ä½“ã€‚
<a class="link" href="https://www.bilibili.com/video/BV1LS4y1b7xZ"  target="_blank" rel="noopener"
    >æ¢ç§˜ä¸‰ç»´é€è§†æŠ•å½±-é½æ¬¡åæ ‡çš„å¦™ç”¨ -å¥‡ä¹bili</a></p>
</li>
<li>
<p>(2023-11-30) NDC = Perspective projection to the near plane <strong>with depths kept</strong> + Scaling.</p>
</li>
</ul>
<hr>
<h2 id="ç›¸æœºå˜æ¢çŸ©é˜µ">ç›¸æœºå˜æ¢çŸ©é˜µ</h2>
<p><a class="link" href="https://blog.csdn.net/popy007/article/details/5120158"  target="_blank" rel="noopener"
    >æ¨å¯¼ç›¸æœºå˜æ¢çŸ©é˜µ-csdn-æ½˜å®</a></p>
<ul>
<li>
<p>(ä¸åŒåŸºåº•é—´çš„) åæ ‡è½¬æ¢å…¬å¼: ğ¯=ğ ğ¯&rsquo;=ğ‘ ğ¯&rsquo;&rsquo; â‡’ ğ¯&rsquo;&rsquo;= ğ‘â»Â¹ğ ğ¯&rsquo;ï¼Œå…¶ä¸­ğ,ğ‘ æ˜¯ä¸åŒçš„æ­£äº¤çŸ©é˜µï¼Œä»£è¡¨åæ ‡ç³»ï¼Œå› ä¸ºæ­£äº¤çŸ©é˜µçš„é€†ç­‰äºè½¬ç½®ï¼Œæ‰€ä»¥å¯ä»¥å†™ä¸ºï¼šğ¯&rsquo;&rsquo;= ğ‘áµ€ğ ğ¯'</p>
</li>
<li>
<p>UVNç›¸æœºæ¨¡å‹ç”¨å‘é‡å®šä¹‰ç›¸æœºæœå‘ï¼šN æ˜¯ç›¸æœºè§‚å¯Ÿæ–¹å‘çš„åæ–¹å‘ï¼ŒU ç”±è¾…åŠ©å‘é‡upä¸Nå‰ä¹˜ç¡®å®šï¼Œè¾…åŠ©å‘é‡ç”¨äºè®©ç›¸æœºäº§ç”Ÿåè½¬ï¼ˆä¸æ­ªå¤´ä¸€èˆ¬å–(0,1,0)ï¼‰ï¼›V=NÃ—Uï¼ŒV è½åœ¨ up ä¸ N å½¢æˆçš„å¹³é¢ä¸Šã€‚<br>
ä¾‹å¦‚nerfçš„å‡½æ•°<a class="link" href="https://github.com/bmild/nerf/blob/18b8aebda6700ed659cb27a0c348b737a5f6ab60/load_llff.py#L128"  target="_blank" rel="noopener"
    >viewmatrix()</a> ç”¨äºæ„å»ºå¹³å‡ç›¸æœºä½å§¿ <code>poses_avg</code> çš„UVNç›¸æœºåæ ‡ç³» [X|Y|Z]ï¼ˆä¸–ç•Œç³»åªæœ‰ä¸€ä¸ªï¼Œè€Œç›¸æœºç³»æœ‰å¤šä¸ªï¼Œå–å¹³å‡ç›¸æœºç³»ä½œä¸º&rsquo;æ–°ä¸–ç•Œç³»&rsquo;ï¼‰ã€‚</p>
</li>
<li>
<p>View transformation: æŠŠç‰©ä½“åæ ‡ä»ä¸–ç•Œç³»å˜æ¢åˆ°ç›¸æœºç³»ä¸‹ï¼Œä¹Ÿå°±æ˜¯åšä¸€æ¬¡ç›¸æœºè¿åŠ¨çš„é€†å˜æ¢ã€‚å˜æ¢è¿‡ç¨‹ï¼šåˆå§‹æ—¶ç›¸æœºç³»ä¸ä¸–ç•Œç³»é‡åˆï¼Œ(åœ¨ä¸–ç•Œç³»ä¸‹)ç›¸æœºåšæ—‹è½¬ã€å†å¹³ç§»æ¥è¿‘ç‰©ä½“ï¼Œç„¶åç›¸æœºä¸ç‰©ä½“ä¸€èµ·åšé€†å¹³ç§»ã€é€†æ—‹è½¬ï¼Œç›¸æœºåˆå›åˆ°åˆå§‹ä½ç½®ï¼Œç‰©ä½“å°±å˜åˆ°äº†ç›¸æœºç³»ä¸‹ã€‚<br>
é€†å¹³ç§»æ˜“æ±‚(å–å)ï¼Œé€†æ—‹è½¬ä¸æ˜“æ±‚(æ±‚é€†çš„é¡ºåº)ï¼›ä½†æ˜¯åšå®Œé€†å¹³ç§»åï¼Œç›¸æœºç³»ä¸ä¸–ç•Œç³»çš„åŸç‚¹é‡åˆäº†ï¼Œåªæ˜¯åŸºåº•ä¸åŒï¼Œåˆ©ç”¨åæ ‡è½¬æ¢å…¬å¼å°±å¯ä»¥æ±‚å‡ºåœ¨ç›¸æœºç³»ä¸‹çš„åæ ‡ ğ¯&rsquo;&rsquo;= ğ‘áµ€ğ ğ¯&rsquo;ï¼Œå…¶ä¸­ğ‘æ˜¯UVNç³»ç»Ÿï¼Œğ æ˜¯ä¸–ç•Œç³»(å¯¹è§’é˜µ)ï¼Œğ¯&rsquo;æ˜¯é€†å¹³ç§»åçš„å‘é‡ğ“â»Â¹ğ¯ï¼Œæ•…æœ€ç»ˆçš„åæ ‡å˜æ¢çŸ©é˜µ(w2cå¤–å‚çŸ©é˜µExtrinsic matrix)ï¼šğ‘áµ€ğ ğ“â»Â¹</p>
</li>
<li>
<p>doubt: æ—‹è½¬çŸ©é˜µæ±‚é€† <a class="link" href="https://duckduckgo.com/?q=%e9%80%86%e6%97%8b%e8%bd%ac%e7%9f%a9%e9%98%b5%e4%b8%8d%e5%a5%bd%e6%b1%82&amp;ia=web"  target="_blank" rel="noopener"
    >DDG</a></p>
</li>
</ul>
<hr>
<h2 id="3ä¸ªçŸ©é˜µ">3ä¸ªçŸ©é˜µ</h2>
<ol>
<li>
<p>å¤–å‚çŸ©é˜µæŠŠç‚¹çš„ world space åæ ‡ Xw å˜æ¢åˆ°ç›¸æœºç³»ä¸‹ï¼šXc=Râ‹…Xw+Tï¼›</p>
</li>
<li>
<p>å†…å‚çŸ©é˜µæŠŠç‚¹çš„ camera space åæ ‡ Xc å˜æ¢åˆ°ç„¦å¹³é¢(åŸç‚¹åœ¨å›¾ç‰‡ä¸­å¤®)
ï¼ˆåŠ ä¸Šç¼©æ”¾å› å­fx,fyå’Œå…‰å¿ƒåæ ‡(cx,cy)å¯ä»¥å˜æ¢åˆ°åƒç´ åæ ‡ç³»u,vï¼Œ
åŸç‚¹åœ¨å›¾ç‰‡å·¦ä¸Šè§’,vè½´æœä¸‹ï¼‰ä¸Šï¼šP=Kâ‹…Xcï¼›</p>
</li>
<li>
<p>ç›¸æœºæŠ•å½±çŸ©é˜µ Camera projection matrixï¼šæŠŠä¸–ç•Œç‚¹ç›´æ¥å˜æ¢åˆ°å›¾åƒå¹³é¢ä¸Šï¼ˆå†…å‚çŸ©é˜µKâ‚ƒâ‚“â‚ƒ âˆ— å¤–å‚çŸ©é˜µ[R T]â‚ƒâ‚“â‚„ = Pâ‚ƒâ‚“â‚„ï¼‰ã€‚</p>
</li>
</ol>
<p>Ref:</p>
<ul>
<li><a class="link" href="https://www.cs.cmu.edu/~16385/s17/Slides/11.1_Camera_matrix.pdf"  target="_blank" rel="noopener"
    >11.1 Camera matrix-CMU</a></li>
<li><a class="link" href="https://www.cnblogs.com/wangguchangqing/p/8126333.html#autoid-0-5-0"  target="_blank" rel="noopener"
    >SLAMå…¥é—¨ä¹‹è§†è§‰é‡Œç¨‹è®¡(2)ï¼šç›¸æœºæ¨¡å‹ï¼ˆå†…å‚æ•°ï¼Œå¤–å‚æ•°ï¼‰</a></li>
<li><a class="link" href="https://www.opencv.org.cn/opencvdoc/2.3.2/html/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html?highlight=findfun"  target="_blank" rel="noopener"
    >Camera Calibration and 3D Reconstruction-openCV</a></li>
</ul>
<hr>
<h2 id="uvn-æ¨¡å‹">UVN æ¨¡å‹</h2>
<ul>
<li>
<p>ä»å¤–å‚çŸ©é˜µExtrinsic matrixâ‚„â‚“â‚„ æå–å‡ºç›¸æœºçš„ä½ç½®å’Œæœå‘: (æœ€åä¸€è¡Œæ˜¯é½æ¬¡åæ ‡ï¼‰<del>æœ€åä¸€åˆ—æ˜¯ä¸–ç•Œç³»ä¸­å¿ƒåœ¨ç›¸æœºç³»ä¸­çš„ä½ç½®</del>ï¼Œ
å·¦ä¸Š3x3æ˜¯ç›¸æœºåœ¨ä¸–ç•Œç³»ä¸‹æ—‹è½¬è¿åŠ¨Rçš„è½¬ç½®ï¼ˆåˆ—å‘é‡æ˜¯ä¸–ç•Œç³»ï¼Œè¡Œå‘é‡æ˜¯ç›¸æœºç³»ï¼‰ã€‚å¦‚æœå†çŸ¥é“ç›¸æœºçš„è§‚å¯Ÿæ–¹å‘ï¼Œå€ŸåŠ©ä¸€ä¸ªè¾…åŠ©å‘é‡upï¼Œå°±èƒ½ç¡®å®šUVNç³»ç»Ÿã€‚
<a class="link" href="https://math.stackexchange.com/q/82602"  target="_blank" rel="noopener"
    >StackExchange</a></p>
</li>
<li>
<p>doubt: UVN ç›¸æœºæ¨¡å‹ <a class="link" href="https://www.google.com/search?q=UVN&#43;%e7%9b%b8%e6%9c%ba%e6%a8%a1%e5%9e%8b"  target="_blank" rel="noopener"
    >Google Search</a></p>
</li>
</ul>
<hr>
<p>(2024-04-02)</p>
<ul>
<li>Establishing w2c from camera position and looking-at vector.
<a class="link" href="https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/lookat-function/framing-lookat-function.html"  target="_blank" rel="noopener"
    >Placing a Camera: the LookAt Function - Scratchapixel</a>
<ul>
<li>
<p>The &ldquo;forward&rdquo; direction is defined as <code>From - To</code>, because He marked the &ldquo;out&rdquo; of the screen as &ldquo;forward&rdquo;</p>
</li>
<li>
<p>After determining the &ldquo;forward&rdquo; vector, specify a temporary &ldquo;up&rdquo; vector (usually (0,1,0)), which is
not necessary to be perpendicular to the &ldquo;forward&rdquo;,
to produce the &ldquo;right&rdquo; vector, accroding to &ldquo;forward&quot;Ã— temporary &ldquo;up&rdquo;.</p>
<p>Once the &ldquo;right&rdquo; vector is obtained, re-construct the accurate &ldquo;up&rdquo; vector by &ldquo;forward&rdquo; cross &ldquo;right&rdquo;.
<strong>Note</strong>: He define the Backward as &ldquo;forward&rdquo;.</p>
</li>
<li>
<p>The c2w in this post is row-major format. So, he writes each row is a direction.</p>
</li>
<li>
<p>z = -1 is the camera-space coordinate of the ray direction vector.</p>
</li>
<li>
<p>The limitation of the looking-at method is the case that the &ldquo;forward&rdquo; direction is aligned with the temporary &ldquo;up&rdquo; (0,1,0),
as the cross product of 2 parallel vectors is zero $\vec{0}$.
<a class="link" href="https://math.libretexts.org/Bookshelves/Calculus/Calculus_3e_%28Apex%29/10%3A_Vectors/10.04%3A_The_Cross_Product#:~:text=Properties%20of%20the%20Cross%20Product"  target="_blank" rel="noopener"
    >10.4: The Cross Product - Mathematics LibreTexts</a></p>
<p>A solution is using quaternion.</p>
</li>
</ul>
</li>
</ul>
<p>(2024-04-04)</p>
<ul>
<li>NeRF builds RUB matrix (i.e., averaged c2w)ï¼šaverage up Ã— back (z-axis) = right (x-axis)
<a class="link" href="https://github.com/bmild/nerf/blob/18b8aebda6700ed659cb27a0c348b737a5f6ab60/load_llff.py#L128-L134"  target="_blank" rel="noopener"
    >Code</a></li>
</ul>
<hr>
<h2 id="cam-coords-system">Cam Coords System</h2>
<p>(2024-03-21)</p>
<ul>
<li>
<p>ç¡®å®šäº†ç›¸æœºåæ ‡ç³»ä¸ä¸–ç•Œåæ ‡ç³»çš„ç›¸å¯¹å…³ç³»ï¼Œæ‰èƒ½æ­£ç¡®åœ°æŠŠä¸€ä¸ª 3D ç‚¹çš„ä¸–ç•Œåæ ‡å˜æˆç›¸æœºåæ ‡ç³»ä¸‹çš„åæ ‡ã€‚</p>
<p>å‡å®šä¸–ç•Œåæ ‡ç³»æ˜¯å³æ‰‹åæ ‡ç³»ï¼Œç›¸æœºåæ ‡ç³»å¯èƒ½ä¸ä¸ä¸–ç•Œç³»é‡åˆã€‚</p>
<p>ç›¸æœºåæ ‡ç³»æœ‰ 3 ä¸ªè½´ï¼šå·¦ï¼ˆå³ï¼‰ï¼Œä¸Šï¼ˆä¸‹ï¼‰ï¼Œå‰ï¼ˆåï¼‰ï¼Œæ–¹å‘ä¸åŒåˆ™ï¼šç‚¹åœ¨è¯¥æ–¹å‘ä¸Šçš„åæ ‡ç›¸å·® 1 ä¸ªè´Ÿå·ã€‚è€Œä¸” 3 ä¸ªè½´çš„æ’åˆ—æ¬¡åºä¹Ÿä¸ç»Ÿä¸€ã€‚</p>
<figure><a href="https://zhuanlan.zhihu.com/p/593204605"><img src="https://pic3.zhimg.com/80/v2-77094ec63c1d68a0401cb0f7c10d8faa_720w.jpg"
           alt="NeRFä»£ç è§£è¯»-ç›¸æœºå‚æ•°ä¸åæ ‡ç³»å˜æ¢ - é™ˆå† è‹± - çŸ¥ä¹"/></a><figcaption>
              <p>NeRFä»£ç è§£è¯»-ç›¸æœºå‚æ•°ä¸åæ ‡ç³»å˜æ¢ - é™ˆå† è‹± - çŸ¥ä¹</p>
          </figcaption>
  </figure>

<ul>
<li>Open3D&rsquo;s camera coord. sys. is RDF. <a class="link" href="https://github.com/isl-org/Open3D/issues/1347#issuecomment-558205561"  target="_blank" rel="noopener"
    >camera coordinate system of visualization #1347</a></li>
</ul>
</li>
<li>
<p>ç¡®å®šäº†ç›¸æœºåœ¨ <strong>ä¸–ç•Œ</strong> åæ ‡ç³»ä¸­çš„æœå‘å’Œä½ç½®: Up vector, viewing direction and positionï¼Œ
æ‰å¯ä»¥æ“çºµç›¸æœº (Camera Manipulation)ï¼šChanging roll, yaw, pitch, dollying (<a class="link" href="https://www3.cs.stonybrook.edu/~qin/courses/graphics/camera-coordinate-system.pdf"  target="_blank" rel="noopener"
    >Slides - Hong Qin</a>).
An interactive example in <a class="link" href="https://learnwebgl.brown37.net/07_cameras/camera_introduction.html"  target="_blank" rel="noopener"
    >LearnWebGL</a>ã€‚
Songho also explain camera manipulation <a class="link" href="https://www.songho.ca/opengl/gl_camera.html"  target="_blank" rel="noopener"
    >OpenGL Camera</a>.</p>
<p>æ‰€ä»¥åæ ‡å˜æ¢çš„é¡ºåºæ˜¯ï¼šä¸–ç•Œç³»ä¸‹çš„åæ ‡ â¡ ç›¸æœºç³»ä¸‹çš„åæ ‡ â¡ ç›¸æœºåš 6 DoF è¿åŠ¨ï¼ˆç­‰ä»·äºç‰©ä½“çš„ç›¸æœºç³»åæ ‡åš inverse è¿åŠ¨ï¼‰â¡
åœ¨ç›¸æœºè¿åŠ¨å®Œæˆåï¼Œå†æŠŠ 3D ç‚¹åœ¨ç›¸æœºç³»ä¸‹çš„åæ ‡æŠ•å½±åˆ°ç›¸æœºå¹³é¢ã€‚</p>
</li>
<li>
<p>å¯¹äºçŸ©é˜µ w2cï¼Œå‰ 3 åˆ—çš„æ¯ä¸€åˆ—æ˜¯ä¸–ç•Œåæ ‡ç³»çš„æ¯ä¸ª axis åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„åæ ‡ã€‚</p>
<p>(2024-03-25)</p>
<ul>
<li>
<p>w2c æ˜¯æŠŠä¸€ä¸ª <strong>ç‚¹</strong> çš„ä¸–ç•Œåæ ‡è½¬æ¢æˆç›¸æœºåæ ‡ã€‚ä¸€ä¸ª 3D ç‚¹çš„åæ ‡ç­‰äº ä¸€ä¸ªæ•°ç»„ä¹˜ä»¥åæ ‡ç³»ã€‚
æ‰€ä»¥ w2c ç­‰äº rotation matrix ä¹˜ä»¥ä¸–ç•Œåæ ‡ç³»ï¼š</p>
<p>$$
\begin{bmatrix} c_{x_1} &amp; c_{y_1} &amp; c_{z_1} \\ c_{x_2} &amp; c_{y_2} &amp; c_{z_2} \\ c_{x_3} &amp; c_{y_3} &amp; c_{z_3} \end{bmatrix} =
\begin{bmatrix} râ‚â‚ &amp; râ‚â‚‚ &amp; râ‚â‚ƒ \\ râ‚‚â‚ &amp; râ‚‚â‚‚ &amp; râ‚‚â‚ƒ \\ râ‚ƒâ‚ &amp; râ‚ƒâ‚‚ &amp; râ‚ƒâ‚ƒ  \end{bmatrix}
\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1
\end{bmatrix}
$$</p>
</li>
<li>
<p>å› ä¸º rotation matrix çš„ç‰¹æ€§ï¼Œå®ƒçš„ä¸€è¡Œå°±æ˜¯ç›®æ ‡åæ ‡ç³»çš„ä¸€ä¸ªè½´åœ¨ æºç³»ä¸‹çš„åæ ‡ã€‚å®ƒçš„ä¸€åˆ—å°±æ˜¯æºç³»çš„ä¸€ä¸ªè½´åœ¨ç›®æ ‡ç³»ä¸‹çš„åæ ‡ã€‚</p>
</li>
<li>
<p>Each row in rotation matrix for w2c is an axis of target camera coordinate system. This can be verified by the example below:</p>

    
    
    
    
      
      
      
      
       
      
      
       
      
      <img src= /writenotes/vis/img/camSys_rot_w2c.png width=>
      
      
    

<p>Plotting script: <a class="link" href="https://gist.github.com/zichen34/4ba6e6afb724eb294dceee5f6306ea7d"  target="_blank" rel="noopener"
    >Test_rotation_matrix.ipynb</a></p>
</li>
</ul>
<p>åŒæ ·ï¼Œå¯¹äºçŸ©é˜µ c2wï¼Œå‰ 3 åˆ—çš„æ¯ <strong>ä¸€åˆ—</strong> æ˜¯ç›¸æœºåæ ‡ç³»çš„æ¯ä¸ª axis åœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹çš„åæ ‡ã€‚
æ‰€ä»¥è¦ <strong>è°ƒæ¢</strong> ç›¸æœºåæ ‡ç³»åœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹çš„æœå‘ï¼Œå¯¹ <strong>c2w</strong> çš„ rot çš„ <strong>æŸä¸€åˆ—</strong> ä¹˜ä¸Šä¸€ä¸ªè´Ÿå·å³å¯ã€‚</p>
<p>ç›¸æœºåæ ‡ç³»çš„å®šä¹‰å½±å“çš„æ˜¯ 3D ç‚¹åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„åæ ‡ï¼Œæ”¹å˜ç›¸æœºæœå‘ï¼Œæœ€ç»ˆä½“ç°åœ¨ 3D ç‚¹åœ¨ç›¸æœºç³»ä¸‹çš„åæ ‡çš„æ­£è´Ÿã€‚
å…·ä½“æ¥è¯´ï¼Œå¯¹äº <strong>w2c</strong> ä¸­çš„æ—‹è½¬çŸ©é˜µï¼Œè¦ <strong>è°ƒæ¢</strong> ç›¸æœºç³»çš„ä¸€ä¸ªè½´çš„æ–¹å‘ï¼Œåº”å¯¹ rotation matrix ä¸­å¯¹åº”çš„ <strong>ä¸€è¡Œ</strong> æ·»åŠ è´Ÿå·ã€‚</p>
<p>å› ä¸º NeRF ä½¿ç”¨çš„æ˜¯ c2wï¼Œå®ƒçš„æ—‹è½¬çŸ©é˜µçš„ <strong>æ¯ä¸€åˆ—</strong> æ˜¯ä¸€ä¸ªç›¸æœºç³»çš„è½´ï¼Œè€Œä¸”æ¬¡åºæ˜¯ <a class="link" href="https://github.com/fyusion/llff?tab=readme-ov-file#using-your-own-poses-without-running-colmap"  target="_blank" rel="noopener"
    >DRB</a>
æ‰€ä»¥ä»£ç ä¸­äº¤æ¢ç¬¬ 0 åˆ—(Down) å’Œç¬¬ 1 åˆ— (Right)ï¼Œç„¶åå¯¹ y æ–¹å‘ä¹˜ä¸Š -1 å˜æˆ Upã€‚æœ€ç»ˆå˜åˆ°äº† OpenGL çš„ RUBã€‚
<a class="link" href="https://github.com/bmild/nerf/blob/18b8aebda6700ed659cb27a0c348b737a5f6ab60/load_llff.py#L250"  target="_blank" rel="noopener"
    >Code</a></p>
</li>
</ul>
<p>(2024-03-24)</p>
<ul>
<li>
<p>&ldquo;The view matrix <strong>transforms</strong> all world coordinates to camera-space coordinates.&rdquo;
&ndash; <a class="link" href="https://learnopengl.com/Getting-started/Camera#:~:text=Camera%2FView%20space"  target="_blank" rel="noopener"
    >LearnOpenGL - Camera</a></p>
<p>Therefore, the view matrix (extrinsics) transforms the X,Y,Z axes of the world coordinates system
to X,Y,Z axes of the camera coordinates system.</p>
<p>Let the world X-Y-Z axes be the 3 unit column vectors, as shown in the below right matrix,
they&rsquo;re transformed to camera axes by a w2c:</p>
<p>$$
\begin{bmatrix} râ‚â‚ &amp; râ‚â‚‚ &amp; râ‚â‚ƒ &amp; tâ‚ \\ râ‚‚â‚ &amp; râ‚‚â‚‚ &amp; râ‚‚â‚ƒ &amp; tâ‚‚ \\ râ‚ƒâ‚ &amp; râ‚ƒâ‚‚ &amp; râ‚ƒâ‚ƒ &amp; tâ‚ƒ \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix}
\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 1 \end{bmatrix}
$$</p>
<ul>
<li>The extrinsics matrix transforms a world coordinates into camera-space coordinates.
Next, the point will be applied with the <a class="link" href="https://www.songho.ca/opengl/gl_projectionmatrix.html"  target="_blank" rel="noopener"
    >projection matrix</a>
(scaling axes to preserve points whose $z_{clip}$ is larger than its $x_{clip},\ y_{clip},\ z_{clip}$,
and performing intrinsics) for frustum clipping.
The projection matrix requires a 4D homogeneous coordinates: $[x_{cam},y_{cam},z_{cam},1]^T$.
So, the above extrinsic matrix has a <strong>4-th row</strong>, that results in an additional $1$,
which is reserved for storing the depth z value,
for the final perspective division.</li>
</ul>
<p>After multiplied with the extrinsics (w2c), the X,Y,Z axes of the world system are still 3 <strong>columns</strong>,
but values become their coordinates under the camera coordinate system.
And the 3 <strong>rows in the R of w2c</strong> are the camera coordinate system.</p>
<p>However, the camera coordinate system has many different matrix formats in different 3D applications.
For example, OpenGL (Blender) uses RUB order.</p>
<p>Usually, the world space is RUB as well. So, transforming world-space coordinates to OpenGL camera-space coordiantes doesn&rsquo;t need
to reverse axes.</p>
<figure><a href="https://zhuanlan.zhihu.com/p/593204605"><img src="https://pic1.zhimg.com/80/v2-ff5969172410c94a252b09cb8516a2f0_720w.webp"/></a>
  </figure>

<p>Whereas, OpenCV uses RDF camera coord. sys. Thus, the sign of y and z coordinates require flips in the camera space.</p>
</li>
</ul>
<ul>
<li>
<p>One of the differences between OpenCV and OpenGL is that in OpenGL, the z-axis has near and far boundary.
Refer to <a class="link" href="https://amytabb.com/tips/tutorials/2019/06/28/OpenCV-to-OpenGL-tutorial-essentials/"  target="_blank" rel="noopener"
    >Amy Tabb</a>.</p>
<p>That post was found with searching &ldquo;Converting camera poses from OpenCV to OpenGL can be easy&rdquo; (<a class="link" href="https://duckduckgo.com/?q=Converting&#43;camera&#43;poses&#43;from&#43;OpenCV&#43;to&#43;OpenGL&#43;can&#43;be&#43;easy&amp;ia=web"  target="_blank" rel="noopener"
    >DDG</a>),
that is a medium blog, which is found when searching &ldquo;camera coordinates right front up&rdquo; (<a class="link" href="https://duckduckgo.com/?q=camera&#43;coordinates&#43;right&#43;front&#43;up&amp;ia=web"  target="_blank" rel="noopener"
    >DDG</a>)</p>
</li>
</ul>
<p>(2024-03-25)</p>
<p>Example with a 3D point p:</p>



<div class="goat svg-container ">
  
    <svg
      xmlns="http://www.w3.org/2000/svg"
      font-family="Menlo,Lucida Console,monospace"
      
        viewBox="0 0 224 185"
      >
      <g transform='translate(8,16)'>
<path d='M 56,32 L 88,32' fill='none' stroke='currentColor'></path>
<path d='M 88,32 L 120,32' fill='none' stroke='currentColor'></path>
<path d='M 40,64 L 56,64' fill='none' stroke='currentColor'></path>
<path d='M 56,64 L 72,64' fill='none' stroke='currentColor'></path>
<path d='M 72,64 L 104,64' fill='none' stroke='currentColor'></path>
<path d='M 56,96 L 104,96' fill='none' stroke='currentColor'></path>
<path d='M 104,96 L 120,96' fill='none' stroke='currentColor'></path>
<path d='M 120,96 L 136,96' fill='none' stroke='currentColor'></path>
<path d='M 40,128 L 56,128' fill='none' stroke='currentColor'></path>
<path d='M 56,128 L 104,128' fill='none' stroke='currentColor'></path>
<path d='M 40,64 L 40,128' fill='none' stroke='currentColor'></path>
<path d='M 56,0 L 56,32' fill='none' stroke='currentColor'></path>
<path d='M 56,32 L 56,64' fill='none' stroke='currentColor'></path>
<path d='M 56,64 L 56,96' fill='none' stroke='currentColor'></path>
<path d='M 56,96 L 56,128' fill='none' stroke='currentColor'></path>
<path d='M 56,128 L 56,160' fill='none' stroke='currentColor'></path>
<path d='M 104,64 L 104,96' fill='none' stroke='currentColor'></path>
<path d='M 104,96 L 104,128' fill='none' stroke='currentColor'></path>
<path d='M 120,32 L 120,96' fill='none' stroke='currentColor'></path>
<path d='M 40,64 L 56,32' fill='none' stroke='currentColor'></path>
<path d='M 24,160 L 40,128' fill='none' stroke='currentColor'></path>
<path d='M 40,128 L 56,96' fill='none' stroke='currentColor'></path>
<path d='M 56,96 L 72,64' fill='none' stroke='currentColor'></path>
<path d='M 72,64 L 88,32' fill='none' stroke='currentColor'></path>
<path d='M 88,32 L 104,0' fill='none' stroke='currentColor'></path>
<path d='M 104,64 L 120,32' fill='none' stroke='currentColor'></path>
<path d='M 104,128 L 120,96' fill='none' stroke='currentColor'></path>
<polygon points='36.000000,160.000000 24.000000,154.399994 24.000000,165.600006' fill='currentColor' transform='rotate(120.000000, 24.000000, 160.000000)'></polygon>
<polygon points='64.000000,0.000000 52.000000,-5.600000 52.000000,5.600000' fill='currentColor' transform='rotate(270.000000, 56.000000, 0.000000)'></polygon>
<polygon points='64.000000,160.000000 52.000000,154.399994 52.000000,165.600006' fill='currentColor' transform='rotate(90.000000, 56.000000, 160.000000)'></polygon>
<polygon points='116.000000,0.000000 104.000000,-5.600000 104.000000,5.600000' fill='currentColor' transform='rotate(300.000000, 104.000000, 0.000000)'></polygon>
<polygon points='144.000000,96.000000 132.000000,90.400002 132.000000,101.599998' fill='currentColor' transform='rotate(0.000000, 136.000000, 96.000000)'></polygon>
<circle cx='104' cy='64' r='6' stroke='currentColor' fill='currentColor'></circle>
<text text-anchor='middle' x='8' y='164' fill='currentColor' style='font-size:1em'>Z</text>
<text text-anchor='middle' x='32' y='4' fill='currentColor' style='font-size:1em'>Y</text>
<text text-anchor='middle' x='64' y='116' fill='currentColor' style='font-size:1em'>O</text>
<text text-anchor='middle' x='72' y='164' fill='currentColor' style='font-size:1em'>D</text>
<text text-anchor='middle' x='80' y='164' fill='currentColor' style='font-size:1em'>o</text>
<text text-anchor='middle' x='88' y='164' fill='currentColor' style='font-size:1em'>w</text>
<text text-anchor='middle' x='96' y='164' fill='currentColor' style='font-size:1em'>n</text>
<text text-anchor='middle' x='104' y='52' fill='currentColor' style='font-size:1em'>p</text>
<text text-anchor='middle' x='120' y='4' fill='currentColor' style='font-size:1em'>F</text>
<text text-anchor='middle' x='128' y='4' fill='currentColor' style='font-size:1em'>o</text>
<text text-anchor='middle' x='136' y='4' fill='currentColor' style='font-size:1em'>r</text>
<text text-anchor='middle' x='144' y='4' fill='currentColor' style='font-size:1em'>w</text>
<text text-anchor='middle' x='152' y='4' fill='currentColor' style='font-size:1em'>a</text>
<text text-anchor='middle' x='152' y='100' fill='currentColor' style='font-size:1em'>X</text>
<text text-anchor='middle' x='160' y='4' fill='currentColor' style='font-size:1em'>r</text>
<text text-anchor='middle' x='160' y='100' fill='currentColor' style='font-size:1em'>,</text>
<text text-anchor='middle' x='168' y='4' fill='currentColor' style='font-size:1em'>d</text>
<text text-anchor='middle' x='176' y='100' fill='currentColor' style='font-size:1em'>R</text>
<text text-anchor='middle' x='184' y='100' fill='currentColor' style='font-size:1em'>i</text>
<text text-anchor='middle' x='192' y='100' fill='currentColor' style='font-size:1em'>g</text>
<text text-anchor='middle' x='200' y='100' fill='currentColor' style='font-size:1em'>h</text>
<text text-anchor='middle' x='208' y='100' fill='currentColor' style='font-size:1em'>t</text>
</g>

    </svg>
  
</div>
<ul>
<li>
<p>The above figure shows the <strong>right-hand</strong> world coordinate system (X-Y-Z) and a OpenCV camera coordinate system (Right-Down-Forward).</p>
<p>Those 2 coordinate systems have a common origin $O$. And the camera has no rotation.</p>
<p>The coordinates of a point p under the world space is $(2, 2, 1)$. However, the coordinates in the camera space is $(2, -2, -1)$.</p>
<p>This shows that when converting the world-space coordinate to OpenCV camera-space coordinates,
there is a &ldquo;sign matrix&rdquo;:</p>
<p>$$
\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; -1 \end{bmatrix}
\begin{bmatrix} 2 \\ 2 \\ 1 \end{bmatrix}
$$</p>
<p>When the camera shifts from the world origin by rotation and translation, i.e., the extrinsics matrix,
which transforms the <strong>axes of world</strong> system.
So, the result coordinates is measured in a <strong>transformed</strong> world coordinate system.</p>
<p>Thus, the &ldquo;sign matrix&rdquo; is required to convert the &ldquo;transformed world&rdquo; system to OpenCV (or other) camera coordinate system.</p>
<p>$$
\begin{bmatrix} x_{cam} \\ y_{cam} \\ z_{cam} \\ 1 \end{bmatrix} =
\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix}
\begin{bmatrix} râ‚â‚ &amp; râ‚â‚‚ &amp; râ‚â‚ƒ &amp; tâ‚ \\ râ‚‚â‚ &amp; râ‚‚â‚‚ &amp; râ‚‚â‚ƒ &amp; tâ‚‚ \\ râ‚ƒâ‚ &amp; râ‚ƒâ‚‚ &amp; râ‚ƒâ‚ƒ &amp; tâ‚ƒ \\ 0 &amp; 0 &amp; 0 &amp; 1  \end{bmatrix}
\begin{bmatrix} x_{world} \\ y_{world} \\ z_{world} \\ 1 \end{bmatrix}
$$</p>
<p>Therefore, the matrix transforming world coordinates to OpenCV camera coordiantes is:</p>
<p>$$
\begin{bmatrix} râ‚â‚ &amp; râ‚â‚‚ &amp; râ‚â‚ƒ &amp; tâ‚ \\ -râ‚‚â‚ &amp; -râ‚‚â‚‚ &amp; -râ‚‚â‚ƒ &amp; -tâ‚‚ \\ -râ‚ƒâ‚ &amp; -râ‚ƒâ‚‚ &amp; -râ‚ƒâ‚ƒ &amp; -tâ‚ƒ \\ 0 &amp; 0 &amp; 0 &amp; 1  \end{bmatrix}
$$</p>
</li>
</ul>
<ul>
<li>
<p>Since w2c transforms world axes to camera-space coordinates,
the coordinates performed by w2c must be a world coordinates of a point, instead of a camera coordinates.</p>
<p>So, the &ldquo;sign matrix&rdquo; must be applied after w2c. Otherwise, the world coordinate becomes a camera coordinate immediately,
which doesn&rsquo;t match w2c.
Specifically, the below order is <strong>incorrect</strong>:</p>
<p>$$
w2c
\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix}
\begin{bmatrix} x_{world} \\ y_{world} \\ z_{world} \\ 1 \end{bmatrix}
$$</p>
<p>In other words, the &ldquo;sign matrix&rdquo; should be applied on a camera-space coordinates.</p>
</li>
<li>
<p>In NeRF, the provided matrix is <strong>c2w</strong>, where each <strong>column</strong> of the rot is a camera axis, and the columns order is DRB.
So, the first 2 columns need to switch, thus, becoming RDB.
Then, to align the camera coordinate system of Blender: RUB,
the second <strong>row</strong> (the U axis) needs to be multiplied with -1.
<a class="link" href="https://github.com/bmild/nerf/blob/18b8aebda6700ed659cb27a0c348b737a5f6ab60/load_llff.py#L250"  target="_blank" rel="noopener"
    >Code</a></p>
<p>(2024-03-26)</p>
<ul>
<li>
<p>Note: the rotation matrix in <code>c2w</code> and <code>w2c</code> are different.
For the rot in <code>c2w</code>, each <strong>column</strong> is an axis of camera, so reversing the direction of a camera axis requires
multiplying <strong>a column</strong> with -1.</p>
<p>Whereas, for the rot in <code>w2c</code>, each <strong>row</strong> is an axis of a camera.
Thus, to reverse a camera axis, <strong>a row</strong> needs to be negated.</p>
</li>
</ul>
</li>
</ul>
<hr>
<p>(2024-03-26)</p>
<p>Test reversing a row and a column in a rotation matrix for w2c:</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th>Original Rot in w2c</th>
<th>Flip 0th row</th>
<th>Flip 0th column</th>
</tr>
</thead>
<tbody>
<tr>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/camSys_rot_orig.png width=>
  
  

</td>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/camSys_flip_row0.png width=>
  
  

</td>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/camSys_flip_col0.png width=>
  
  

</td>
</tr>
<tr>
<td>$$\begin{bmatrix} 0.970 &amp; 0.00747 &amp;  0.241 \\ -0.0147 &amp; 0.999 &amp; 0.028 \\ -0.241 &amp; -0.0309 &amp; 0.969 \end{bmatrix}$$</td>
<td>$$\begin{bmatrix} -0.970 &amp; -0.00747 &amp; -0.241 \\ -0.0147 &amp; 0.999 &amp; 0.0282 \\ -0.241 &amp; -0.0309 &amp; 0.969 \end{bmatrix}$$</td>
<td>$$\begin{bmatrix} -0.970 &amp; 0.00747 &amp; 0.241 \\ 0.0147 &amp; 0.999 &amp; 0.0282 \\ 0.241 &amp; -0.0309 &amp; 0.969 \end{bmatrix}$$</td>
</tr>
<tr>
<td>$p_{cam}=[2.18994, 0.99823, 0.45571]$</td>
<td>$p_{cam}=[-2.18994,  0.99823,  0.45571]$</td>
<td>$p_{cam}=[-1.69110,  1.05720,  1.42213]$</td>
</tr>
</tbody>
</table></div>
<ul>
<li>
<p>A row of the rotation matrix in w2c is the coordinates of a camera axis in the world space.</p>
</li>
<li>
<p>A column is the coordinates of a world axis in the camera space.</p>
</li>
</ul>
<ol>
<li>
<p>The original rotation matrix transforms the world axes to a tilted coordinate system.</p>
</li>
<li>
<p>Flip the 0th row of the rotation matrix: only the X axis entirely turns to the oppsite direction.</p>
</li>
<li>
<p>Flip the 0th row of the rotation matrix: the x component of <strong>all</strong> the X-Y-Z axes are affected.
Apparently, this is not desired result.
When flipping a single axis, the other axes should be unchanged.</p>
</li>
</ol>
<p>Figure plotting script: <a class="link" href="https://gist.github.com/zichen34/4a1f0b08aa7a3e76a2d6a84147b38168"  target="_blank" rel="noopener"
    >Test_reverse_cam_axis.ipynb</a></p>
<hr>
<h2 id="identify-cam-axes">Identify Cam Axes</h2>
<p>åªæœ‰æ—‹è½¬çŸ©é˜µ Rï¼Œä½†ä¸çŸ¥é“ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„æœå‘ï¼ˆä¹Ÿä¸çŸ¥é“å„è½´çš„æ¬¡åºï¼‰ã€‚</p>
<ul>
<li>@will åœ¨ 23-11-10 8:25 AM è¯´ï¼šç”»å‡ºæ¥çœ‹çœ‹æ­£ä¸æ­£å¯¹åœºæ™¯ã€‚</li>
<li>@ä»€ä¹ˆåŠ åœ¨ 22-11-21 8:50 PM å±•ç¤ºè¿‡ä»–ç”¨ plt ç”»çš„ç›¸æœºä½å§¿ã€‚</li>
</ul>
<p>(2024-03-27)</p>
<ul>
<li>
<p>The pose1 does not face towards the object (MVSNet_testing/dtu/scan1/cams/00000000_cam.txt):</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th>R for w2c</th>
<th>rect_001_0 (full)</th>
<th>mod signs</th>
</tr>
</thead>
<tbody>
<tr>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/dtu_pose1.jpg width=>
  
  

</td>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/dtu_test_rect_001_0_r5000.jpg width=>
  
  

</td>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/dtu_pose1_mod.jpg width=>
  
  

</td>
</tr>
</tbody>
</table></div>
<ul>
<li>
<p>I have dragged the figure to make the z axis upside down.
The camera position is $[-191.02, 3.28832, 22.5401 ]$
And I feel the pose should be $[3, 191, 22]$</p>
<p>(2024-03-30) Camera position was wrong, but it&rsquo;s not due to signs. The 4-th column in w2c is not the camera position in world.</p>
</li>
<li>
<p>Dragging z-axis to upside down is equivalent to negating the z coordinate and switching the x and y of points coordinates.
Specifically, given a point (x,y,z), dragging z to flip equals:
<code>x=y; y=x; z=-z</code></p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th>Drag manually</th>
<th>Flip z and switch x,y</th>
</tr>
</thead>
<tbody>
<tr>
<td>
    
    
    
    
      
      
      
      
       
      
      
       
      
      <img src= /writenotes/vis/img/dtu_drag_z_scan23.jpg width=>
      
      
    
</td>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/dtu_flip_z.jpg width=>
  
  

</td>
</tr>
</tbody>
</table></div>
<details> <summary>Code for modifying axes for scan23</summary>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="o">%</span><span class="n">matplotlib</span> <span class="n">widget</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">open3d</span> <span class="k">as</span> <span class="nn">o3d</span>
</span></span><span class="line"><span class="cl"><span class="n">pcd</span> <span class="o">=</span> <span class="n">o3d</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_point_cloud</span><span class="p">(</span><span class="s2">&#34;/mnt/data2_z/SampleSet/MVS Data/Points/stl/stl023_total.ply&#34;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;ply&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">pcd</span><span class="o">.</span><span class="n">points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">samples</span> <span class="o">=</span> <span class="n">vs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">vs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1000</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">z</span> <span class="o">=</span> <span class="o">-</span><span class="n">samples</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div></details>
</li>
</ul>
</li>
</ul>
<hr>
<p>(204-03-28)</p>
<ul>
<li>I know DTU matches the setup of OpenCV because the function <code>cv2.decomposeProjectionMatrix</code> is used.
But, I&rsquo;m still confused about the scene visualization with matplotlib.</li>
</ul>
<hr>
<p>(2024-03-30)</p>
<ul>
<li>
<p>The 4-th column of the w2c is <strong>not</strong> the camera center position in world space!!
The camera position in world should be the 4-th column of c2w,
i.e., $-R_{w2c}^T t_{w2c}$.</p>
<p>And the <code>t</code> returned by <code>decomposeProjectionMatrix</code> is the camera position as well.</p>
</li>
<li>
<p>After correcting the camera center position, the camera geometry is correct:</p>

  
  
  
  
    
    
    
    
     
    
    
     
    
    <img src= /writenotes/vis/img/dtu_cam_geo.jpg width=50%>
    
    
  

<p>Plotting script: <a class="link" href="https://gist.github.com/zichen34/9304e656396efe24455872345a2e6b88"  target="_blank" rel="noopener"
    >gist</a></p>
</li>
<li>
<p>Identifying the axes directions should be independent of camera geometry.</p>
<p>Only drawing one camera may not easily indicate if it&rsquo;s facing the scene.</p>
</li>
</ul>
<hr>
<p>(2024-03-31)</p>
<ul>
<li>
<p>Open3D can set the window (visualizer) to be the specified camera pose.</p>
<ol>
<li>
<p>Change <code>set_front</code> to different row in the rotation mat:</p>
<details><summary> Code </summary>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">w2c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.970263</span><span class="p">,</span> <span class="mf">0.00747983</span><span class="p">,</span> <span class="mf">0.241939</span><span class="p">,</span> <span class="o">-</span><span class="mf">191.02</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="o">-</span><span class="mf">0.0147429</span><span class="p">,</span> <span class="mf">0.999493</span><span class="p">,</span> <span class="mf">0.0282234</span><span class="p">,</span> <span class="mf">3.28832</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="o">-</span><span class="mf">0.241605</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.030951</span><span class="p">,</span> <span class="mf">0.969881</span><span class="p">,</span> <span class="mf">22.5401</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span> <span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">pcd</span> <span class="o">=</span> <span class="n">o3d</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_point_cloud</span><span class="p">(</span><span class="s2">&#34;/home/yi/Downloads/DTU_SampleSet/MVS Data/Points/stl/stl001_total.ply&#34;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;ply&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span> <span class="o">=</span> <span class="n">o3d</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">VisualizerWithKeyCallback</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">create_window</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">get_render_option</span><span class="p">()</span><span class="o">.</span><span class="n">background_color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">view_ctl</span> <span class="o">=</span> <span class="n">vis</span><span class="o">.</span><span class="n">get_view_control</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">add_geometry</span><span class="p">(</span><span class="n">pcd</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">view_ctl</span><span class="o">.</span><span class="n">set_front</span><span class="p">(</span><span class="n">w2c</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">destroy_window</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div></details>
<div class="table-wrapper"><table>
<thead>
<tr>
<th>set_front(w2c[2][:3])</th>
<th>set_front(w2c[0][:3])</th>
</tr>
</thead>
<tbody>
<tr>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/open3d_front_row2.jpg width=>
  
  

</td>
<td>




  
  
  
  
   
  
  
   
  
  <img src= /writenotes/vis/img/open3d_front_row0.jpg width=>
  
  

</td>
</tr>
</tbody>
</table></div>
</li>
<li>
<p>Set the extrinsic to simulate a camera pose:
<a class="link" href="https://github.com/isl-org/Open3D/issues/2338"  target="_blank" rel="noopener"
    >Determining the Proper Camera Position #2338</a></p>
<details><summary> Code </summary>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">open3d</span> <span class="k">as</span> <span class="nn">o3d</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pcd</span> <span class="o">=</span> <span class="n">o3d</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_point_cloud</span><span class="p">(</span><span class="s2">&#34;/home/yi/Downloads/DTU_SampleSet/MVS Data/Points/stl/stl001_total.ply&#34;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;ply&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span> <span class="o">=</span> <span class="n">o3d</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">VisualizerWithKeyCallback</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">create_window</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">get_render_option</span><span class="p">()</span><span class="o">.</span><span class="n">background_color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">add_geometry</span><span class="p">(</span><span class="n">pcd</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">view_ctl</span> <span class="o">=</span> <span class="n">vis</span><span class="o">.</span><span class="n">get_view_control</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">w2c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.970263</span><span class="p">,</span> <span class="mf">0.00747983</span><span class="p">,</span> <span class="mf">0.241939</span><span class="p">,</span> <span class="o">-</span><span class="mf">191.02</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="o">-</span><span class="mf">0.0147429</span><span class="p">,</span> <span class="mf">0.999493</span><span class="p">,</span> <span class="mf">0.0282234</span><span class="p">,</span> <span class="mf">3.28832</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="o">-</span><span class="mf">0.241605</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.030951</span><span class="p">,</span> <span class="mf">0.969881</span><span class="p">,</span> <span class="mf">22.5401</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span> <span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">cam</span> <span class="o">=</span> <span class="n">view_ctl</span><span class="o">.</span><span class="n">convert_to_pinhole_camera_parameters</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">cam</span><span class="o">.</span><span class="n">extrinsic</span> <span class="o">=</span> <span class="n">w2c</span>
</span></span><span class="line"><span class="cl"><span class="n">view_ctl</span><span class="o">.</span><span class="n">convert_from_pinhole_camera_parameters</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">current_param</span> <span class="o">=</span> <span class="n">view_ctl</span><span class="o">.</span><span class="n">convert_to_pinhole_camera_parameters</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">current_param</span><span class="o">.</span><span class="n">extrinsic</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">destroy_window</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div></details>

     
     
     
     
       
       
       
       
        
       
       
        
       
       <img src= /writenotes/vis/img/open3d_pose1.jpg width=50%>
       
       
     

<ul>
<li>
<p>The argument <code>allow_arbitrary=True</code> is required (using 0.18.0),
reminded by: <a class="link" href="https://github.com/isl-org/Open3D/issues/1483#issuecomment-1873081439"  target="_blank" rel="noopener"
    >How to you position camera and look at certain location in Open3D? #1483</a></p>
<p>This argument is added to free the limitation on pinhole camera models.
<a class="link" href="https://github.com/isl-org/Open3D/issues/834"  target="_blank" rel="noopener"
    >ConvertFromPinholeCameraParameters() failed #834</a></p>
</li>
</ul>
<p>Similar issues:</p>
<ul>
<li>
<p><a class="link" href="https://github.com/isl-org/Open3D/issues/1343"  target="_blank" rel="noopener"
    >convert_from_pinhole_camera_parameters does not work #1343</a></p>
</li>
<li>
<p><a class="link" href="https://github.com/isl-org/Open3D/issues/5816"  target="_blank" rel="noopener"
    >convert_from_pinhole_camera_parameters allow_arbitrary=True modifies intrinsic matrix #5816</a></p>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<ul>
<li>
<p>&ldquo;view matrix&rdquo; means w2c. While &ldquo;world transformation matrix&rdquo; is c2w.
<a class="link" href="https://www.3dgep.com/understanding-the-view-matrix/#transformations"  target="_blank" rel="noopener"
    >3D GEP</a></p>
<ul>
<li>
<p>Each column in c2w is a camera axis coordinates in world space.
So, 3 columns represent directions, such as RDF, and the 4-th colmun is the camera center in world space.</p>
</li>
<li>
<p>He gave a code demo to show the matrix format in column-major memory accessing.</p>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="opencv2opengl">OpenCV2OpenGL</h2>
<p>(2024-03-29)</p>
<ul>
<li>
<p>Just negate the 2nd and 3rd <strong>rows</strong> in the rotation matrix that transforms word coords to cam coords.
Such that, RDF camera system becomes RUB.
(And note OpenGL reads matrix by columns.)
<a class="link" href="https://stackoverflow.com/a/59305821/18003182"  target="_blank" rel="noopener"
    >OpenCV to OpenGL coordinate system transform - SO</a></p>
<img src="https://i.ibb.co/2g5vdNr/coordinates.png">
<p>This process can be done with a &ldquo;sign matrix&rdquo;:
$[[1,0,0,0],\ [0,-1,0,0],\ [0,0,-1,0],\ [0,0,0,1]]$.</p>
<ul>
<li>
<p>This &ldquo;sign matrix&rdquo; also appears in <a class="link" href="https://github.com/sxyu/pixel-nerf/issues/23"  target="_blank" rel="noopener"
    >PixelNeRF</a> to process DTU.
Yu called it as &ldquo;similarity transform&rdquo;. (<a class="link" href="https://github.com/sxyu/pixel-nerf/issues/2"  target="_blank" rel="noopener"
    >issue#2</a>)</p>
</li>
<li>
<p>Same as the function <code>T_opencv_to_opengl()</code> in <a class="link" href="https://github.com/yxlao/camtools/blob/5bf6199482577c5efcaa6064f5afcfe2f3f3fd55/camtools/convert.py#L215"  target="_blank" rel="noopener"
    >camtools</a></p>
</li>
</ul>
</li>
</ul>
<hr>
<p>(2024-04-02)</p>
<ul>
<li>
<p>Mapping a coordinate system to another has <strong>two transformations</strong>: rotation+translation [R|t] and sign matrix. <br>
<a class="link" href="https://readmedium.com/p/27ff6c413bdb"  target="_blank" rel="noopener"
    >Converting camera poses from OpenCV to OpenGL can be easy - readmedium</a>
(Found when searching &ldquo;opencv to opengl transformation&rdquo; <a class="link" href="https://duckduckgo.com/?q=opencv&#43;to&#43;opengl&#43;transformation&amp;ia=web"  target="_blank" rel="noopener"
    >DDG</a>)</p>
<p>Specifically, change the source basis first, and then flip axes of the source basis (world) to target basis (camera).</p>



<div class="goat svg-container ">
  
    <svg
      xmlns="http://www.w3.org/2000/svg"
      font-family="Menlo,Lucida Console,monospace"
      
        viewBox="0 0 400 121"
      >
      <g transform='translate(8,16)'>
<path d='M 32,48 L 64,48' fill='none' stroke='currentColor'></path>
<path d='M 104,48 L 120,48' fill='none' stroke='currentColor'></path>
<path d='M 168,48 L 200,48' fill='none' stroke='currentColor'></path>
<path d='M 256,48 L 272,48' fill='none' stroke='currentColor'></path>
<path d='M 328,48 L 360,48' fill='none' stroke='currentColor'></path>
<path d='M 32,16 L 32,48' fill='none' stroke='currentColor'></path>
<path d='M 16,80 L 32,48' fill='none' stroke='currentColor'></path>
<path d='M 200,48 L 216,16' fill='none' stroke='currentColor'></path>
<path d='M 328,48 L 344,16' fill='none' stroke='currentColor'></path>
<path d='M 200,48 L 216,80' fill='none' stroke='currentColor'></path>
<path d='M 312,16 L 328,48' fill='none' stroke='currentColor'></path>
<polygon points='28.000000,80.000000 16.000000,74.400002 16.000000,85.599998' fill='currentColor' transform='rotate(120.000000, 16.000000, 80.000000)'></polygon>
<polygon points='40.000000,16.000000 28.000000,10.400000 28.000000,21.600000' fill='currentColor' transform='rotate(270.000000, 32.000000, 16.000000)'></polygon>
<polygon points='72.000000,48.000000 60.000000,42.400002 60.000000,53.599998' fill='currentColor' transform='rotate(0.000000, 64.000000, 48.000000)'></polygon>
<polygon points='128.000000,48.000000 116.000000,42.400002 116.000000,53.599998' fill='currentColor' transform='rotate(0.000000, 120.000000, 48.000000)'></polygon>
<polygon points='176.000000,48.000000 164.000000,42.400002 164.000000,53.599998' fill='currentColor' transform='rotate(180.000000, 168.000000, 48.000000)'></polygon>
<polygon points='228.000000,16.000000 216.000000,10.400000 216.000000,21.600000' fill='currentColor' transform='rotate(300.000000, 216.000000, 16.000000)'></polygon>
<polygon points='228.000000,80.000000 216.000000,74.400002 216.000000,85.599998' fill='currentColor' transform='rotate(60.000000, 216.000000, 80.000000)'></polygon>
<polygon points='280.000000,48.000000 268.000000,42.400002 268.000000,53.599998' fill='currentColor' transform='rotate(0.000000, 272.000000, 48.000000)'></polygon>
<polygon points='324.000000,16.000000 312.000000,10.400000 312.000000,21.600000' fill='currentColor' transform='rotate(240.000000, 312.000000, 16.000000)'></polygon>
<polygon points='356.000000,16.000000 344.000000,10.400000 344.000000,21.600000' fill='currentColor' transform='rotate(300.000000, 344.000000, 16.000000)'></polygon>
<polygon points='368.000000,48.000000 356.000000,42.400002 356.000000,53.599998' fill='currentColor' transform='rotate(0.000000, 360.000000, 48.000000)'></polygon>
<text text-anchor='middle' x='0' y='84' fill='currentColor' style='font-size:1em'>z</text>
<text text-anchor='middle' x='16' y='20' fill='currentColor' style='font-size:1em'>y</text>
<text text-anchor='middle' x='16' y='100' fill='currentColor' style='font-size:1em'>W</text>
<text text-anchor='middle' x='24' y='100' fill='currentColor' style='font-size:1em'>o</text>
<text text-anchor='middle' x='32' y='100' fill='currentColor' style='font-size:1em'>r</text>
<text text-anchor='middle' x='40' y='100' fill='currentColor' style='font-size:1em'>l</text>
<text text-anchor='middle' x='48' y='100' fill='currentColor' style='font-size:1em'>d</text>
<text text-anchor='middle' x='80' y='52' fill='currentColor' style='font-size:1em'>x</text>
<text text-anchor='middle' x='104' y='36' fill='currentColor' style='font-size:1em'>R</text>
<text text-anchor='middle' x='112' y='36' fill='currentColor' style='font-size:1em'>|</text>
<text text-anchor='middle' x='120' y='36' fill='currentColor' style='font-size:1em'>t</text>
<text text-anchor='middle' x='144' y='100' fill='currentColor' style='font-size:1em'>R</text>
<text text-anchor='middle' x='152' y='52' fill='currentColor' style='font-size:1em'>y</text>
<text text-anchor='middle' x='152' y='100' fill='currentColor' style='font-size:1em'>o</text>
<text text-anchor='middle' x='160' y='100' fill='currentColor' style='font-size:1em'>t</text>
<text text-anchor='middle' x='168' y='100' fill='currentColor' style='font-size:1em'>a</text>
<text text-anchor='middle' x='176' y='100' fill='currentColor' style='font-size:1em'>t</text>
<text text-anchor='middle' x='184' y='100' fill='currentColor' style='font-size:1em'>e</text>
<text text-anchor='middle' x='192' y='100' fill='currentColor' style='font-size:1em'>d</text>
<text text-anchor='middle' x='200' y='84' fill='currentColor' style='font-size:1em'>z</text>
<text text-anchor='middle' x='208' y='100' fill='currentColor' style='font-size:1em'>w</text>
<text text-anchor='middle' x='216' y='100' fill='currentColor' style='font-size:1em'>o</text>
<text text-anchor='middle' x='224' y='4' fill='currentColor' style='font-size:1em'>x</text>
<text text-anchor='middle' x='224' y='100' fill='currentColor' style='font-size:1em'>r</text>
<text text-anchor='middle' x='232' y='100' fill='currentColor' style='font-size:1em'>l</text>
<text text-anchor='middle' x='240' y='100' fill='currentColor' style='font-size:1em'>d</text>
<text text-anchor='middle' x='256' y='20' fill='currentColor' style='font-size:1em'>f</text>
<text text-anchor='middle' x='256' y='36' fill='currentColor' style='font-size:1em'>s</text>
<text text-anchor='middle' x='264' y='20' fill='currentColor' style='font-size:1em'>l</text>
<text text-anchor='middle' x='264' y='36' fill='currentColor' style='font-size:1em'>i</text>
<text text-anchor='middle' x='272' y='20' fill='currentColor' style='font-size:1em'>i</text>
<text text-anchor='middle' x='272' y='36' fill='currentColor' style='font-size:1em'>g</text>
<text text-anchor='middle' x='280' y='20' fill='currentColor' style='font-size:1em'>p</text>
<text text-anchor='middle' x='280' y='36' fill='currentColor' style='font-size:1em'>n</text>
<text text-anchor='middle' x='304' y='4' fill='currentColor' style='font-size:1em'>z</text>
<text text-anchor='middle' x='312' y='4' fill='currentColor' style='font-size:1em'>á¶œ</text>
<text text-anchor='middle' x='312' y='100' fill='currentColor' style='font-size:1em'>C</text>
<text text-anchor='middle' x='320' y='100' fill='currentColor' style='font-size:1em'>a</text>
<text text-anchor='middle' x='328' y='100' fill='currentColor' style='font-size:1em'>m</text>
<text text-anchor='middle' x='336' y='100' fill='currentColor' style='font-size:1em'>e</text>
<text text-anchor='middle' x='344' y='100' fill='currentColor' style='font-size:1em'>r</text>
<text text-anchor='middle' x='352' y='4' fill='currentColor' style='font-size:1em'>x</text>
<text text-anchor='middle' x='352' y='100' fill='currentColor' style='font-size:1em'>a</text>
<text text-anchor='middle' x='360' y='4' fill='currentColor' style='font-size:1em'>á¶œ</text>
<text text-anchor='middle' x='376' y='52' fill='currentColor' style='font-size:1em'>y</text>
<text text-anchor='middle' x='384' y='52' fill='currentColor' style='font-size:1em'>á¶œ</text>
</g>

    </svg>
  
</div>
<ul>
<li>
<p>I realized that the terminologies: w2c and c2w are siutable for the transition between world and the <strong>OpenGL</strong> camera coordinate syste,
beacuse their axes are aligned, i.e., both RUB.</p>
<p>Otherwise, for example, between world and <strong>OpenCV</strong> camera system,
the world system is not directly becoming the target camera system after rotation and translation [R|t].</p>
</li>
<li>
<p>That post also takes the column-major memory access into account.</p>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="dtu-dataset">DTU dataset</h2>
<h3 id="original">Original</h3>
<p>(2024-02-21)</p>
<p><a class="link" href="https://roboimagedata.compute.dtu.dk/?page_id=36"  target="_blank" rel="noopener"
    >DTU Homepage</a>
Each object scan is taken from 49 fixed camera positions.</p>
<p>For the SampleSet, the images dimensions are 1600x1200:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">yi@yi:~/Downloads/DTU_SampleSet$ identify MVS<span class="se">\ </span>Data/Rectified/scan1/rect_001_0_r5000.png
</span></span><span class="line"><span class="cl">MVS Data/Rectified/scan1/rect_001_0_r5000.png PNG 1600x1200 1600x1200+0+0 8-bit sRGB 2.85068MiB 0.000u 0:00.000
</span></span></code></pre></td></tr></table>
</div>
</div><p>The camera projection matrix ğâ‚ƒâ‚“â‚„ from world to image, i.e. K@[R|t]
(<a class="link" href="https://github.com/kwea123/CasMVSNet_pl/blob/a09e5ba230a18be54b9f6b1d714c3dc58acd8a00/datasets/dtu.py#L70"  target="_blank" rel="noopener"
    >Casmvsnet</a>
and <a class="link" href="https://stackoverflow.com/a/69556782/18003182"  target="_blank" rel="noopener"
    >SO</a>):</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">yi@yi:~/Downloads/DTU_SampleSet$ cat MVS<span class="se">\ </span>Data/Calibration/cal18/pos_001.txt
</span></span><span class="line"><span class="cl">2607.429996 -3.844898 1498.178098 -533936.661373
</span></span><span class="line"><span class="cl">-192.076910 2862.552532 681.798177 23434.686572
</span></span><span class="line"><span class="cl">-0.241605 -0.030951 0.969881 22.540121
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>(2024-03-27) The P is estimated by Matlab, and Matlab regards camera coordinates system as RDF (mentioned in
<a class="link" href="https://www.mathworks.com/matlabcentral/answers/251315-multi-cameras-on-same-coordinate-system#comment_323427"  target="_blank" rel="noopener"
    >Multi-cameras on same coordinate system - Dima</a> found by Perplexity),
which is the same as OpenCV <a class="link" href="https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#:~:text=pinhole%20camera%20model.-,Pinhole%20camera%20model,-Real%20lenses%20usually"  target="_blank" rel="noopener"
    >camera model</a>.</p>
<img src="https://docs.opencv.org/3.4/pinhole_camera_model.png" width="65%">
</li>
</ul>
<p>The P can be decomposed to K,R,t by <a class="link" href="https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#:~:text=%E2%97%86%C2%A0decomposeProjectionMatrix%28%29"  target="_blank" rel="noopener"
    >decomposeProjectionMatrix()</a>: <a id="exp"></a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">P_orig</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">       <span class="p">[[</span><span class="mf">2607.429996</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.844898</span><span class="p">,</span> <span class="mf">1498.178098</span><span class="p">,</span> <span class="o">-</span><span class="mf">533936.661373</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="o">-</span><span class="mf">192.076910</span><span class="p">,</span> <span class="mf">2862.552532</span><span class="p">,</span> <span class="mf">681.798177</span><span class="p">,</span> <span class="mf">23434.686572</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="o">-</span><span class="mf">0.241605</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.030951</span><span class="p">,</span> <span class="mf">0.969881</span><span class="p">,</span> <span class="mf">22.540121</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">K</span><span class="p">,</span><span class="n">R</span><span class="p">,</span><span class="n">t</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">decomposeProjectionMatrix</span><span class="p">(</span><span class="n">P_orig</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The original intrinsic matrix K (performed <a class="link" href="https://github.com/sxyu/pixel-nerf/blob/91a044bdd62aebe0ed3a5685ca37cb8a9dc8e8ee/src/data/DVRDataset.py#L164"  target="_blank" rel="noopener"
    ><code>K/K[2][2]</code></a>) is:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">array<span class="o">([[</span> 2.89233051e+03, -2.48063349e-04,  8.23205273e+02<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span> 0.00000000e+00,  2.88317528e+03,  6.19070918e+02<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span> 0.00000000e+00,  0.00000000e+00,  1.00000000e+00<span class="o">]])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>It&rsquo;s aligned with the intrinsics in mvs_training (not the cams in <code>train/</code> folder):</p>
<details> <summary>mvs_training/dtu/Cameras/00000000_cam.txt</summary>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">z@homepc:~/Downloads/Datasets_life/mvs_training/dtu/Cameras$ cat 00000000_cam.txt
</span></span><span class="line"><span class="cl">extrinsic
</span></span><span class="line"><span class="cl">0.970263 0.00747983 0.241939 -191.02
</span></span><span class="line"><span class="cl">-0.0147429 0.999493 0.0282234 3.28832
</span></span><span class="line"><span class="cl">-0.241605 -0.030951 0.969881 22.5401
</span></span><span class="line"><span class="cl">0.0 0.0 0.0 1.0
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">intrinsic
</span></span><span class="line"><span class="cl">2892.33 <span class="m">0</span> 823.205
</span></span><span class="line"><span class="cl"><span class="m">0</span> 2883.18 619.071
</span></span><span class="line"><span class="cl"><span class="m">0</span> <span class="m">0</span> <span class="m">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="m">425</span> 2.5
</span></span></code></pre></td></tr></table>
</div>
</div></details>
</li>
</ul>
<p>The table lists focal length and image resolution correspondence:</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th>Scale</th>
<th>resolusion</th>
<th>cropped</th>
<th>f_x</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1200x1600</td>
<td></td>
<td>2892.3</td>
</tr>
<tr>
<td>1/2</td>
<td>600x800</td>
<td>512x640</td>
<td>1446.1</td>
</tr>
<tr>
<td>1/4</td>
<td>300x400</td>
<td></td>
<td>723.08</td>
</tr>
<tr>
<td>1/8</td>
<td>150x200</td>
<td></td>
<td>361.5</td>
</tr>
</tbody>
</table></div>
<p>(2024-03-27)</p>
<ul>
<li>
<p>In Dima&rsquo;s answer, he described RDF as the world space.
That means the extrinsics has been applied by the &ldquo;sign matrix&rdquo;, which changes the world axes to camera axes.
So, the R decomposed from P essentially corresponds to the RDF coordinates system.</p>
<p>In other words, the camera coordinate system is used as the world coord. sys.</p>
<p>Whereas, the world system during visualization is usually RUB (Y-axis is Up), like OpenGL.
So, the object is upside down when plotting the point cloud with matplotlib.</p>
<p>And the ccs in Open3D also is RDF (relative to world space RUB),
so its initial w2c has reverse the y-axis and z-axis of the world space:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="o">[[</span> 1.  0.  0. -0.<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>-0. -1. -0.  0.<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>-0. -0. -1.  0.<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span> 0.  0.  0.  1.<span class="o">]]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><details><summary> Code: Print current cam pose </summary>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">open3d</span> <span class="k">as</span> <span class="nn">o3d</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span> <span class="o">=</span> <span class="n">o3d</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">VisualizerWithKeyCallback</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">create_window</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">view_ctl</span> <span class="o">=</span> <span class="n">vis</span><span class="o">.</span><span class="n">get_view_control</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">current_param</span> <span class="o">=</span> <span class="n">view_ctl</span><span class="o">.</span><span class="n">convert_to_pinhole_camera_parameters</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">current_param</span><span class="o">.</span><span class="n">extrinsic</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vis</span><span class="o">.</span><span class="n">destroy_window</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div></details>
</li>
</ul>
<hr>
<h3 id="mvsnet">MVSNet</h3>
<p>(2024-02-22)</p>
<ul>
<li>
<p><strong>Training</strong> set: <a class="link" href="https://github.com/YoYo000/MVSNet?tab=readme-ov-file#download"  target="_blank" rel="noopener"
    >dtu_training.rar (19G)</a>
(&ldquo;mvs_training/dtu/&rdquo;)</p>
<p>As mentioned in the section 4.1 of the <a class="link" href="https://arxiv.org/abs/1804.02505"  target="_blank" rel="noopener"
    >MVSNet paper</a>,
the training images are 1/2 * (1200,1600) = (600,800), which then cropped to (512,640).</p>
<p>In addition, because the camera is looking at <strong>feature maps</strong>, the focal lengths should be scaled
with the ratio of the size of feature map to the input image size.</p>
<p>As feature map size (128,160) is 1/4 input image (512,640) mentioned in paper section 3.1,
the focal_x should be: 2892.33 * 1/2 * 1/4 = 361.541.
<a class="link" href="https://github.com/YoYo000/MVSNet/issues/3"  target="_blank" rel="noopener"
    >Issue</a></p>
<p><strong>Note</strong>: The already calculated trianing camera params are placed in &ldquo;mvs_training/dtu/Cameras/train&rdquo;.
<a class="link" href="https://github.com/YoYo000/MVSNet/blob/3ae2cb2b72c6df58ebcb321d7d243d4efd01fbc5/mvsnet/preprocess.py#L266"  target="_blank" rel="noopener"
    >Code</a>
While the cameras displayed outside the &ldquo;train/&rdquo; are params corresponding to the original DTU images (1200,1600).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">z@lambda:~/Downloads/mvs_training/dtu$ identify Rectified/scan1_train/rect_001_0_r5000.png 
</span></span><span class="line"><span class="cl">Rectified/scan1_train/rect_001_0_r5000.png PNG 640x512 640x512+0+0 8-bit sRGB 626KB 0.000u 0:00.000
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">z@lambda:~/Downloads/mvs_training/dtu$ cat Cameras/train/00000000_cam.txt 
</span></span><span class="line"><span class="cl">extrinsic
</span></span><span class="line"><span class="cl">0.970263 0.00747983 0.241939 -191.02 
</span></span><span class="line"><span class="cl">-0.0147429 0.999493 0.0282234 3.28832 
</span></span><span class="line"><span class="cl">-0.241605 -0.030951 0.969881 22.5401 
</span></span><span class="line"><span class="cl">0.0 0.0 0.0 1.0 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">intrinsic
</span></span><span class="line"><span class="cl">361.54125 0.0 82.900625 
</span></span><span class="line"><span class="cl">0.0 360.3975 66.383875 
</span></span><span class="line"><span class="cl">0.0 0.0 1.0 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">425.0 2.5
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><strong>Testing</strong> set (dtu.zip) has the full-size images:</p>
<p>Testing images are&rsquo;t downsized twice or cropped, so the focal lengths <strong>only times 1/4</strong>.
<a class="link" href="https://github.com/YoYo000/MVSNet/blob/3ae2cb2b72c6df58ebcb321d7d243d4efd01fbc5/mvsnet/test.py#L135"  target="_blank" rel="noopener"
    >Code</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">z@lambda:~/Downloads/data2/MVSNet_testing/dtu$ identify scan1/images/00000000.jpg 
</span></span><span class="line"><span class="cl">scan1/images/00000000.jpg JPEG 1600x1200 1600x1200+0+0 8-bit sRGB 705KB 0.000u 0:00.000
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">z@lambda:~/Downloads/data2/MVSNet_testing/dtu$ cat scan1/cams/00000000_cam.txt 
</span></span><span class="line"><span class="cl">extrinsic
</span></span><span class="line"><span class="cl">0.970263 0.00747983 0.241939 -191.02
</span></span><span class="line"><span class="cl">-0.0147429 0.999493 0.0282234 3.28832
</span></span><span class="line"><span class="cl">-0.241605 -0.030951 0.969881 22.5401
</span></span><span class="line"><span class="cl">0.0 0.0 0.0 1.0
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">intrinsic
</span></span><span class="line"><span class="cl">2892.33 <span class="m">0</span> 823.205
</span></span><span class="line"><span class="cl"><span class="m">0</span> 2883.18 619.071
</span></span><span class="line"><span class="cl"><span class="m">0</span> <span class="m">0</span> <span class="m">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="m">425</span> 2.5
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>The factor <code>adaptive_scaling</code> is used for the requirement that image size must be evenly divisible by 32 (e.g., <a class="link" href="https://github.com/YoYo000/MVSNet?tab=readme-ov-file#testing"  target="_blank" rel="noopener"
    >864x1152</a>)
and reducing images for limited VRAM.
So, this step will also change resolution, focals, and principle points:
<a class="link" href="https://github.com/YoYo000/MVSNet/blob/3ae2cb2b72c6df58ebcb321d7d243d4efd01fbc5/mvsnet/test.py#L107"  target="_blank" rel="noopener"
    >Code</a></p>
</li>
</ul>
<hr>
<h3 id="mvsnet-pytorch">MVSNet-PyTorch</h3>
<ul>
<li>
<p>Training cam: 1/8 focal of the original DTU
<a class="link" href="https://github.com/xy-guo/MVSNet_pytorch/blob/e0f2ae3d7cb2dd13807b775f2075682eaa7f1521/datasets/dtu_yao.py#L88"  target="_blank" rel="noopener"
    >Code</a></p>
</li>
<li>
<p>Testing cam: 1/4 focal of the original DTU
<a class="link" href="https://github.com/xy-guo/MVSNet_pytorch/blob/e0f2ae3d7cb2dd13807b775f2075682eaa7f1521/datasets/dtu_yao_eval.py#L53"  target="_blank" rel="noopener"
    >Code</a></p>
</li>
</ul>
<hr>
<h3 id="pixelnerf">PixelNeRF</h3>
<p>(2023-08-17)</p>
<p>&ldquo;rs_dtu_4&rdquo; follows the DVR format. Each object has 6 matrices. Take the object 0 as an example:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="o">[</span><span class="s1">&#39;scale_mat_0&#39;</span>,
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;scale_mat_inv_0&#39;</span>,
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;world_mat_0&#39;</span>,     <span class="c1"># Projection Matrix, 4x4</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;world_mat_inv_0&#39;</span>, <span class="c1"># Inverse Projection matrix, 4x4</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;camera_mat_0&#39;</span>,    <span class="c1"># ???</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;camera_mat_inv_0&#39;</span><span class="o">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li>
<p>Use <a class="link" href="https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#gaaae5a7899faa1ffdf268cd9088940248"  target="_blank" rel="noopener"
    ><code>cv2.decomposeProjectionMatrix(P)</code></a>
to solve ğŠ,ğ‘,ğ­ from ğâ‚ƒâ‚“â‚„.
Code in <a class="link" href="https://github.com/sxyu/pixel-nerf/blob/91a044bdd62aebe0ed3a5685ca37cb8a9dc8e8ee/src/data/DVRDataset.py#L157-L181"  target="_blank" rel="noopener"
    >PixelNeRF</a>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">P</span> <span class="o">=</span> <span class="n">all_cam</span><span class="p">[</span><span class="s2">&#34;world_mat_0&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">P</span> <span class="o">=</span> <span class="n">P</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>   <span class="c1"># (3,4), projection: Intrinsics * Extrinsics * 3Dpoint</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">K</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">decomposeProjectionMatrix</span><span class="p">(</span><span class="n">P</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]</span>  
</span></span><span class="line"><span class="cl"><span class="n">K</span> <span class="o">=</span> <span class="n">K</span> <span class="o">/</span> <span class="n">K</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>   <span class="c1"># Not the camera_mat, </span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Xc = extrinsics*Xw</span>
</span></span><span class="line"><span class="cl"><span class="n">extrinsics</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">extrinsics</span><span class="p">[:</span><span class="mi">3</span><span class="p">,:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">R</span>
</span></span><span class="line"><span class="cl"><span class="c1"># The 4th column is the rotated transVec</span>
</span></span><span class="line"><span class="cl"><span class="n">extrinsics</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">R</span> <span class="o">@</span> <span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span><span class="n">t</span><span class="p">[</span><span class="mi">3</span><span class="p">]))[:,</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">extrinsics</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># c2w equals inverse extrinsics</span>
</span></span><span class="line"><span class="cl"><span class="n">c2w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">c2w</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># The 4th column is the normalized t decomposed by cv2.</span>
</span></span><span class="line"><span class="cl"><span class="n">c2w</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">/</span> <span class="n">t</span><span class="p">[</span><span class="mi">3</span><span class="p">])[:,</span> <span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">c2w</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">extrinsics</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>The <a class="link" href="https://github.com/sxyu/pixel-nerf/blob/91a044bdd62aebe0ed3a5685ca37cb8a9dc8e8ee/src/data/DVRDataset.py#L178-L179"  target="_blank" rel="noopener"
    ><code>K</code></a>
(focal) in pixelNeRF is about <strong>twice as large</strong> as the <code>intrinsics</code> of &ldquo;dtu_training&rdquo;,
because the image size of pixelNeRF (300x400) is <strong>twice as small</strong> as MVSNet (or MVSNeRF) in each dimension,
where (512x640) is cropped from (600x800).
It&rsquo;s like when you observe the scene from far away, the image captured gets smaller.</p>
<p>Since the projection matrix computed from K@(R|Rt) is different, the decomposed intrinsics will be different.</p>
</li>
</ul>
<ul>
<li>
<p>(2024-02-22) The above statement may be wrong.
Take the 1st camera as an example:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cams</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&#34;pixel-nerf/data/DTU_Dataset/rs_dtu_4/DTU/scan1/cameras.npz&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">P</span> <span class="o">=</span> <span class="n">cams</span><span class="p">[</span><span class="s1">&#39;world_mat_0&#39;</span><span class="p">][:</span><span class="mi">3</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">K</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">decomposeProjectionMatrix</span><span class="p">(</span><span class="n">P</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">K</span> <span class="o">/</span> <span class="n">K</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The <code>K</code> equals 1/4 the intrinsics of the original DTU dataset:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="o">[[</span> 7.23082629e+02, -6.20158374e-05,  2.05801318e+02<span class="o">]</span>,
</span></span><span class="line"><span class="cl"> <span class="o">[</span> 0.00000000e+00,  7.20793819e+02,  1.54767729e+02<span class="o">]</span>,
</span></span><span class="line"><span class="cl"> <span class="o">[</span> 0.00000000e+00,  0.00000000e+00,  1.00000000e+00<span class="o">]]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Because camera is used to project 3D points ont feature maps, the focals should be scaled
based on the ratio of the feat map to the original image (1600,1200).</p>
</li>
</ul>
</li>
<li>
<p><code>c2w</code> (3x4) is not the Inverse Projection Matrix (4x4).</p>
<ul>
<li>
<p>Inverse Projection Matrix = <code>np.linalg.inv(Projection Matrix)</code></p>
</li>
<li>
<p>Projection matrix converts a 3D world coords to 2D <strong>pixel</strong> coords;</p>
</li>
<li>
<p>Extrinsics ( <strong>w2c = [R|t] = (R|Rt)</strong> ) converts 3D world coords to 3D camera coords.</p>
</li>
<li>
<p>Inverse Extrinsics ( <strong>c2w</strong> ) converts 3D camera coords to 3D world coords.</p>
</li>
<li>
<p>Give Extrinsics and Intrinsics (of dataset &ldquo;dtu_training&rdquo; from <a class="link" href="https://github.com/YoYo000/MVSNet#camera-files"  target="_blank" rel="noopener"
    >MVSNet</a>),
the Projection matrix can be restored as implemented in MVSNeRF <a class="link" href="https://github.com/apchenstu/mvsnerf/blob/1fdf6487389d0872dade614b3cea61f7b099406e/data/dtu.py#L82-L96"  target="_blank" rel="noopener"
    ><code>def build_proj_mats()</code></a></p>
</li>
</ul>
</li>
<li>
<p>The translation vector also needs rotation. <a class="link" href="https://stackoverflow.com/q/62686618/18003182"  target="_blank" rel="noopener"
    >OpenCV Decompose projection matrix</a></p>
<ul>
<li>
<p>Projection matrix = Intrinsics@Extrinsics = K@[R|t] = K@(R|Rt) = (KR|KRt)</p>
</li>
<li>
<p>Decomposed <code>t</code> needs normalization, and to be negated sometimes:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">631</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span> <span class="mi">384</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">              <span class="p">[</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">631</span><span class="p">,</span> <span class="mi">288</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">              <span class="p">[</span>  <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">1</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.30164902</span><span class="p">,</span>  <span class="mf">0.68282439</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.66540117</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">              <span class="p">[</span><span class="o">-</span><span class="mf">0.63417301</span><span class="p">,</span>  <span class="mf">0.37743435</span><span class="p">,</span>  <span class="mf">0.67480953</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">              <span class="p">[</span> <span class="mf">0.71192167</span><span class="p">,</span>  <span class="mf">0.6255351</span> <span class="p">,</span>  <span class="mf">0.3191761</span> <span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mf">3.75082481</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.18089565</span><span class="p">,</span>  <span class="mf">1.06138781</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">P</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span> <span class="o">@</span> <span class="n">R</span>
</span></span><span class="line"><span class="cl"><span class="n">P</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span> <span class="o">@</span> <span class="n">R</span> <span class="o">@</span> <span class="n">t</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">K1</span><span class="p">,</span> <span class="n">R1</span><span class="p">,</span> <span class="n">t1</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">decomposeProjectionMatrix</span><span class="p">(</span><span class="n">P</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:])[:</span><span class="mi">3</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">t</span> <span class="o">==</span> <span class="o">-</span><span class="p">(</span><span class="n">t1</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span><span class="n">t1</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>The original <code>t</code> can be obtained directly from projection matrix:
<code>np.linalg.inv(P[:3,:3]) @ P[:3,3]</code>,
i.e., use the inverse rotation to rotate the transVec back.</p>
</li>
</ul>
</li>
</ol>
<p>(2024-03-29)</p>
<ol start="4">
<li>
<p>The <code>t</code> returned by <code>cv2.decomposeProjectionMatrix</code> is the <strong>position of a camera</strong> in the world space. (<a class="link" href="https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#:~:text=%E2%97%86%C2%A0decomposeProjectionMatrix%28%29"  target="_blank" rel="noopener"
    >Docs</a>)
So, it&rsquo;s actually the translation vector in <strong>c2w</strong>: $t_{c2w}$.</p>
<p>Because <code>t</code> (denoted as $t_{cv2}$ for later) is the camera center, its corresponding camera-space coordinates is 0.
Thus, this is the relationship:</p>
<p>$$t_{cv2} = R_{c2w} 0 + t_{c2w} \\ t_{cv2} = t_{c2w}$$</p>
<p>To get the $t_{w2c}$, i.e., the 4-th column in the w2c (extrinsics), the conversion formula is $t_{w2c} = - R_{w2c} t_{c2w}$.</p>
<p>This relationship can be derived from the transformation between camera-space coordinate X and world coordinate P:</p>
<p>$$
P = R_{c2w} X + t_{c2w} \\
X = \underbrace{R_{c2w}^T}_{R_{w2c}} P \underbrace{- R_{c2w}^T t_{c2w}}_{t_{w2c}}
$$</p>
<p>Considering the <a class="link" href="#exp" >above</a> example, <code>t</code> is not the 4-th column in extrinsics, but the <code>-R @ (t/t[3])[:3]</code> is.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">&gt;&gt;&gt; t
</span></span><span class="line"><span class="cl">array<span class="o">([[</span>-0.99198397<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span> 0.00603084<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span>-0.12611273<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span>-0.00519817<span class="o">]])</span>
</span></span><span class="line"><span class="cl">&gt;&gt;&gt; t/t<span class="o">[</span>3<span class="o">]</span>
</span></span><span class="line"><span class="cl">array<span class="o">([[</span>190.83346195<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span> -1.16018638<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span> 24.26100588<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span>  1.        <span class="o">]])</span>
</span></span><span class="line"><span class="cl">&gt;&gt;&gt; -R @ <span class="o">(</span>t/t<span class="o">[</span>3<span class="o">])[</span>:3<span class="o">]</span>
</span></span><span class="line"><span class="cl">array<span class="o">([[</span>-191.01958721<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span>   3.28830259<span class="o">]</span>,
</span></span><span class="line"><span class="cl">       <span class="o">[</span>  22.54011993<span class="o">]])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Therefore, in PixelNeRF directly used <code>t</code> as the 4-th column of the <strong>c2w</strong>
(named as <a class="link" href="https://github.com/sxyu/pixel-nerf/blob/91a044bdd62aebe0ed3a5685ca37cb8a9dc8e8ee/src/data/DVRDataset.py#L166-L168"  target="_blank" rel="noopener"
    ><code>pose</code></a>)</p>
<p>I was reminded by:</p>
<ul>
<li>
<p><a class="link" href="https://github.com/sxyu/pixel-nerf/issues/10"  target="_blank" rel="noopener"
    >One question about cv2.decomposeProjectionMatrix #10</a></p>
</li>
<li>
<p><a class="link" href="https://github.com/facebookresearch/pytorch3d/issues/1371"  target="_blank" rel="noopener"
    >Questions on how to use PyTorch3D</a></p>
</li>
<li>
<p><a class="link" href="https://math.stackexchange.com/a/83578/1256848"  target="_blank" rel="noopener"
    >How to find camera position and rotation from a 4x4 matrix? - SE</a>
(surfaced by &ldquo;given camera extrinsics, how to determine right, up, front&rdquo; <a class="link" href="https://duckduckgo.com/?q=given&#43;camera&#43;extrinsics%2C&#43;how&#43;to&#43;determine&#43;right%2C&#43;up%2C&#43;front&amp;ia=web"  target="_blank" rel="noopener"
    >DDG</a>)</p>
<p>$$0=RC+T \\ C=âˆ’R^T T$$</p>
</li>
</ul>
<p>In the folllwing posts, they all mentioned the 4-th column in Extrinsics is not the camera center, but $-R_{c2w}^T C$,
where C is the camera center in world space:</p>
<ul>
<li>
<p><a class="link" href="https://ksimek.github.io/2012/08/22/extrinsic/#:~:text=Building%20the%20Extrinsic%20Matrix%20from%20Camera%20Pose"  target="_blank" rel="noopener"
    >Dissecting the Camera Matrix, Part 2: The Extrinsic Matrix - ksimek</a></p>
<p>He derived w2c from c2w, ie. w2c = (c2w)â»Â¹, and provided an interactive demo for visualizing camera intrinsic, extrinsic.</p>
</li>
<li>
<p><a class="link" href="https://miaodx.com/blogs/unrealcv_digest/camera_pose/"  target="_blank" rel="noopener"
    >Camera Pose &amp; Pose Estimation - MiaoDX</a>
refered by <a class="link" href="https://stackoverflow.com/q/73345418/18003182"  target="_blank" rel="noopener"
    >Camera extrinsic matrix from camera location and rotation</a></p>
</li>
<li>
<p><a class="link" href="https://stackoverflow.com/q/8178467/18003182"  target="_blank" rel="noopener"
    >How to plot the camera and image positions from camera calibration data? - SO</a></p>
<p>The OP cited <a class="link" href="https://en.wikipedia.org/wiki/Camera_resectioning#Extrinsic_parameters"  target="_blank" rel="noopener"
    >wikipedia</a> $C = -R^{-1} T = -R^T T$</p>
</li>
<li>
<p><a class="link" href="https://stackoverflow.com/q/42652522/18003182"  target="_blank" rel="noopener"
    >Plot Camera Trajectory - SO</a>
<img src="https://i.stack.imgur.com/urG1y.png" width="50%"></p>
</li>
<li>
<p><a class="link" href="https://github.com/colmap/colmap/issues/1476#issuecomment-1087241468"  target="_blank" rel="noopener"
    >Understanding COLMAP&rsquo;s Camera Poses and Depth Data #1476</a></p>
</li>
<li>
<p><code>inv([R|t]) = [R'|-R'*t]</code> <a class="link" href="https://stackoverflow.com/a/18643735/18003182"  target="_blank" rel="noopener"
    >Camera position in world coordinate from cv::solvePnP - SO</a></p>
</li>
</ul>
</li>
</ol>

</section>


    <footer class="article-footer">
    

    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css"integrity="sha256-J&#43;iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s="crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js"integrity="sha256-InsNdER1b2xUewP&#43;pKCUJpkhiqwHgqiPXDlIk7GzBu4="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js"integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI="crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>

    

    

    


    
    


    
    

</article>



    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2024 Zichen Wang
    </section>
    
    <section class="powerby">
        
              <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CC BY-SA 4.0</a>
   <br/>
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.16.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
